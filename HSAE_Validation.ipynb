{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import layers, models, regularizers\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, ExtraTreesClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import confusion_matrix,classification_report,accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.svm import SVC\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.read_csv('protein_expression.csv')\n",
    "inputed_columns = ['AGID00215',\n",
    " 'AGID00537',\n",
    " 'AGID00536',\n",
    " 'AGID00211',\n",
    " 'AGID00485',\n",
    " 'AGID00383',\n",
    " 'AGID00216',\n",
    " 'AGID00257',\n",
    " 'AGID00545',\n",
    " 'AGID00413',\n",
    " 'AGID00547',\n",
    " 'AGID00144']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['AGID00100', 'AGID00111', 'AGID00101', 'AGID00001', 'AGID00002',\n",
       "       'AGID00003', 'AGID00443', 'AGID00120', 'AGID00004', 'AGID00005',\n",
       "       ...\n",
       "       'AGID00349', 'AGID02137', 'AGID00088', 'AGID00089', 'AGID00504',\n",
       "       'AGID00095', 'AGID02217', 'AGID02210', 'AGID00326', 'AGID00432'],\n",
       "      dtype='object', length=468)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "protein_columns = merged_df.columns.drop([\"ajcc_pathologic_stage\",\"vital_status\",\"days_to_death\",\"days_to_last_follow_up\",\"case_submitter_id\"])\n",
    "protein_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "describe_df = merged_df[protein_columns].describe()\n",
    "row_means = describe_df.loc['mean']\n",
    "\n",
    "# Plot row means\n",
    "plt.figure(figsize=(10, 6))\n",
    "row_means.plot(kind='bar', color='skyblue')\n",
    "plt.title('Feature Means')\n",
    "plt.xlabel('Feature')\n",
    "plt.ylabel('Mean')\n",
    "\n",
    "plt.xticks(range(0, len(row_means), 10), row_means.index[::10], rotation=45, ha='right')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = merged_df.drop([\"ajcc_pathologic_stage\",\"vital_status\",\"days_to_last_follow_up\",\"case_submitter_id\"], axis=1)\n",
    "other = merged_df.columns.drop(\"days_to_death\")\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "merged_df[other] = scaler.fit_transform(merged_df[other])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(merged_df[other], merged_df[\"days_to_death\"],\n",
    "                                                    train_size=0.8,\n",
    "                                                    random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_train.hist(bins=30) \n",
    "plt.xlabel('OS')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of the OS')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AE():\n",
    "    def __init__(self,X_train,X_test,y_train,y_test,bottleneck,size,type):\n",
    "        self.X_train = X_train\n",
    "        self.X_test = X_test        \n",
    "        self.y_train = y_train\n",
    "        self.y_test = y_test\n",
    "        self.bottleneck = bottleneck\n",
    "        self.history = None\n",
    "        self.encoder = None\n",
    "        self.autoencoder = None\n",
    "        self.size = size\n",
    "        self.classifer = None\n",
    "        self.cv_scores = {}\n",
    "        self.type = type\n",
    "\n",
    "    def train(self):\n",
    "    # Number of features in your dataset\n",
    "        n_features = len(self.X_train.columns) \n",
    "\n",
    "\n",
    "        input_layer = Input(shape=(n_features,))\n",
    "        encoder = Dense(64, activation='relu')(input_layer)\n",
    "        encoder = Dense(32, activation='relu')(encoder)\n",
    "\n",
    "\n",
    "        bottleneck = Dense(self.bottleneck, activation='relu')(encoder)  \n",
    "\n",
    "        # Define the decoder (mirror the encoder)\n",
    "        decoder = Dense(32, activation='relu')(bottleneck)\n",
    "        decoder = Dense(64, activation='relu')(decoder)\n",
    "        self.encoder= Model(inputs=input_layer, outputs=bottleneck)\n",
    "\n",
    "        # Output layer\n",
    "        output_layer = Dense(n_features, activation='sigmoid')(decoder) \n",
    "\n",
    "        # Define the autoencoder model\n",
    "        self.autoencoder = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "        # Compile the autoencoder\n",
    "        self.autoencoder.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "        self.checkpoint = ModelCheckpoint(f'model/{self.type}_{self.size}_best_model.keras', \n",
    "                             monitor='val_loss', \n",
    "                             verbose=1,           \n",
    "                             save_best_only=True, \n",
    "                             mode='min')         \n",
    "\n",
    "        X_train, X_test= train_test_split(self.X_train,\n",
    "                                            train_size=0.8,\n",
    "                                            random_state=1)\n",
    "\n",
    "        self.history = self.autoencoder.fit(X_train, X_train,\n",
    "                epochs=40,\n",
    "                batch_size=8,\n",
    "                shuffle=True,\n",
    "                validation_data=(X_test, X_test),\n",
    "                callbacks=[self.checkpoint])  \n",
    "        \n",
    "        self.encode()\n",
    "        self.map_y()\n",
    "\n",
    "    def plot(self):\n",
    "        plt.plot(self.history.history['loss'], label='Training Loss')\n",
    "        plt.plot(self.history.history['val_loss'], label='Validation Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title('Training and Validation Loss '+ self.size)\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    def encode(self):\n",
    "        self.autoencoder.load_weights(f'model/{self.type}_{self.size}_best_model.keras')\n",
    "        self.encoded_X_train = self.encoder.predict(self.X_train)\n",
    "        self.encoded_X_test = self.encoder.predict(self.X_test)\n",
    "    \n",
    "    def do_PCA(self,n_components):\n",
    "        if self.bottleneck == 2:\n",
    "            # pca = PCA(n_components=n_components)\n",
    "            # reduced_data = pca.fit_transform(self.encoded_X_test)\n",
    "            x = self.encoded_X_test[:, 0]\n",
    "            y = self.encoded_X_test[:, 1]\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            scatter = plt.scatter(x, y, c=self.y_test_in_bin, cmap='viridis', alpha=0.7)\n",
    "            plt.title('Encoded Data '+self.size)\n",
    "            plt.xlabel('Encoded Dim 0')\n",
    "            plt.ylabel('Encoded Dim 1')\n",
    "            plt.colorbar(scatter, label='OS')\n",
    "            plt.grid(True)\n",
    "            plt.show()\n",
    "            return\n",
    "        if n_components ==2:\n",
    "            pca = PCA(n_components=n_components)\n",
    "            reduced_data = pca.fit_transform(self.encoded_X_test)\n",
    "            x = reduced_data[:, 0]\n",
    "            y = reduced_data[:, 1]\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            scatter = plt.scatter(x, y, c=self.y_test_in_bin, cmap='viridis', alpha=0.7)\n",
    "            plt.title('PCA of Encoded Data '+self.size)\n",
    "            plt.xlabel('Principal Component 1')\n",
    "            plt.ylabel('Principal Component 2')\n",
    "            plt.colorbar(scatter, label='OS')\n",
    "            plt.grid(True)\n",
    "            plt.show()\n",
    "        elif n_components ==3:\n",
    "            pca = PCA(n_components=3)  # Reduce to 3 dimensions\n",
    "            reduced_data = pca.fit_transform(self.encoded_X_test)\n",
    "            x = reduced_data[:, 0]\n",
    "            y = reduced_data[:, 1]\n",
    "            z = reduced_data[:, 2]\n",
    "            fig =plt.figure(figsize=(8, 6))\n",
    "            ax = fig.add_subplot(111, projection='3d')\n",
    "            scatter = ax.scatter(x, y, z, c=self.y_test_in_bin, cmap='viridis', depthshade=True)\n",
    "            ax.set_title('3D PCA of Encoded Data '+self.size)\n",
    "            ax.set_xlabel('Principal Component 1')\n",
    "            ax.set_ylabel('Principal Component 2')\n",
    "            ax.set_zlabel('Principal Component 3')\n",
    "            plt.colorbar(scatter, label='OS')\n",
    "            plt.show()\n",
    "\n",
    "    @staticmethod\n",
    "    def map_years_to_group(value):\n",
    "        years = value / 365\n",
    "        if years <= 1:\n",
    "            return 0\n",
    "        elif 1 < years <= 3:\n",
    "            return 1\n",
    "        elif 3 < years <= 5:\n",
    "            return 2\n",
    "        elif 5 < years <= 10:\n",
    "            return 3\n",
    "        elif 10 < years <= 20:\n",
    "            return 4\n",
    "        else:  \n",
    "            return 5\n",
    "        \n",
    "    @staticmethod        \n",
    "    def map_to_binary(category):\n",
    "        if category >= 4:\n",
    "            return 1\n",
    "        else:  \n",
    "            return 0\n",
    "        \n",
    "    def map_y(self):\n",
    "        self.y_trian_in_category = self.y_train.map(AE.map_years_to_group)\n",
    "        self.y_test_in_category = self.y_test.map(AE.map_years_to_group)        \n",
    "        \n",
    "        self.y_trian_in_bin = self.y_trian_in_category.map(AE.map_to_binary)\n",
    "        self.y_test_in_bin = self.y_test_in_category.map(AE.map_to_binary)\n",
    "\n",
    "    def cross_validation_model_selection(self,fold=10):\n",
    "        classifiers = {\n",
    "            'LogisticRegression': LogisticRegression(),\n",
    "            'SVM': SVC(),\n",
    "            'RandomForest': RandomForestClassifier(),\n",
    "            'KNN': KNeighborsClassifier(),\n",
    "            'GradientBoosting': GradientBoostingClassifier(),\n",
    "            'AdaBoost': AdaBoostClassifier(),\n",
    "            'NaiveBayes': GaussianNB(),\n",
    "            'DecisionTree': DecisionTreeClassifier(),\n",
    "            'ExtraTrees': ExtraTreesClassifier(),\n",
    "            'XGBoost': xgb.XGBClassifier()\n",
    "        }\n",
    "\n",
    "        kf = KFold(n_splits=fold)\n",
    "        best_cv_score = 0\n",
    "\n",
    "\n",
    "        for name, clf in classifiers.items():\n",
    "            cv_scores = []\n",
    "            confusion_matrices = []\n",
    "\n",
    "            for train_index, test_index in kf.split(self.encoded_X_train):\n",
    "                X_train, X_test = self.encoded_X_train[train_index], self.encoded_X_train[test_index]\n",
    "                y_train, y_test = self.y_trian_in_bin.iloc[train_index], self.y_trian_in_bin.iloc[test_index]\n",
    "\n",
    "                clf.fit(X_train, y_train)\n",
    "                y_pred = clf.predict(X_test)\n",
    "                \n",
    "                cv_scores.append(accuracy_score(y_test, y_pred))\n",
    "                confusion_matrices.append(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "            mean_cv_score = np.mean(cv_scores)\n",
    "            mean_conf_matrix = np.mean(confusion_matrices, axis=0)\n",
    "\n",
    "            self.cv_scores[name] = mean_cv_score\n",
    "            \n",
    "            print(f\"{name} - Mean CV Score: {mean_cv_score}\")\n",
    "            print(f\"{name} - Mean Confusion Matrix:\\n{mean_conf_matrix}\")\n",
    "\n",
    "            if mean_cv_score > best_cv_score:\n",
    "                best_cv_score = mean_cv_score\n",
    "                best_classifier = name\n",
    "\n",
    "        print(f\"Size: {self.size}, Best classifier: {best_classifier}, CV Score: {best_cv_score}\")\n",
    "\n",
    "\n",
    "\n",
    "    def cross_validation_hyperparameter_optimization(self,fold=5):\n",
    "        pass\n",
    "\n",
    "\n",
    "    def do_RF(self,binary):\n",
    "        clf = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "\n",
    "        if binary:\n",
    "            clf.fit(self.encoded_X_train, self.y_trian_in_bin)\n",
    "            y_pred = clf.predict(self.encoded_X_test)\n",
    "            cm = confusion_matrix(self.y_test_in_bin, y_pred)\n",
    "            print(classification_report(self.y_test_in_bin, y_pred))\n",
    "\n",
    "        else:\n",
    "            clf.fit(self.encoded_X_train, self.y_trian_in_category)\n",
    "            y_pred = clf.predict(self.encoded_X_test)\n",
    "            cm = confusion_matrix(self.y_test_in_category, y_pred)\n",
    "            print(classification_report(self.y_test_in_category, y_pred))\n",
    "\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=np.unique(y_pred), yticklabels=np.unique(self.y_test_in_bin))\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('Actual')\n",
    "        plt.title('RF Confusion Matrix '+self.type)\n",
    "        plt.show()\n",
    "        self.classifer = clf\n",
    "\n",
    "    def do_Kmean(self):\n",
    "        # Number of clusters - assuming you want as many as your known classes\n",
    "        num_clusters = 2\n",
    "        # Perform K-means clustering on the PCA output\n",
    "        kmeans = KMeans(n_clusters=num_clusters, random_state=0)\n",
    "        cluster_labels = kmeans.fit_predict(self.encoded_X_test)  # Use your 2D or 3D PCA-reduced data here\n",
    "\n",
    "\n",
    "        print(\"Classification Report:\")\n",
    "        print(classification_report(self.y_test_in_bin, cluster_labels))\n",
    "        conf_mat = confusion_matrix(self.y_test_in_bin, cluster_labels)\n",
    "\n",
    "        # Plotting the confusion matrix\n",
    "        sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues', xticklabels=range(num_clusters), yticklabels=np.unique(self.y_test_in_bin))\n",
    "        plt.xlabel('Predicted labels')\n",
    "        plt.ylabel('True labels')\n",
    "        plt.title('K-mean Confusion Matrix '+self.size)\n",
    "        plt.show()\n",
    "        self.classifer = kmeans\n",
    "\n",
    "    def do_SVM(self,binary):\n",
    "        svm_classifier = SVC(kernel='linear',random_state=0)\n",
    "        # Load the best weights into the autoencoder model\n",
    "        if binary:\n",
    "            svm_classifier.fit(self.encoded_X_train, self.y_trian_in_bin)\n",
    "            y_pred = svm_classifier.predict(self.encoded_X_test)\n",
    "            cm = confusion_matrix(self.y_test_in_bin, y_pred)\n",
    "            print(classification_report(self.y_test_in_bin, y_pred))\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=np.unique(y_pred), yticklabels=np.unique(self.y_test_in_bin))\n",
    "            plt.xlabel('Predicted')\n",
    "            plt.ylabel('Actual')\n",
    "            plt.title('SVM Confusion Matrix '+ self.size)\n",
    "            plt.show()\n",
    "        else:\n",
    "            svm_classifier.fit(self.encoded_X_train, self.y_trian_in_category)\n",
    "            y_pred = svm_classifier.predict(self.encoded_X_test)\n",
    "            cm = confusion_matrix(self.y_test_in_category, y_pred)\n",
    "            print(classification_report(self.y_test_in_category, y_pred))\n",
    "        \n",
    "            # Plotting the confusion matrix\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=np.unique(y_pred), yticklabels=np.unique(self.y_test_in_category))\n",
    "            plt.xlabel('Predicted')\n",
    "            plt.ylabel('Actual')\n",
    "            plt.title('SVM Confusion Matrix '+ self.size)\n",
    "            plt.show()\n",
    "        self.classifer = svm_classifier\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Wider_AE(AE):\n",
    "    def train(self):\n",
    "    # Number of features in your dataset\n",
    "        n_features = len(self.X_train.columns) \n",
    "\n",
    "\n",
    "        input_layer = Input(shape=(n_features,))\n",
    "        encoder = Dense(256, activation='relu')(input_layer)\n",
    "\n",
    "        encoder = Dense(128, activation='relu')(input_layer)\n",
    "        encoder = Dense(64, activation='relu')(encoder)\n",
    "\n",
    "\n",
    "        bottleneck = Dense(self.bottleneck, activation='relu')(encoder)  \n",
    "\n",
    "        # Define the decoder (mirror the encoder)\n",
    "        decoder = Dense(64, activation='relu')(bottleneck)\n",
    "        decoder = Dense(128, activation='relu')(decoder)\n",
    "        decoder = Dense(256, activation='relu')(decoder)\n",
    "\n",
    "        self.encoder= Model(inputs=input_layer, outputs=bottleneck)\n",
    "\n",
    "        # Output layer\n",
    "        output_layer = Dense(n_features, activation='sigmoid')(decoder) \n",
    "\n",
    "        # Define the autoencoder model\n",
    "        self.autoencoder = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "        # Compile the autoencoder\n",
    "        self.autoencoder.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "        self.checkpoint = ModelCheckpoint(f'model/{self.type}_{self.size}_best_model.keras', \n",
    "                             monitor='val_loss', \n",
    "                             verbose=1,           \n",
    "                             save_best_only=True, \n",
    "                             mode='min')         \n",
    "\n",
    "        X_train, X_test= train_test_split(self.X_train,\n",
    "                                            train_size=0.8,\n",
    "                                            random_state=1)\n",
    "\n",
    "        self.history = self.autoencoder.fit(X_train, X_train,\n",
    "                epochs=40,\n",
    "                batch_size=8,\n",
    "                shuffle=True,\n",
    "                validation_data=(X_test, X_test),\n",
    "                callbacks=[self.checkpoint])  \n",
    "        \n",
    "        self.encode()\n",
    "        self.map_y()       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAE(AE):\n",
    "    def train(self):\n",
    "\n",
    "        n_features = len(self.X_train.columns)\n",
    "\n",
    "        # Define the encoder\n",
    "        input_layer = Input(shape=(n_features,))\n",
    "        # Add L1 regularization to encourage sparsity\n",
    "        encoder = Dense(64, activation='relu', \n",
    "                        activity_regularizer=regularizers.l1(1e-6))(input_layer)  # Adjust regularization rate as needed\n",
    "        encoder = Dense(32, activation='relu', \n",
    "                        activity_regularizer=regularizers.l1(1e-6))(encoder)  # Adjust regularization rate as needed\n",
    "\n",
    "        # Define the bottleneck\n",
    "        bottleneck = Dense(self.bottleneck, activation='relu')(encoder)  \n",
    "\n",
    "        # Define the decoder (mirror the encoder)\n",
    "        decoder = Dense(32, activation='relu')(bottleneck)\n",
    "        decoder = Dense(64, activation='relu')(decoder)\n",
    "        self.encoder = Model(inputs=input_layer, outputs=bottleneck)\n",
    "\n",
    "        # Output layer\n",
    "        output_layer = Dense(n_features, activation='sigmoid')(decoder) \n",
    "\n",
    "        # Define the autoencoder model\n",
    "        self.autoencoder = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "        # Compile the autoencoder\n",
    "        self.autoencoder.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "        # Callback to save the best model\n",
    "        self.checkpoint = ModelCheckpoint(f'model/{self.type}_{self.size}_best_model.keras', \n",
    "                             monitor='val_loss', \n",
    "                             verbose=1, \n",
    "                             save_best_only=True, \n",
    "                             mode='min')\n",
    "\n",
    "        X_train, X_test= train_test_split(self.X_train,\n",
    "                                            train_size=0.8,\n",
    "                                            random_state=1)\n",
    "\n",
    "        self.history = self.autoencoder.fit(X_train, X_train,\n",
    "                epochs=40,\n",
    "                batch_size=8,\n",
    "                shuffle=True,\n",
    "                validation_data=(X_test, X_test),\n",
    "                callbacks=[self.checkpoint])  \n",
    "        self.encode()\n",
    "        self.map_y()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DSAE(AE):\n",
    "    def train(self):\n",
    "    # Number of features in your dataset\n",
    "        n_features = len(self.X_train.columns) \n",
    "\n",
    "\n",
    "        input_layer = Input(shape=(n_features,))\n",
    "        encoder = Dense(256, activation='relu',activity_regularizer=regularizers.l1(1e-4))(input_layer)\n",
    "\n",
    "        encoder = Dense(128, activation='relu',activity_regularizer=regularizers.l1(1e-4))(input_layer)\n",
    "        encoder = Dense(64, activation='relu',activity_regularizer=regularizers.l1(1e-4))(encoder)\n",
    "\n",
    "\n",
    "        bottleneck = Dense(self.bottleneck, activation='relu')(encoder)  \n",
    "\n",
    "        # Define the decoder (mirror the encoder)\n",
    "        decoder = Dense(64, activation='relu')(bottleneck)\n",
    "        decoder = Dense(128, activation='relu')(decoder)\n",
    "        decoder = Dense(256, activation='relu')(decoder)\n",
    "\n",
    "        self.encoder= Model(inputs=input_layer, outputs=bottleneck)\n",
    "\n",
    "        # Output layer\n",
    "        output_layer = Dense(n_features, activation='sigmoid')(decoder) \n",
    "\n",
    "        # Define the autoencoder model\n",
    "        self.autoencoder = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "        # Compile the autoencoder\n",
    "        self.autoencoder.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "        self.checkpoint = ModelCheckpoint(f'model/{self.type}_{self.size}_best_model.keras', \n",
    "                             monitor='val_loss', \n",
    "                             verbose=1,           \n",
    "                             save_best_only=True, \n",
    "                             mode='min')         \n",
    "\n",
    "        X_train, X_test= train_test_split(self.X_train,\n",
    "                                            train_size=0.8,\n",
    "                                            random_state=1)\n",
    "\n",
    "        self.history = self.autoencoder.fit(X_train, X_train,\n",
    "                epochs=40,\n",
    "                batch_size=8,\n",
    "                shuffle=True,\n",
    "                validation_data=(X_test, X_test),\n",
    "                callbacks=[self.checkpoint])  \n",
    "        \n",
    "        self.encode()\n",
    "        self.map_y()\n",
    "\n",
    "\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dispatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dispatcher(model,type,min_bottleneck, max_bottleneck,step =4):\n",
    "    current_size = min_bottleneck\n",
    "    AEs = []\n",
    "    results = []\n",
    "    while current_size <= max_bottleneck:\n",
    "        name = f\"bottleneck_{current_size}\"\n",
    "        AEs.append(model(X_train=X_train,X_test=X_test,y_train=y_train,y_test=y_test,bottleneck = current_size,size = name,type = type))\n",
    "        current_size += step\n",
    "    for AE_to_train in AEs:\n",
    "        AE_to_train.train()\n",
    "        AE_to_train.cross_validation_model_selection()\n",
    "        results.append({f\"{type} {name}\": AE_to_train.cv_scores})\n",
    "    \n",
    "    output = json.dumps(results)\n",
    "    with open(f\"output\\{type}_model_output.json\",\"w\") as file:\n",
    "        file.write(output)\n",
    "    return\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0374 \n",
      "Epoch 1: val_loss improved from inf to 0.02685, saving model to model\\AE_bottleneck_8_best_model.keras\n",
      "26/26 [==============================] - 1s 14ms/step - loss: 0.0373 - val_loss: 0.0269\n",
      "Epoch 2/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0218\n",
      "Epoch 2: val_loss improved from 0.02685 to 0.02423, saving model to model\\AE_bottleneck_8_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0237 - val_loss: 0.0242\n",
      "Epoch 3/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0225\n",
      "Epoch 3: val_loss improved from 0.02423 to 0.02370, saving model to model\\AE_bottleneck_8_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0227 - val_loss: 0.0237\n",
      "Epoch 4/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0250\n",
      "Epoch 4: val_loss improved from 0.02370 to 0.02330, saving model to model\\AE_bottleneck_8_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0224 - val_loss: 0.0233\n",
      "Epoch 5/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0220\n",
      "Epoch 5: val_loss improved from 0.02330 to 0.02220, saving model to model\\AE_bottleneck_8_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0218 - val_loss: 0.0222\n",
      "Epoch 6/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0202\n",
      "Epoch 6: val_loss improved from 0.02220 to 0.02039, saving model to model\\AE_bottleneck_8_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0203 - val_loss: 0.0204\n",
      "Epoch 7/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0190\n",
      "Epoch 7: val_loss improved from 0.02039 to 0.01976, saving model to model\\AE_bottleneck_8_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0192 - val_loss: 0.0198\n",
      "Epoch 8/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0167\n",
      "Epoch 8: val_loss improved from 0.01976 to 0.01946, saving model to model\\AE_bottleneck_8_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0186 - val_loss: 0.0195\n",
      "Epoch 9/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0188\n",
      "Epoch 9: val_loss improved from 0.01946 to 0.01893, saving model to model\\AE_bottleneck_8_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0183 - val_loss: 0.0189\n",
      "Epoch 10/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0172\n",
      "Epoch 10: val_loss improved from 0.01893 to 0.01852, saving model to model\\AE_bottleneck_8_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0179 - val_loss: 0.0185\n",
      "Epoch 11/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0182\n",
      "Epoch 11: val_loss improved from 0.01852 to 0.01814, saving model to model\\AE_bottleneck_8_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0174 - val_loss: 0.0181\n",
      "Epoch 12/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0170\n",
      "Epoch 12: val_loss improved from 0.01814 to 0.01805, saving model to model\\AE_bottleneck_8_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0170 - val_loss: 0.0180\n",
      "Epoch 13/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0197\n",
      "Epoch 13: val_loss improved from 0.01805 to 0.01777, saving model to model\\AE_bottleneck_8_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0168 - val_loss: 0.0178\n",
      "Epoch 14/40\n",
      "21/26 [=======================>......] - ETA: 0s - loss: 0.0164\n",
      "Epoch 14: val_loss improved from 0.01777 to 0.01771, saving model to model\\AE_bottleneck_8_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0166 - val_loss: 0.0177\n",
      "Epoch 15/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0156\n",
      "Epoch 15: val_loss improved from 0.01771 to 0.01755, saving model to model\\AE_bottleneck_8_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0164 - val_loss: 0.0176\n",
      "Epoch 16/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0164\n",
      "Epoch 16: val_loss improved from 0.01755 to 0.01744, saving model to model\\AE_bottleneck_8_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0163 - val_loss: 0.0174\n",
      "Epoch 17/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0222\n",
      "Epoch 17: val_loss improved from 0.01744 to 0.01737, saving model to model\\AE_bottleneck_8_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0162 - val_loss: 0.0174\n",
      "Epoch 18/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0149\n",
      "Epoch 18: val_loss improved from 0.01737 to 0.01727, saving model to model\\AE_bottleneck_8_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0161 - val_loss: 0.0173\n",
      "Epoch 19/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0171\n",
      "Epoch 19: val_loss improved from 0.01727 to 0.01714, saving model to model\\AE_bottleneck_8_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0159 - val_loss: 0.0171\n",
      "Epoch 20/40\n",
      "15/26 [================>.............] - ETA: 0s - loss: 0.0162\n",
      "Epoch 20: val_loss improved from 0.01714 to 0.01713, saving model to model\\AE_bottleneck_8_best_model.keras\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0158 - val_loss: 0.0171\n",
      "Epoch 21/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0159\n",
      "Epoch 21: val_loss improved from 0.01713 to 0.01696, saving model to model\\AE_bottleneck_8_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0157 - val_loss: 0.0170\n",
      "Epoch 22/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0153\n",
      "Epoch 22: val_loss improved from 0.01696 to 0.01692, saving model to model\\AE_bottleneck_8_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0155 - val_loss: 0.0169\n",
      "Epoch 23/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0132\n",
      "Epoch 23: val_loss improved from 0.01692 to 0.01678, saving model to model\\AE_bottleneck_8_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0154 - val_loss: 0.0168\n",
      "Epoch 24/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0174\n",
      "Epoch 24: val_loss improved from 0.01678 to 0.01666, saving model to model\\AE_bottleneck_8_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0152 - val_loss: 0.0167\n",
      "Epoch 25/40\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0149\n",
      "Epoch 25: val_loss improved from 0.01666 to 0.01641, saving model to model\\AE_bottleneck_8_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0149 - val_loss: 0.0164\n",
      "Epoch 26/40\n",
      "12/26 [============>.................] - ETA: 0s - loss: 0.0142\n",
      "Epoch 26: val_loss improved from 0.01641 to 0.01635, saving model to model\\AE_bottleneck_8_best_model.keras\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0146 - val_loss: 0.0164\n",
      "Epoch 27/40\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0145\n",
      "Epoch 27: val_loss improved from 0.01635 to 0.01633, saving model to model\\AE_bottleneck_8_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0145 - val_loss: 0.0163\n",
      "Epoch 28/40\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0144\n",
      "Epoch 28: val_loss improved from 0.01633 to 0.01615, saving model to model\\AE_bottleneck_8_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0144 - val_loss: 0.0162\n",
      "Epoch 29/40\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0142\n",
      "Epoch 29: val_loss improved from 0.01615 to 0.01610, saving model to model\\AE_bottleneck_8_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0142 - val_loss: 0.0161\n",
      "Epoch 30/40\n",
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0142\n",
      "Epoch 30: val_loss improved from 0.01610 to 0.01608, saving model to model\\AE_bottleneck_8_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0142 - val_loss: 0.0161\n",
      "Epoch 31/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0133\n",
      "Epoch 31: val_loss did not improve from 0.01608\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0141 - val_loss: 0.0161\n",
      "Epoch 32/40\n",
      "11/26 [===========>..................] - ETA: 0s - loss: 0.0136\n",
      "Epoch 32: val_loss did not improve from 0.01608\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0140 - val_loss: 0.0161\n",
      "Epoch 33/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0147\n",
      "Epoch 33: val_loss improved from 0.01608 to 0.01598, saving model to model\\AE_bottleneck_8_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0140 - val_loss: 0.0160\n",
      "Epoch 34/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0158\n",
      "Epoch 34: val_loss did not improve from 0.01598\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0139 - val_loss: 0.0160\n",
      "Epoch 35/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0125\n",
      "Epoch 35: val_loss improved from 0.01598 to 0.01595, saving model to model\\AE_bottleneck_8_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0138 - val_loss: 0.0160\n",
      "Epoch 36/40\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0138\n",
      "Epoch 36: val_loss improved from 0.01595 to 0.01594, saving model to model\\AE_bottleneck_8_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0138 - val_loss: 0.0159\n",
      "Epoch 37/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0104\n",
      "Epoch 37: val_loss improved from 0.01594 to 0.01593, saving model to model\\AE_bottleneck_8_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0138 - val_loss: 0.0159\n",
      "Epoch 38/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0126\n",
      "Epoch 38: val_loss improved from 0.01593 to 0.01592, saving model to model\\AE_bottleneck_8_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0138 - val_loss: 0.0159\n",
      "Epoch 39/40\n",
      "13/26 [==============>...............] - ETA: 0s - loss: 0.0140\n",
      "Epoch 39: val_loss improved from 0.01592 to 0.01591, saving model to model\\AE_bottleneck_8_best_model.keras\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0137 - val_loss: 0.0159\n",
      "Epoch 40/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0147\n",
      "Epoch 40: val_loss improved from 0.01591 to 0.01582, saving model to model\\AE_bottleneck_8_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0136 - val_loss: 0.0158\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "LogisticRegression - Mean CV Score: 0.5752307692307692\n",
      "LogisticRegression - Mean Confusion Matrix:\n",
      "[[7.  5.6]\n",
      " [5.4 7.9]]\n",
      "SVM - Mean CV Score: 0.6064615384615384\n",
      "SVM - Mean Confusion Matrix:\n",
      "[[7.5 5.1]\n",
      " [5.1 8.2]]\n",
      "RandomForest - Mean CV Score: 0.5833846153846153\n",
      "RandomForest - Mean Confusion Matrix:\n",
      "[[7.5 5.1]\n",
      " [5.7 7.6]]\n",
      "KNN - Mean CV Score: 0.564\n",
      "KNN - Mean Confusion Matrix:\n",
      "[[8.  4.6]\n",
      " [6.7 6.6]]\n",
      "GradientBoosting - Mean CV Score: 0.5599999999999999\n",
      "GradientBoosting - Mean Confusion Matrix:\n",
      "[[7.5 5.1]\n",
      " [6.3 7. ]]\n",
      "AdaBoost - Mean CV Score: 0.5872307692307691\n",
      "AdaBoost - Mean Confusion Matrix:\n",
      "[[7.8 4.8]\n",
      " [5.9 7.4]]\n",
      "NaiveBayes - Mean CV Score: 0.6063076923076922\n",
      "NaiveBayes - Mean Confusion Matrix:\n",
      "[[8.8 3.8]\n",
      " [6.4 6.9]]\n",
      "DecisionTree - Mean CV Score: 0.5326153846153845\n",
      "DecisionTree - Mean Confusion Matrix:\n",
      "[[6.6 6. ]\n",
      " [6.1 7.2]]\n",
      "ExtraTrees - Mean CV Score: 0.6104615384615384\n",
      "ExtraTrees - Mean Confusion Matrix:\n",
      "[[7.6 5. ]\n",
      " [5.1 8.2]]\n",
      "XGBoost - Mean CV Score: 0.5598461538461539\n",
      "XGBoost - Mean Confusion Matrix:\n",
      "[[7.3 5.3]\n",
      " [6.1 7.2]]\n",
      "Size: bottleneck_8, Best classifier: ExtraTrees, CV Score: 0.6104615384615384\n",
      "Epoch 1/40\n",
      "16/26 [=================>............] - ETA: 0s - loss: 0.0411 \n",
      "Epoch 1: val_loss improved from inf to 0.02680, saving model to model\\AE_bottleneck_12_best_model.keras\n",
      "26/26 [==============================] - 1s 13ms/step - loss: 0.0365 - val_loss: 0.0268\n",
      "Epoch 2/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0277\n",
      "Epoch 2: val_loss improved from 0.02680 to 0.02334, saving model to model\\AE_bottleneck_12_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0233 - val_loss: 0.0233\n",
      "Epoch 3/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0213\n",
      "Epoch 3: val_loss improved from 0.02334 to 0.02141, saving model to model\\AE_bottleneck_12_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0214 - val_loss: 0.0214\n",
      "Epoch 4/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0200\n",
      "Epoch 4: val_loss improved from 0.02141 to 0.01998, saving model to model\\AE_bottleneck_12_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0197 - val_loss: 0.0200\n",
      "Epoch 5/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0163\n",
      "Epoch 5: val_loss improved from 0.01998 to 0.01971, saving model to model\\AE_bottleneck_12_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0190 - val_loss: 0.0197\n",
      "Epoch 6/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0208\n",
      "Epoch 6: val_loss improved from 0.01971 to 0.01941, saving model to model\\AE_bottleneck_12_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0187 - val_loss: 0.0194\n",
      "Epoch 7/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0175\n",
      "Epoch 7: val_loss improved from 0.01941 to 0.01931, saving model to model\\AE_bottleneck_12_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0186 - val_loss: 0.0193\n",
      "Epoch 8/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0194\n",
      "Epoch 8: val_loss improved from 0.01931 to 0.01918, saving model to model\\AE_bottleneck_12_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0185 - val_loss: 0.0192\n",
      "Epoch 9/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0169\n",
      "Epoch 9: val_loss improved from 0.01918 to 0.01909, saving model to model\\AE_bottleneck_12_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0184 - val_loss: 0.0191\n",
      "Epoch 10/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0228\n",
      "Epoch 10: val_loss improved from 0.01909 to 0.01889, saving model to model\\AE_bottleneck_12_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0183 - val_loss: 0.0189\n",
      "Epoch 11/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0186\n",
      "Epoch 11: val_loss improved from 0.01889 to 0.01860, saving model to model\\AE_bottleneck_12_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0180 - val_loss: 0.0186\n",
      "Epoch 12/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0181\n",
      "Epoch 12: val_loss improved from 0.01860 to 0.01826, saving model to model\\AE_bottleneck_12_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0176 - val_loss: 0.0183\n",
      "Epoch 13/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0165\n",
      "Epoch 13: val_loss improved from 0.01826 to 0.01791, saving model to model\\AE_bottleneck_12_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0172 - val_loss: 0.0179\n",
      "Epoch 14/40\n",
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0168\n",
      "Epoch 14: val_loss improved from 0.01791 to 0.01777, saving model to model\\AE_bottleneck_12_best_model.keras\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0169 - val_loss: 0.0178\n",
      "Epoch 15/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0167\n",
      "Epoch 15: val_loss improved from 0.01777 to 0.01758, saving model to model\\AE_bottleneck_12_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0167 - val_loss: 0.0176\n",
      "Epoch 16/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0168\n",
      "Epoch 16: val_loss improved from 0.01758 to 0.01741, saving model to model\\AE_bottleneck_12_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0165 - val_loss: 0.0174\n",
      "Epoch 17/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0140\n",
      "Epoch 17: val_loss improved from 0.01741 to 0.01737, saving model to model\\AE_bottleneck_12_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0163 - val_loss: 0.0174\n",
      "Epoch 18/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0193\n",
      "Epoch 18: val_loss improved from 0.01737 to 0.01733, saving model to model\\AE_bottleneck_12_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0163 - val_loss: 0.0173\n",
      "Epoch 19/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0142\n",
      "Epoch 19: val_loss improved from 0.01733 to 0.01718, saving model to model\\AE_bottleneck_12_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0161 - val_loss: 0.0172\n",
      "Epoch 20/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0159\n",
      "Epoch 20: val_loss improved from 0.01718 to 0.01715, saving model to model\\AE_bottleneck_12_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0161 - val_loss: 0.0171\n",
      "Epoch 21/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0161\n",
      "Epoch 21: val_loss did not improve from 0.01715\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0160 - val_loss: 0.0172\n",
      "Epoch 22/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0122\n",
      "Epoch 22: val_loss improved from 0.01715 to 0.01708, saving model to model\\AE_bottleneck_12_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0159 - val_loss: 0.0171\n",
      "Epoch 23/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0136\n",
      "Epoch 23: val_loss improved from 0.01708 to 0.01703, saving model to model\\AE_bottleneck_12_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0158 - val_loss: 0.0170\n",
      "Epoch 24/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0128\n",
      "Epoch 24: val_loss improved from 0.01703 to 0.01691, saving model to model\\AE_bottleneck_12_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0157 - val_loss: 0.0169\n",
      "Epoch 25/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0162\n",
      "Epoch 25: val_loss improved from 0.01691 to 0.01681, saving model to model\\AE_bottleneck_12_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0156 - val_loss: 0.0168\n",
      "Epoch 26/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0137\n",
      "Epoch 26: val_loss improved from 0.01681 to 0.01672, saving model to model\\AE_bottleneck_12_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0154 - val_loss: 0.0167\n",
      "Epoch 27/40\n",
      "21/26 [=======================>......] - ETA: 0s - loss: 0.0154\n",
      "Epoch 27: val_loss improved from 0.01672 to 0.01664, saving model to model\\AE_bottleneck_12_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0153 - val_loss: 0.0166\n",
      "Epoch 28/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0125\n",
      "Epoch 28: val_loss improved from 0.01664 to 0.01639, saving model to model\\AE_bottleneck_12_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0150 - val_loss: 0.0164\n",
      "Epoch 29/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0171\n",
      "Epoch 29: val_loss improved from 0.01639 to 0.01630, saving model to model\\AE_bottleneck_12_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0148 - val_loss: 0.0163\n",
      "Epoch 30/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0117\n",
      "Epoch 30: val_loss improved from 0.01630 to 0.01602, saving model to model\\AE_bottleneck_12_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0145 - val_loss: 0.0160\n",
      "Epoch 31/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0128\n",
      "Epoch 31: val_loss improved from 0.01602 to 0.01593, saving model to model\\AE_bottleneck_12_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0143 - val_loss: 0.0159\n",
      "Epoch 32/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0149\n",
      "Epoch 32: val_loss improved from 0.01593 to 0.01586, saving model to model\\AE_bottleneck_12_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0141 - val_loss: 0.0159\n",
      "Epoch 33/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0111\n",
      "Epoch 33: val_loss improved from 0.01586 to 0.01568, saving model to model\\AE_bottleneck_12_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0139 - val_loss: 0.0157\n",
      "Epoch 34/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0133\n",
      "Epoch 34: val_loss did not improve from 0.01568\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0137 - val_loss: 0.0157\n",
      "Epoch 35/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0150\n",
      "Epoch 35: val_loss improved from 0.01568 to 0.01559, saving model to model\\AE_bottleneck_12_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0137 - val_loss: 0.0156\n",
      "Epoch 36/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0148\n",
      "Epoch 36: val_loss did not improve from 0.01559\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0136 - val_loss: 0.0157\n",
      "Epoch 37/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0127\n",
      "Epoch 37: val_loss improved from 0.01559 to 0.01548, saving model to model\\AE_bottleneck_12_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0135 - val_loss: 0.0155\n",
      "Epoch 38/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0112\n",
      "Epoch 38: val_loss did not improve from 0.01548\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0134 - val_loss: 0.0155\n",
      "Epoch 39/40\n",
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0133\n",
      "Epoch 39: val_loss did not improve from 0.01548\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0133 - val_loss: 0.0155\n",
      "Epoch 40/40\n",
      "20/26 [======================>.......] - ETA: 0s - loss: 0.0131\n",
      "Epoch 40: val_loss improved from 0.01548 to 0.01543, saving model to model\\AE_bottleneck_12_best_model.keras\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0133 - val_loss: 0.0154\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "LogisticRegression - Mean CV Score: 0.5486153846153846\n",
      "LogisticRegression - Mean Confusion Matrix:\n",
      "[[6.1 6.5]\n",
      " [5.2 8.1]]\n",
      "SVM - Mean CV Score: 0.5599999999999999\n",
      "SVM - Mean Confusion Matrix:\n",
      "[[8.1 4.5]\n",
      " [6.9 6.4]]\n",
      "RandomForest - Mean CV Score: 0.578923076923077\n",
      "RandomForest - Mean Confusion Matrix:\n",
      "[[7.  5.6]\n",
      " [5.3 8. ]]\n",
      "KNN - Mean CV Score: 0.5443076923076923\n",
      "KNN - Mean Confusion Matrix:\n",
      "[[7.5 5.1]\n",
      " [6.7 6.6]]\n",
      "GradientBoosting - Mean CV Score: 0.5904615384615385\n",
      "GradientBoosting - Mean Confusion Matrix:\n",
      "[[7.7 4.9]\n",
      " [5.7 7.6]]\n",
      "AdaBoost - Mean CV Score: 0.5873846153846154\n",
      "AdaBoost - Mean Confusion Matrix:\n",
      "[[7.4 5.2]\n",
      " [5.5 7.8]]\n",
      "NaiveBayes - Mean CV Score: 0.5092307692307693\n",
      "NaiveBayes - Mean Confusion Matrix:\n",
      "[[11.6  1. ]\n",
      " [11.7  1.6]]\n",
      "DecisionTree - Mean CV Score: 0.5213846153846153\n",
      "DecisionTree - Mean Confusion Matrix:\n",
      "[[5.9 6.7]\n",
      " [5.7 7.6]]\n",
      "ExtraTrees - Mean CV Score: 0.578923076923077\n",
      "ExtraTrees - Mean Confusion Matrix:\n",
      "[[7.2 5.4]\n",
      " [5.5 7.8]]\n",
      "XGBoost - Mean CV Score: 0.5518461538461539\n",
      "XGBoost - Mean Confusion Matrix:\n",
      "[[6.5 6.1]\n",
      " [5.5 7.8]]\n",
      "Size: bottleneck_12, Best classifier: GradientBoosting, CV Score: 0.5904615384615385\n",
      "Epoch 1/40\n",
      "21/26 [=======================>......] - ETA: 0s - loss: 0.0404 \n",
      "Epoch 1: val_loss improved from inf to 0.02751, saving model to model\\AE_bottleneck_16_best_model.keras\n",
      "26/26 [==============================] - 1s 13ms/step - loss: 0.0380 - val_loss: 0.0275\n",
      "Epoch 2/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0234\n",
      "Epoch 2: val_loss improved from 0.02751 to 0.02440, saving model to model\\AE_bottleneck_16_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0238 - val_loss: 0.0244\n",
      "Epoch 3/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0164\n",
      "Epoch 3: val_loss improved from 0.02440 to 0.02377, saving model to model\\AE_bottleneck_16_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0228 - val_loss: 0.0238\n",
      "Epoch 4/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0232\n",
      "Epoch 4: val_loss improved from 0.02377 to 0.02349, saving model to model\\AE_bottleneck_16_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0225 - val_loss: 0.0235\n",
      "Epoch 5/40\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0224\n",
      "Epoch 5: val_loss improved from 0.02349 to 0.02325, saving model to model\\AE_bottleneck_16_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0224 - val_loss: 0.0232\n",
      "Epoch 6/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0191\n",
      "Epoch 6: val_loss improved from 0.02325 to 0.02249, saving model to model\\AE_bottleneck_16_best_model.keras\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 0.0220 - val_loss: 0.0225\n",
      "Epoch 7/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0211\n",
      "Epoch 7: val_loss improved from 0.02249 to 0.02032, saving model to model\\AE_bottleneck_16_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0207 - val_loss: 0.0203\n",
      "Epoch 8/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0153\n",
      "Epoch 8: val_loss improved from 0.02032 to 0.01929, saving model to model\\AE_bottleneck_16_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0190 - val_loss: 0.0193\n",
      "Epoch 9/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0185\n",
      "Epoch 9: val_loss improved from 0.01929 to 0.01908, saving model to model\\AE_bottleneck_16_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0186 - val_loss: 0.0191\n",
      "Epoch 10/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0241\n",
      "Epoch 10: val_loss improved from 0.01908 to 0.01882, saving model to model\\AE_bottleneck_16_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0182 - val_loss: 0.0188\n",
      "Epoch 11/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0181\n",
      "Epoch 11: val_loss improved from 0.01882 to 0.01856, saving model to model\\AE_bottleneck_16_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0179 - val_loss: 0.0186\n",
      "Epoch 12/40\n",
      "13/26 [==============>...............] - ETA: 0s - loss: 0.0172\n",
      "Epoch 12: val_loss improved from 0.01856 to 0.01823, saving model to model\\AE_bottleneck_16_best_model.keras\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0175 - val_loss: 0.0182\n",
      "Epoch 13/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0169\n",
      "Epoch 13: val_loss improved from 0.01823 to 0.01793, saving model to model\\AE_bottleneck_16_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0169 - val_loss: 0.0179\n",
      "Epoch 14/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0203\n",
      "Epoch 14: val_loss improved from 0.01793 to 0.01772, saving model to model\\AE_bottleneck_16_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0166 - val_loss: 0.0177\n",
      "Epoch 15/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0165\n",
      "Epoch 15: val_loss improved from 0.01772 to 0.01749, saving model to model\\AE_bottleneck_16_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0163 - val_loss: 0.0175\n",
      "Epoch 16/40\n",
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0161\n",
      "Epoch 16: val_loss improved from 0.01749 to 0.01733, saving model to model\\AE_bottleneck_16_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0161 - val_loss: 0.0173\n",
      "Epoch 17/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0165\n",
      "Epoch 17: val_loss improved from 0.01733 to 0.01725, saving model to model\\AE_bottleneck_16_best_model.keras\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 0.0158 - val_loss: 0.0173\n",
      "Epoch 18/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0152\n",
      "Epoch 18: val_loss improved from 0.01725 to 0.01695, saving model to model\\AE_bottleneck_16_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0156 - val_loss: 0.0170\n",
      "Epoch 19/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0186\n",
      "Epoch 19: val_loss improved from 0.01695 to 0.01671, saving model to model\\AE_bottleneck_16_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0153 - val_loss: 0.0167\n",
      "Epoch 20/40\n",
      "21/26 [=======================>......] - ETA: 0s - loss: 0.0153\n",
      "Epoch 20: val_loss improved from 0.01671 to 0.01669, saving model to model\\AE_bottleneck_16_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0151 - val_loss: 0.0167\n",
      "Epoch 21/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0139\n",
      "Epoch 21: val_loss improved from 0.01669 to 0.01649, saving model to model\\AE_bottleneck_16_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0149 - val_loss: 0.0165\n",
      "Epoch 22/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0150\n",
      "Epoch 22: val_loss improved from 0.01649 to 0.01641, saving model to model\\AE_bottleneck_16_best_model.keras\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 0.0148 - val_loss: 0.0164\n",
      "Epoch 23/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0137\n",
      "Epoch 23: val_loss improved from 0.01641 to 0.01630, saving model to model\\AE_bottleneck_16_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0147 - val_loss: 0.0163\n",
      "Epoch 24/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0149\n",
      "Epoch 24: val_loss did not improve from 0.01630\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0146 - val_loss: 0.0163\n",
      "Epoch 25/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0146\n",
      "Epoch 25: val_loss improved from 0.01630 to 0.01629, saving model to model\\AE_bottleneck_16_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0146 - val_loss: 0.0163\n",
      "Epoch 26/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0144\n",
      "Epoch 26: val_loss improved from 0.01629 to 0.01617, saving model to model\\AE_bottleneck_16_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0145 - val_loss: 0.0162\n",
      "Epoch 27/40\n",
      "20/26 [======================>.......] - ETA: 0s - loss: 0.0143\n",
      "Epoch 27: val_loss did not improve from 0.01617\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0144 - val_loss: 0.0162\n",
      "Epoch 28/40\n",
      "12/26 [============>.................] - ETA: 0s - loss: 0.0135\n",
      "Epoch 28: val_loss did not improve from 0.01617\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0143 - val_loss: 0.0162\n",
      "Epoch 29/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0144\n",
      "Epoch 29: val_loss improved from 0.01617 to 0.01609, saving model to model\\AE_bottleneck_16_best_model.keras\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0143 - val_loss: 0.0161\n",
      "Epoch 30/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0144\n",
      "Epoch 30: val_loss did not improve from 0.01609\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0143 - val_loss: 0.0162\n",
      "Epoch 31/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0140\n",
      "Epoch 31: val_loss did not improve from 0.01609\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0142 - val_loss: 0.0161\n",
      "Epoch 32/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0141\n",
      "Epoch 32: val_loss improved from 0.01609 to 0.01608, saving model to model\\AE_bottleneck_16_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0141 - val_loss: 0.0161\n",
      "Epoch 33/40\n",
      "20/26 [======================>.......] - ETA: 0s - loss: 0.0139\n",
      "Epoch 33: val_loss did not improve from 0.01608\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0141 - val_loss: 0.0161\n",
      "Epoch 34/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0156\n",
      "Epoch 34: val_loss improved from 0.01608 to 0.01606, saving model to model\\AE_bottleneck_16_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0140 - val_loss: 0.0161\n",
      "Epoch 35/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0155\n",
      "Epoch 35: val_loss improved from 0.01606 to 0.01599, saving model to model\\AE_bottleneck_16_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0139 - val_loss: 0.0160\n",
      "Epoch 36/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0188\n",
      "Epoch 36: val_loss did not improve from 0.01599\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0140 - val_loss: 0.0160\n",
      "Epoch 37/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0135\n",
      "Epoch 37: val_loss did not improve from 0.01599\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0139 - val_loss: 0.0162\n",
      "Epoch 38/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0138\n",
      "Epoch 38: val_loss improved from 0.01599 to 0.01595, saving model to model\\AE_bottleneck_16_best_model.keras\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0139 - val_loss: 0.0160\n",
      "Epoch 39/40\n",
      "20/26 [======================>.......] - ETA: 0s - loss: 0.0141\n",
      "Epoch 39: val_loss improved from 0.01595 to 0.01587, saving model to model\\AE_bottleneck_16_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0138 - val_loss: 0.0159\n",
      "Epoch 40/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0160\n",
      "Epoch 40: val_loss improved from 0.01587 to 0.01583, saving model to model\\AE_bottleneck_16_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0137 - val_loss: 0.0158\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "LogisticRegression - Mean CV Score: 0.5212307692307692\n",
      "LogisticRegression - Mean Confusion Matrix:\n",
      "[[5.6 7. ]\n",
      " [5.4 7.9]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM - Mean CV Score: 0.5524615384615383\n",
      "SVM - Mean Confusion Matrix:\n",
      "[[7.9 4.7]\n",
      " [6.9 6.4]]\n",
      "RandomForest - Mean CV Score: 0.5638461538461538\n",
      "RandomForest - Mean Confusion Matrix:\n",
      "[[6.8 5.8]\n",
      " [5.5 7.8]]\n",
      "KNN - Mean CV Score: 0.5484615384615383\n",
      "KNN - Mean Confusion Matrix:\n",
      "[[7.6 5. ]\n",
      " [6.7 6.6]]\n",
      "GradientBoosting - Mean CV Score: 0.576\n",
      "GradientBoosting - Mean Confusion Matrix:\n",
      "[[7.3 5.3]\n",
      " [5.7 7.6]]\n",
      "AdaBoost - Mean CV Score: 0.5984615384615385\n",
      "AdaBoost - Mean Confusion Matrix:\n",
      "[[7.7 4.9]\n",
      " [5.5 7.8]]\n",
      "NaiveBayes - Mean CV Score: 0.5444615384615383\n",
      "NaiveBayes - Mean Confusion Matrix:\n",
      "[[10.8  1.8]\n",
      " [10.   3.3]]\n",
      "DecisionTree - Mean CV Score: 0.5216923076923077\n",
      "DecisionTree - Mean Confusion Matrix:\n",
      "[[6.2 6.4]\n",
      " [6.  7.3]]\n",
      "ExtraTrees - Mean CV Score: 0.6138461538461538\n",
      "ExtraTrees - Mean Confusion Matrix:\n",
      "[[7.7 4.9]\n",
      " [5.1 8.2]]\n",
      "XGBoost - Mean CV Score: 0.5446153846153845\n",
      "XGBoost - Mean Confusion Matrix:\n",
      "[[6.3 6.3]\n",
      " [5.5 7.8]]\n",
      "Size: bottleneck_16, Best classifier: ExtraTrees, CV Score: 0.6138461538461538\n",
      "Epoch 1/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0376 \n",
      "Epoch 1: val_loss improved from inf to 0.02661, saving model to model\\AE_bottleneck_20_best_model.keras\n",
      "26/26 [==============================] - 2s 15ms/step - loss: 0.0366 - val_loss: 0.0266\n",
      "Epoch 2/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0238\n",
      "Epoch 2: val_loss improved from 0.02661 to 0.02427, saving model to model\\AE_bottleneck_20_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0236 - val_loss: 0.0243\n",
      "Epoch 3/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0226\n",
      "Epoch 3: val_loss improved from 0.02427 to 0.02368, saving model to model\\AE_bottleneck_20_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0227 - val_loss: 0.0237\n",
      "Epoch 4/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0218\n",
      "Epoch 4: val_loss improved from 0.02368 to 0.02311, saving model to model\\AE_bottleneck_20_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0223 - val_loss: 0.0231\n",
      "Epoch 5/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0187\n",
      "Epoch 5: val_loss improved from 0.02311 to 0.02193, saving model to model\\AE_bottleneck_20_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0216 - val_loss: 0.0219\n",
      "Epoch 6/40\n",
      "12/26 [============>.................] - ETA: 0s - loss: 0.0200\n",
      "Epoch 6: val_loss improved from 0.02193 to 0.02060, saving model to model\\AE_bottleneck_20_best_model.keras\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0201 - val_loss: 0.0206\n",
      "Epoch 7/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0242\n",
      "Epoch 7: val_loss improved from 0.02060 to 0.01989, saving model to model\\AE_bottleneck_20_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0191 - val_loss: 0.0199\n",
      "Epoch 8/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0177\n",
      "Epoch 8: val_loss improved from 0.01989 to 0.01894, saving model to model\\AE_bottleneck_20_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0184 - val_loss: 0.0189\n",
      "Epoch 9/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0177\n",
      "Epoch 9: val_loss improved from 0.01894 to 0.01852, saving model to model\\AE_bottleneck_20_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0177 - val_loss: 0.0185\n",
      "Epoch 10/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0154\n",
      "Epoch 10: val_loss improved from 0.01852 to 0.01809, saving model to model\\AE_bottleneck_20_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0172 - val_loss: 0.0181\n",
      "Epoch 11/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0157\n",
      "Epoch 11: val_loss improved from 0.01809 to 0.01783, saving model to model\\AE_bottleneck_20_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0168 - val_loss: 0.0178\n",
      "Epoch 12/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0167\n",
      "Epoch 12: val_loss improved from 0.01783 to 0.01765, saving model to model\\AE_bottleneck_20_best_model.keras\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 0.0167 - val_loss: 0.0177\n",
      "Epoch 13/40\n",
      "19/26 [====================>.........] - ETA: 0s - loss: 0.0160\n",
      "Epoch 13: val_loss improved from 0.01765 to 0.01751, saving model to model\\AE_bottleneck_20_best_model.keras\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0164 - val_loss: 0.0175\n",
      "Epoch 14/40\n",
      "20/26 [======================>.......] - ETA: 0s - loss: 0.0162\n",
      "Epoch 14: val_loss improved from 0.01751 to 0.01734, saving model to model\\AE_bottleneck_20_best_model.keras\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0163 - val_loss: 0.0173\n",
      "Epoch 15/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0163\n",
      "Epoch 15: val_loss did not improve from 0.01734\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0162 - val_loss: 0.0174\n",
      "Epoch 16/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0147\n",
      "Epoch 16: val_loss improved from 0.01734 to 0.01717, saving model to model\\AE_bottleneck_20_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0161 - val_loss: 0.0172\n",
      "Epoch 17/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0174\n",
      "Epoch 17: val_loss improved from 0.01717 to 0.01710, saving model to model\\AE_bottleneck_20_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0158 - val_loss: 0.0171\n",
      "Epoch 18/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0174\n",
      "Epoch 18: val_loss improved from 0.01710 to 0.01698, saving model to model\\AE_bottleneck_20_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0157 - val_loss: 0.0170\n",
      "Epoch 19/40\n",
      "14/26 [===============>..............] - ETA: 0s - loss: 0.0155\n",
      "Epoch 19: val_loss improved from 0.01698 to 0.01672, saving model to model\\AE_bottleneck_20_best_model.keras\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0155 - val_loss: 0.0167\n",
      "Epoch 20/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0128\n",
      "Epoch 20: val_loss improved from 0.01672 to 0.01642, saving model to model\\AE_bottleneck_20_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0151 - val_loss: 0.0164\n",
      "Epoch 21/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0136\n",
      "Epoch 21: val_loss improved from 0.01642 to 0.01620, saving model to model\\AE_bottleneck_20_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0148 - val_loss: 0.0162\n",
      "Epoch 22/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0117\n",
      "Epoch 22: val_loss improved from 0.01620 to 0.01604, saving model to model\\AE_bottleneck_20_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0145 - val_loss: 0.0160\n",
      "Epoch 23/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0119\n",
      "Epoch 23: val_loss improved from 0.01604 to 0.01586, saving model to model\\AE_bottleneck_20_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0143 - val_loss: 0.0159\n",
      "Epoch 24/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0135\n",
      "Epoch 24: val_loss did not improve from 0.01586\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0142 - val_loss: 0.0159\n",
      "Epoch 25/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0144\n",
      "Epoch 25: val_loss improved from 0.01586 to 0.01570, saving model to model\\AE_bottleneck_20_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0140 - val_loss: 0.0157\n",
      "Epoch 26/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0132\n",
      "Epoch 26: val_loss did not improve from 0.01570\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0139 - val_loss: 0.0158\n",
      "Epoch 27/40\n",
      "15/26 [================>.............] - ETA: 0s - loss: 0.0140\n",
      "Epoch 27: val_loss improved from 0.01570 to 0.01568, saving model to model\\AE_bottleneck_20_best_model.keras\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0138 - val_loss: 0.0157\n",
      "Epoch 28/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0136\n",
      "Epoch 28: val_loss improved from 0.01568 to 0.01566, saving model to model\\AE_bottleneck_20_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0137 - val_loss: 0.0157\n",
      "Epoch 29/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0133\n",
      "Epoch 29: val_loss improved from 0.01566 to 0.01556, saving model to model\\AE_bottleneck_20_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0136 - val_loss: 0.0156\n",
      "Epoch 30/40\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0134\n",
      "Epoch 30: val_loss improved from 0.01556 to 0.01555, saving model to model\\AE_bottleneck_20_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0134 - val_loss: 0.0156\n",
      "Epoch 31/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0146\n",
      "Epoch 31: val_loss improved from 0.01555 to 0.01542, saving model to model\\AE_bottleneck_20_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0134 - val_loss: 0.0154\n",
      "Epoch 32/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0128\n",
      "Epoch 32: val_loss did not improve from 0.01542\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0133 - val_loss: 0.0155\n",
      "Epoch 33/40\n",
      "13/26 [==============>...............] - ETA: 0s - loss: 0.0131\n",
      "Epoch 33: val_loss did not improve from 0.01542\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0132 - val_loss: 0.0156\n",
      "Epoch 34/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0133\n",
      "Epoch 34: val_loss improved from 0.01542 to 0.01535, saving model to model\\AE_bottleneck_20_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0132 - val_loss: 0.0154\n",
      "Epoch 35/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0133\n",
      "Epoch 35: val_loss did not improve from 0.01535\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0131 - val_loss: 0.0154\n",
      "Epoch 36/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0133\n",
      "Epoch 36: val_loss improved from 0.01535 to 0.01535, saving model to model\\AE_bottleneck_20_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0130 - val_loss: 0.0153\n",
      "Epoch 37/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0126\n",
      "Epoch 37: val_loss improved from 0.01535 to 0.01524, saving model to model\\AE_bottleneck_20_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0129 - val_loss: 0.0152\n",
      "Epoch 38/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0154\n",
      "Epoch 38: val_loss improved from 0.01524 to 0.01522, saving model to model\\AE_bottleneck_20_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0128 - val_loss: 0.0152\n",
      "Epoch 39/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0105\n",
      "Epoch 39: val_loss improved from 0.01522 to 0.01516, saving model to model\\AE_bottleneck_20_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0128 - val_loss: 0.0152\n",
      "Epoch 40/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0123\n",
      "Epoch 40: val_loss did not improve from 0.01516\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0127 - val_loss: 0.0152\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "LogisticRegression - Mean CV Score: 0.536923076923077\n",
      "LogisticRegression - Mean Confusion Matrix:\n",
      "[[6.1 6.5]\n",
      " [5.5 7.8]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM - Mean CV Score: 0.5716923076923077\n",
      "SVM - Mean Confusion Matrix:\n",
      "[[7.4 5.2]\n",
      " [5.9 7.4]]\n",
      "RandomForest - Mean CV Score: 0.6333846153846154\n",
      "RandomForest - Mean Confusion Matrix:\n",
      "[[7.7 4.9]\n",
      " [4.6 8.7]]\n",
      "KNN - Mean CV Score: 0.5907692307692307\n",
      "KNN - Mean Confusion Matrix:\n",
      "[[8.1 4.5]\n",
      " [6.1 7.2]]\n",
      "GradientBoosting - Mean CV Score: 0.6026153846153846\n",
      "GradientBoosting - Mean Confusion Matrix:\n",
      "[[7.4 5.2]\n",
      " [5.1 8.2]]\n",
      "AdaBoost - Mean CV Score: 0.5869230769230769\n",
      "AdaBoost - Mean Confusion Matrix:\n",
      "[[7.  5.6]\n",
      " [5.1 8.2]]\n",
      "NaiveBayes - Mean CV Score: 0.4864615384615384\n",
      "NaiveBayes - Mean Confusion Matrix:\n",
      "[[10.5  2.1]\n",
      " [11.2  2.1]]\n",
      "DecisionTree - Mean CV Score: 0.5524615384615384\n",
      "DecisionTree - Mean Confusion Matrix:\n",
      "[[7.2 5.4]\n",
      " [6.2 7.1]]\n",
      "ExtraTrees - Mean CV Score: 0.6258461538461539\n",
      "ExtraTrees - Mean Confusion Matrix:\n",
      "[[7.9 4.7]\n",
      " [5.  8.3]]\n",
      "XGBoost - Mean CV Score: 0.6298461538461539\n",
      "XGBoost - Mean Confusion Matrix:\n",
      "[[7.5 5.1]\n",
      " [4.5 8.8]]\n",
      "Size: bottleneck_20, Best classifier: RandomForest, CV Score: 0.6333846153846154\n",
      "Epoch 1/40\n",
      " 1/26 [>.............................] - ETA: 24s - loss: 0.0421\n",
      "Epoch 1: val_loss improved from inf to 0.02695, saving model to model\\AE_bottleneck_24_best_model.keras\n",
      "26/26 [==============================] - 1s 11ms/step - loss: 0.0373 - val_loss: 0.0269\n",
      "Epoch 2/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0271\n",
      "Epoch 2: val_loss improved from 0.02695 to 0.02399, saving model to model\\AE_bottleneck_24_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0236 - val_loss: 0.0240\n",
      "Epoch 3/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0251\n",
      "Epoch 3: val_loss improved from 0.02399 to 0.02331, saving model to model\\AE_bottleneck_24_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0225 - val_loss: 0.0233\n",
      "Epoch 4/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0178\n",
      "Epoch 4: val_loss improved from 0.02331 to 0.02205, saving model to model\\AE_bottleneck_24_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0217 - val_loss: 0.0220\n",
      "Epoch 5/40\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0199\n",
      "Epoch 5: val_loss improved from 0.02205 to 0.02012, saving model to model\\AE_bottleneck_24_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0199 - val_loss: 0.0201\n",
      "Epoch 6/40\n",
      "18/26 [===================>..........] - ETA: 0s - loss: 0.0191\n",
      "Epoch 6: val_loss improved from 0.02012 to 0.01933, saving model to model\\AE_bottleneck_24_best_model.keras\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0188 - val_loss: 0.0193\n",
      "Epoch 7/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0177\n",
      "Epoch 7: val_loss improved from 0.01933 to 0.01873, saving model to model\\AE_bottleneck_24_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0181 - val_loss: 0.0187\n",
      "Epoch 8/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0205\n",
      "Epoch 8: val_loss improved from 0.01873 to 0.01847, saving model to model\\AE_bottleneck_24_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0176 - val_loss: 0.0185\n",
      "Epoch 9/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0170\n",
      "Epoch 9: val_loss improved from 0.01847 to 0.01819, saving model to model\\AE_bottleneck_24_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0173 - val_loss: 0.0182\n",
      "Epoch 10/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0176\n",
      "Epoch 10: val_loss improved from 0.01819 to 0.01811, saving model to model\\AE_bottleneck_24_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0169 - val_loss: 0.0181\n",
      "Epoch 11/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0154\n",
      "Epoch 11: val_loss improved from 0.01811 to 0.01792, saving model to model\\AE_bottleneck_24_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0168 - val_loss: 0.0179\n",
      "Epoch 12/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0143\n",
      "Epoch 12: val_loss improved from 0.01792 to 0.01782, saving model to model\\AE_bottleneck_24_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0167 - val_loss: 0.0178\n",
      "Epoch 13/40\n",
      "18/26 [===================>..........] - ETA: 0s - loss: 0.0165\n",
      "Epoch 13: val_loss improved from 0.01782 to 0.01769, saving model to model\\AE_bottleneck_24_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0165 - val_loss: 0.0177\n",
      "Epoch 14/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0176\n",
      "Epoch 14: val_loss improved from 0.01769 to 0.01761, saving model to model\\AE_bottleneck_24_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0164 - val_loss: 0.0176\n",
      "Epoch 15/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0149\n",
      "Epoch 15: val_loss improved from 0.01761 to 0.01738, saving model to model\\AE_bottleneck_24_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0162 - val_loss: 0.0174\n",
      "Epoch 16/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0171\n",
      "Epoch 16: val_loss improved from 0.01738 to 0.01730, saving model to model\\AE_bottleneck_24_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0160 - val_loss: 0.0173\n",
      "Epoch 17/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0188\n",
      "Epoch 17: val_loss improved from 0.01730 to 0.01713, saving model to model\\AE_bottleneck_24_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0158 - val_loss: 0.0171\n",
      "Epoch 18/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0153\n",
      "Epoch 18: val_loss improved from 0.01713 to 0.01694, saving model to model\\AE_bottleneck_24_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0155 - val_loss: 0.0169\n",
      "Epoch 19/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0144\n",
      "Epoch 19: val_loss improved from 0.01694 to 0.01685, saving model to model\\AE_bottleneck_24_best_model.keras\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0153 - val_loss: 0.0169\n",
      "Epoch 20/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0150\n",
      "Epoch 20: val_loss improved from 0.01685 to 0.01681, saving model to model\\AE_bottleneck_24_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0152 - val_loss: 0.0168\n",
      "Epoch 21/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0186\n",
      "Epoch 21: val_loss improved from 0.01681 to 0.01649, saving model to model\\AE_bottleneck_24_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0149 - val_loss: 0.0165\n",
      "Epoch 22/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0139\n",
      "Epoch 22: val_loss improved from 0.01649 to 0.01639, saving model to model\\AE_bottleneck_24_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0147 - val_loss: 0.0164\n",
      "Epoch 23/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0157\n",
      "Epoch 23: val_loss improved from 0.01639 to 0.01634, saving model to model\\AE_bottleneck_24_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0145 - val_loss: 0.0163\n",
      "Epoch 24/40\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0143\n",
      "Epoch 24: val_loss improved from 0.01634 to 0.01623, saving model to model\\AE_bottleneck_24_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0143 - val_loss: 0.0162\n",
      "Epoch 25/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0145\n",
      "Epoch 25: val_loss improved from 0.01623 to 0.01597, saving model to model\\AE_bottleneck_24_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0141 - val_loss: 0.0160\n",
      "Epoch 26/40\n",
      "17/26 [==================>...........] - ETA: 0s - loss: 0.0138\n",
      "Epoch 26: val_loss improved from 0.01597 to 0.01572, saving model to model\\AE_bottleneck_24_best_model.keras\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0139 - val_loss: 0.0157\n",
      "Epoch 27/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0126\n",
      "Epoch 27: val_loss improved from 0.01572 to 0.01558, saving model to model\\AE_bottleneck_24_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0136 - val_loss: 0.0156\n",
      "Epoch 28/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0117\n",
      "Epoch 28: val_loss improved from 0.01558 to 0.01548, saving model to model\\AE_bottleneck_24_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0134 - val_loss: 0.0155\n",
      "Epoch 29/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0150\n",
      "Epoch 29: val_loss did not improve from 0.01548\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0133 - val_loss: 0.0155\n",
      "Epoch 30/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0129\n",
      "Epoch 30: val_loss improved from 0.01548 to 0.01523, saving model to model\\AE_bottleneck_24_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0132 - val_loss: 0.0152\n",
      "Epoch 31/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0133\n",
      "Epoch 31: val_loss improved from 0.01523 to 0.01515, saving model to model\\AE_bottleneck_24_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0130 - val_loss: 0.0151\n",
      "Epoch 32/40\n",
      "20/26 [======================>.......] - ETA: 0s - loss: 0.0130\n",
      "Epoch 32: val_loss improved from 0.01515 to 0.01505, saving model to model\\AE_bottleneck_24_best_model.keras\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0129 - val_loss: 0.0150\n",
      "Epoch 33/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0128\n",
      "Epoch 33: val_loss did not improve from 0.01505\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0128 - val_loss: 0.0151\n",
      "Epoch 34/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0122\n",
      "Epoch 34: val_loss did not improve from 0.01505\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0127 - val_loss: 0.0152\n",
      "Epoch 35/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0111\n",
      "Epoch 35: val_loss improved from 0.01505 to 0.01495, saving model to model\\AE_bottleneck_24_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0126 - val_loss: 0.0149\n",
      "Epoch 36/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0125\n",
      "Epoch 36: val_loss improved from 0.01495 to 0.01483, saving model to model\\AE_bottleneck_24_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0125 - val_loss: 0.0148\n",
      "Epoch 37/40\n",
      "19/26 [====================>.........] - ETA: 0s - loss: 0.0124\n",
      "Epoch 37: val_loss improved from 0.01483 to 0.01474, saving model to model\\AE_bottleneck_24_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0125 - val_loss: 0.0147\n",
      "Epoch 38/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0125\n",
      "Epoch 38: val_loss did not improve from 0.01474\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0124 - val_loss: 0.0148\n",
      "Epoch 39/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0122\n",
      "Epoch 39: val_loss improved from 0.01474 to 0.01464, saving model to model\\AE_bottleneck_24_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0123 - val_loss: 0.0146\n",
      "Epoch 40/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0155\n",
      "Epoch 40: val_loss did not improve from 0.01464\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0122 - val_loss: 0.0147\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "LogisticRegression - Mean CV Score: 0.5635384615384614\n",
      "LogisticRegression - Mean Confusion Matrix:\n",
      "[[6.3 6.3]\n",
      " [5.  8.3]]\n",
      "SVM - Mean CV Score: 0.5907692307692307\n",
      "SVM - Mean Confusion Matrix:\n",
      "[[7.3 5.3]\n",
      " [5.3 8. ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest - Mean CV Score: 0.5833846153846153\n",
      "RandomForest - Mean Confusion Matrix:\n",
      "[[6.5 6.1]\n",
      " [4.7 8.6]]\n",
      "KNN - Mean CV Score: 0.548\n",
      "KNN - Mean Confusion Matrix:\n",
      "[[7.7 4.9]\n",
      " [6.8 6.5]]\n",
      "GradientBoosting - Mean CV Score: 0.6223076923076923\n",
      "GradientBoosting - Mean Confusion Matrix:\n",
      "[[7.8 4.8]\n",
      " [5.  8.3]]\n",
      "AdaBoost - Mean CV Score: 0.5403076923076924\n",
      "AdaBoost - Mean Confusion Matrix:\n",
      "[[6.9 5.7]\n",
      " [6.2 7.1]]\n",
      "NaiveBayes - Mean CV Score: 0.5169230769230769\n",
      "NaiveBayes - Mean Confusion Matrix:\n",
      "[[12.   0.6]\n",
      " [11.9  1.4]]\n",
      "DecisionTree - Mean CV Score: 0.5372307692307693\n",
      "DecisionTree - Mean Confusion Matrix:\n",
      "[[6.4 6.2]\n",
      " [5.8 7.5]]\n",
      "ExtraTrees - Mean CV Score: 0.5830769230769229\n",
      "ExtraTrees - Mean Confusion Matrix:\n",
      "[[7.2 5.4]\n",
      " [5.4 7.9]]\n",
      "XGBoost - Mean CV Score: 0.5758461538461538\n",
      "XGBoost - Mean Confusion Matrix:\n",
      "[[6.7 5.9]\n",
      " [5.1 8.2]]\n",
      "Size: bottleneck_24, Best classifier: GradientBoosting, CV Score: 0.6223076923076923\n",
      "Epoch 1/40\n",
      " 1/26 [>.............................] - ETA: 23s - loss: 0.0539\n",
      "Epoch 1: val_loss improved from inf to 0.02688, saving model to model\\AE_bottleneck_28_best_model.keras\n",
      "26/26 [==============================] - 1s 10ms/step - loss: 0.0356 - val_loss: 0.0269\n",
      "Epoch 2/40\n",
      "20/26 [======================>.......] - ETA: 0s - loss: 0.0241\n",
      "Epoch 2: val_loss improved from 0.02688 to 0.02418, saving model to model\\AE_bottleneck_28_best_model.keras\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0236 - val_loss: 0.0242\n",
      "Epoch 3/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0296\n",
      "Epoch 3: val_loss improved from 0.02418 to 0.02366, saving model to model\\AE_bottleneck_28_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0227 - val_loss: 0.0237\n",
      "Epoch 4/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0214\n",
      "Epoch 4: val_loss improved from 0.02366 to 0.02284, saving model to model\\AE_bottleneck_28_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0222 - val_loss: 0.0228\n",
      "Epoch 5/40\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0211\n",
      "Epoch 5: val_loss improved from 0.02284 to 0.02099, saving model to model\\AE_bottleneck_28_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0211 - val_loss: 0.0210\n",
      "Epoch 6/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0171\n",
      "Epoch 6: val_loss improved from 0.02099 to 0.01957, saving model to model\\AE_bottleneck_28_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0193 - val_loss: 0.0196\n",
      "Epoch 7/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0207\n",
      "Epoch 7: val_loss improved from 0.01957 to 0.01899, saving model to model\\AE_bottleneck_28_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0185 - val_loss: 0.0190\n",
      "Epoch 8/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0181\n",
      "Epoch 8: val_loss improved from 0.01899 to 0.01852, saving model to model\\AE_bottleneck_28_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0180 - val_loss: 0.0185\n",
      "Epoch 9/40\n",
      " 9/26 [=========>....................] - ETA: 0s - loss: 0.0163\n",
      "Epoch 9: val_loss improved from 0.01852 to 0.01812, saving model to model\\AE_bottleneck_28_best_model.keras\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0173 - val_loss: 0.0181\n",
      "Epoch 10/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0129\n",
      "Epoch 10: val_loss improved from 0.01812 to 0.01798, saving model to model\\AE_bottleneck_28_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0169 - val_loss: 0.0180\n",
      "Epoch 11/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0157\n",
      "Epoch 11: val_loss improved from 0.01798 to 0.01776, saving model to model\\AE_bottleneck_28_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0167 - val_loss: 0.0178\n",
      "Epoch 12/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0130\n",
      "Epoch 12: val_loss improved from 0.01776 to 0.01753, saving model to model\\AE_bottleneck_28_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0164 - val_loss: 0.0175\n",
      "Epoch 13/40\n",
      "19/26 [====================>.........] - ETA: 0s - loss: 0.0165\n",
      "Epoch 13: val_loss improved from 0.01753 to 0.01725, saving model to model\\AE_bottleneck_28_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0161 - val_loss: 0.0173\n",
      "Epoch 14/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0157\n",
      "Epoch 14: val_loss improved from 0.01725 to 0.01725, saving model to model\\AE_bottleneck_28_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0158 - val_loss: 0.0172\n",
      "Epoch 15/40\n",
      "15/26 [================>.............] - ETA: 0s - loss: 0.0159\n",
      "Epoch 15: val_loss improved from 0.01725 to 0.01702, saving model to model\\AE_bottleneck_28_best_model.keras\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0157 - val_loss: 0.0170\n",
      "Epoch 16/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0131\n",
      "Epoch 16: val_loss improved from 0.01702 to 0.01691, saving model to model\\AE_bottleneck_28_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0154 - val_loss: 0.0169\n",
      "Epoch 17/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0172\n",
      "Epoch 17: val_loss improved from 0.01691 to 0.01683, saving model to model\\AE_bottleneck_28_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0153 - val_loss: 0.0168\n",
      "Epoch 18/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0155\n",
      "Epoch 18: val_loss improved from 0.01683 to 0.01671, saving model to model\\AE_bottleneck_28_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0152 - val_loss: 0.0167\n",
      "Epoch 19/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0171\n",
      "Epoch 19: val_loss improved from 0.01671 to 0.01663, saving model to model\\AE_bottleneck_28_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0151 - val_loss: 0.0166\n",
      "Epoch 20/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0182\n",
      "Epoch 20: val_loss improved from 0.01663 to 0.01659, saving model to model\\AE_bottleneck_28_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0149 - val_loss: 0.0166\n",
      "Epoch 21/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0173\n",
      "Epoch 21: val_loss improved from 0.01659 to 0.01649, saving model to model\\AE_bottleneck_28_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0149 - val_loss: 0.0165\n",
      "Epoch 22/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0135\n",
      "Epoch 22: val_loss improved from 0.01649 to 0.01645, saving model to model\\AE_bottleneck_28_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0147 - val_loss: 0.0165\n",
      "Epoch 23/40\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0146\n",
      "Epoch 23: val_loss improved from 0.01645 to 0.01624, saving model to model\\AE_bottleneck_28_best_model.keras\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0146 - val_loss: 0.0162\n",
      "Epoch 24/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0132\n",
      "Epoch 24: val_loss improved from 0.01624 to 0.01605, saving model to model\\AE_bottleneck_28_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0144 - val_loss: 0.0161\n",
      "Epoch 25/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0136\n",
      "Epoch 25: val_loss improved from 0.01605 to 0.01578, saving model to model\\AE_bottleneck_28_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0142 - val_loss: 0.0158\n",
      "Epoch 26/40\n",
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0140\n",
      "Epoch 26: val_loss improved from 0.01578 to 0.01545, saving model to model\\AE_bottleneck_28_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0139 - val_loss: 0.0155\n",
      "Epoch 27/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0143\n",
      "Epoch 27: val_loss improved from 0.01545 to 0.01537, saving model to model\\AE_bottleneck_28_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0137 - val_loss: 0.0154\n",
      "Epoch 28/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0144\n",
      "Epoch 28: val_loss improved from 0.01537 to 0.01521, saving model to model\\AE_bottleneck_28_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0134 - val_loss: 0.0152\n",
      "Epoch 29/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0129\n",
      "Epoch 29: val_loss improved from 0.01521 to 0.01503, saving model to model\\AE_bottleneck_28_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0132 - val_loss: 0.0150\n",
      "Epoch 30/40\n",
      "12/26 [============>.................] - ETA: 0s - loss: 0.0127\n",
      "Epoch 30: val_loss did not improve from 0.01503\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0131 - val_loss: 0.0153\n",
      "Epoch 31/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0134\n",
      "Epoch 31: val_loss did not improve from 0.01503\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0131 - val_loss: 0.0150\n",
      "Epoch 32/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0133\n",
      "Epoch 32: val_loss improved from 0.01503 to 0.01499, saving model to model\\AE_bottleneck_28_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0129 - val_loss: 0.0150\n",
      "Epoch 33/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0150\n",
      "Epoch 33: val_loss improved from 0.01499 to 0.01498, saving model to model\\AE_bottleneck_28_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0129 - val_loss: 0.0150\n",
      "Epoch 34/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0143\n",
      "Epoch 34: val_loss did not improve from 0.01498\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0128 - val_loss: 0.0151\n",
      "Epoch 35/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0117\n",
      "Epoch 35: val_loss improved from 0.01498 to 0.01491, saving model to model\\AE_bottleneck_28_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0127 - val_loss: 0.0149\n",
      "Epoch 36/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0100\n",
      "Epoch 36: val_loss did not improve from 0.01491\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0126 - val_loss: 0.0149\n",
      "Epoch 37/40\n",
      "12/26 [============>.................] - ETA: 0s - loss: 0.0121\n",
      "Epoch 37: val_loss improved from 0.01491 to 0.01491, saving model to model\\AE_bottleneck_28_best_model.keras\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0125 - val_loss: 0.0149\n",
      "Epoch 38/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0114\n",
      "Epoch 38: val_loss did not improve from 0.01491\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0125 - val_loss: 0.0150\n",
      "Epoch 39/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0109\n",
      "Epoch 39: val_loss improved from 0.01491 to 0.01488, saving model to model\\AE_bottleneck_28_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0124 - val_loss: 0.0149\n",
      "Epoch 40/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0120\n",
      "Epoch 40: val_loss did not improve from 0.01488\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0123 - val_loss: 0.0149\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "LogisticRegression - Mean CV Score: 0.5326153846153845\n",
      "LogisticRegression - Mean Confusion Matrix:\n",
      "[[6.1 6.5]\n",
      " [5.6 7.7]]\n",
      "SVM - Mean CV Score: 0.5752307692307692\n",
      "SVM - Mean Confusion Matrix:\n",
      "[[6.7 5.9]\n",
      " [5.1 8.2]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest - Mean CV Score: 0.5950769230769231\n",
      "RandomForest - Mean Confusion Matrix:\n",
      "[[7.3 5.3]\n",
      " [5.2 8.1]]\n",
      "KNN - Mean CV Score: 0.5563076923076923\n",
      "KNN - Mean Confusion Matrix:\n",
      "[[7.7 4.9]\n",
      " [6.6 6.7]]\n",
      "GradientBoosting - Mean CV Score: 0.5327692307692307\n",
      "GradientBoosting - Mean Confusion Matrix:\n",
      "[[6.4 6.2]\n",
      " [5.9 7.4]]\n",
      "AdaBoost - Mean CV Score: 0.5641538461538461\n",
      "AdaBoost - Mean Confusion Matrix:\n",
      "[[7.  5.6]\n",
      " [5.7 7.6]]\n",
      "NaiveBayes - Mean CV Score: 0.5133846153846153\n",
      "NaiveBayes - Mean Confusion Matrix:\n",
      "[[9.9 2.7]\n",
      " [9.9 3.4]]\n",
      "DecisionTree - Mean CV Score: 0.5215384615384615\n",
      "DecisionTree - Mean Confusion Matrix:\n",
      "[[6.5 6.1]\n",
      " [6.3 7. ]]\n",
      "ExtraTrees - Mean CV Score: 0.5949230769230768\n",
      "ExtraTrees - Mean Confusion Matrix:\n",
      "[[7.6 5. ]\n",
      " [5.5 7.8]]\n",
      "XGBoost - Mean CV Score: 0.5750769230769232\n",
      "XGBoost - Mean Confusion Matrix:\n",
      "[[6.7 5.9]\n",
      " [5.1 8.2]]\n",
      "Size: bottleneck_28, Best classifier: RandomForest, CV Score: 0.5950769230769231\n",
      "Epoch 1/40\n",
      " 1/26 [>.............................] - ETA: 24s - loss: 0.0462\n",
      "Epoch 1: val_loss improved from inf to 0.02650, saving model to model\\AE_bottleneck_32_best_model.keras\n",
      "26/26 [==============================] - 1s 11ms/step - loss: 0.0363 - val_loss: 0.0265\n",
      "Epoch 2/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0206\n",
      "Epoch 2: val_loss improved from 0.02650 to 0.02391, saving model to model\\AE_bottleneck_32_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0236 - val_loss: 0.0239\n",
      "Epoch 3/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0218\n",
      "Epoch 3: val_loss improved from 0.02391 to 0.02286, saving model to model\\AE_bottleneck_32_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0223 - val_loss: 0.0229\n",
      "Epoch 4/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0183\n",
      "Epoch 4: val_loss improved from 0.02286 to 0.02103, saving model to model\\AE_bottleneck_32_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0210 - val_loss: 0.0210\n",
      "Epoch 5/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0182\n",
      "Epoch 5: val_loss improved from 0.02103 to 0.01999, saving model to model\\AE_bottleneck_32_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0195 - val_loss: 0.0200\n",
      "Epoch 6/40\n",
      "12/26 [============>.................] - ETA: 0s - loss: 0.0187\n",
      "Epoch 6: val_loss improved from 0.01999 to 0.01953, saving model to model\\AE_bottleneck_32_best_model.keras\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0188 - val_loss: 0.0195\n",
      "Epoch 7/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0181\n",
      "Epoch 7: val_loss improved from 0.01953 to 0.01935, saving model to model\\AE_bottleneck_32_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0187 - val_loss: 0.0193\n",
      "Epoch 8/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0178\n",
      "Epoch 8: val_loss improved from 0.01935 to 0.01906, saving model to model\\AE_bottleneck_32_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0185 - val_loss: 0.0191\n",
      "Epoch 9/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0168\n",
      "Epoch 9: val_loss improved from 0.01906 to 0.01860, saving model to model\\AE_bottleneck_32_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0181 - val_loss: 0.0186\n",
      "Epoch 10/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0215\n",
      "Epoch 10: val_loss improved from 0.01860 to 0.01825, saving model to model\\AE_bottleneck_32_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0175 - val_loss: 0.0183\n",
      "Epoch 11/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0223\n",
      "Epoch 11: val_loss improved from 0.01825 to 0.01797, saving model to model\\AE_bottleneck_32_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0170 - val_loss: 0.0180\n",
      "Epoch 12/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0170\n",
      "Epoch 12: val_loss improved from 0.01797 to 0.01784, saving model to model\\AE_bottleneck_32_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0168 - val_loss: 0.0178\n",
      "Epoch 13/40\n",
      " 9/26 [=========>....................] - ETA: 0s - loss: 0.0170\n",
      "Epoch 13: val_loss improved from 0.01784 to 0.01770, saving model to model\\AE_bottleneck_32_best_model.keras\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0165 - val_loss: 0.0177\n",
      "Epoch 14/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0174\n",
      "Epoch 14: val_loss improved from 0.01770 to 0.01750, saving model to model\\AE_bottleneck_32_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0163 - val_loss: 0.0175\n",
      "Epoch 15/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0147\n",
      "Epoch 15: val_loss improved from 0.01750 to 0.01721, saving model to model\\AE_bottleneck_32_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0160 - val_loss: 0.0172\n",
      "Epoch 16/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0173\n",
      "Epoch 16: val_loss improved from 0.01721 to 0.01697, saving model to model\\AE_bottleneck_32_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0157 - val_loss: 0.0170\n",
      "Epoch 17/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0162\n",
      "Epoch 17: val_loss improved from 0.01697 to 0.01667, saving model to model\\AE_bottleneck_32_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0153 - val_loss: 0.0167\n",
      "Epoch 18/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0130\n",
      "Epoch 18: val_loss improved from 0.01667 to 0.01635, saving model to model\\AE_bottleneck_32_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0149 - val_loss: 0.0163\n",
      "Epoch 19/40\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0146\n",
      "Epoch 19: val_loss improved from 0.01635 to 0.01597, saving model to model\\AE_bottleneck_32_best_model.keras\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0146 - val_loss: 0.0160\n",
      "Epoch 20/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0159\n",
      "Epoch 20: val_loss improved from 0.01597 to 0.01585, saving model to model\\AE_bottleneck_32_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0144 - val_loss: 0.0158\n",
      "Epoch 21/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0136\n",
      "Epoch 21: val_loss improved from 0.01585 to 0.01569, saving model to model\\AE_bottleneck_32_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0141 - val_loss: 0.0157\n",
      "Epoch 22/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0140\n",
      "Epoch 22: val_loss improved from 0.01569 to 0.01559, saving model to model\\AE_bottleneck_32_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0138 - val_loss: 0.0156\n",
      "Epoch 23/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0147\n",
      "Epoch 23: val_loss improved from 0.01559 to 0.01543, saving model to model\\AE_bottleneck_32_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0137 - val_loss: 0.0154\n",
      "Epoch 24/40\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0136\n",
      "Epoch 24: val_loss improved from 0.01543 to 0.01542, saving model to model\\AE_bottleneck_32_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0136 - val_loss: 0.0154\n",
      "Epoch 25/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0134\n",
      "Epoch 25: val_loss improved from 0.01542 to 0.01530, saving model to model\\AE_bottleneck_32_best_model.keras\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 0.0134 - val_loss: 0.0153\n",
      "Epoch 26/40\n",
      "20/26 [======================>.......] - ETA: 0s - loss: 0.0135\n",
      "Epoch 26: val_loss did not improve from 0.01530\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0133 - val_loss: 0.0154\n",
      "Epoch 27/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0140\n",
      "Epoch 27: val_loss did not improve from 0.01530\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0133 - val_loss: 0.0155\n",
      "Epoch 28/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0104\n",
      "Epoch 28: val_loss improved from 0.01530 to 0.01514, saving model to model\\AE_bottleneck_32_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0131 - val_loss: 0.0151\n",
      "Epoch 29/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0121\n",
      "Epoch 29: val_loss improved from 0.01514 to 0.01510, saving model to model\\AE_bottleneck_32_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0130 - val_loss: 0.0151\n",
      "Epoch 30/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0137\n",
      "Epoch 30: val_loss improved from 0.01510 to 0.01505, saving model to model\\AE_bottleneck_32_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0129 - val_loss: 0.0151\n",
      "Epoch 31/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0144\n",
      "Epoch 31: val_loss improved from 0.01505 to 0.01495, saving model to model\\AE_bottleneck_32_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0127 - val_loss: 0.0149\n",
      "Epoch 32/40\n",
      "16/26 [=================>............] - ETA: 0s - loss: 0.0130\n",
      "Epoch 32: val_loss improved from 0.01495 to 0.01483, saving model to model\\AE_bottleneck_32_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0127 - val_loss: 0.0148\n",
      "Epoch 33/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0127\n",
      "Epoch 33: val_loss did not improve from 0.01483\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0125 - val_loss: 0.0149\n",
      "Epoch 34/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0147\n",
      "Epoch 34: val_loss did not improve from 0.01483\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0125 - val_loss: 0.0149\n",
      "Epoch 35/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0151\n",
      "Epoch 35: val_loss improved from 0.01483 to 0.01470, saving model to model\\AE_bottleneck_32_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0125 - val_loss: 0.0147\n",
      "Epoch 36/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0092\n",
      "Epoch 36: val_loss improved from 0.01470 to 0.01464, saving model to model\\AE_bottleneck_32_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0123 - val_loss: 0.0146\n",
      "Epoch 37/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0112\n",
      "Epoch 37: val_loss did not improve from 0.01464\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0122 - val_loss: 0.0147\n",
      "Epoch 38/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0108\n",
      "Epoch 38: val_loss did not improve from 0.01464\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0121 - val_loss: 0.0147\n",
      "Epoch 39/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0154\n",
      "Epoch 39: val_loss did not improve from 0.01464\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0121 - val_loss: 0.0147\n",
      "Epoch 40/40\n",
      "13/26 [==============>...............] - ETA: 0s - loss: 0.0119\n",
      "Epoch 40: val_loss did not improve from 0.01464\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0121 - val_loss: 0.0147\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "LogisticRegression - Mean CV Score: 0.5329230769230768\n",
      "LogisticRegression - Mean Confusion Matrix:\n",
      "[[6.3 6.3]\n",
      " [5.8 7.5]]\n",
      "SVM - Mean CV Score: 0.5673846153846155\n",
      "SVM - Mean Confusion Matrix:\n",
      "[[7.2 5.4]\n",
      " [5.8 7.5]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest - Mean CV Score: 0.5983076923076922\n",
      "RandomForest - Mean Confusion Matrix:\n",
      "[[6.9 5.7]\n",
      " [4.7 8.6]]\n",
      "KNN - Mean CV Score: 0.5861538461538462\n",
      "KNN - Mean Confusion Matrix:\n",
      "[[8.3 4.3]\n",
      " [6.4 6.9]]\n",
      "GradientBoosting - Mean CV Score: 0.5401538461538462\n",
      "GradientBoosting - Mean Confusion Matrix:\n",
      "[[7.1 5.5]\n",
      " [6.4 6.9]]\n",
      "AdaBoost - Mean CV Score: 0.5286153846153846\n",
      "AdaBoost - Mean Confusion Matrix:\n",
      "[[6.5 6.1]\n",
      " [6.1 7.2]]\n",
      "NaiveBayes - Mean CV Score: 0.583076923076923\n",
      "NaiveBayes - Mean Confusion Matrix:\n",
      "[[7.7 4.9]\n",
      " [5.9 7.4]]\n",
      "DecisionTree - Mean CV Score: 0.5443076923076923\n",
      "DecisionTree - Mean Confusion Matrix:\n",
      "[[7.2 5.4]\n",
      " [6.4 6.9]]\n",
      "ExtraTrees - Mean CV Score: 0.6138461538461539\n",
      "ExtraTrees - Mean Confusion Matrix:\n",
      "[[7.9 4.7]\n",
      " [5.3 8. ]]\n",
      "XGBoost - Mean CV Score: 0.556\n",
      "XGBoost - Mean Confusion Matrix:\n",
      "[[7.  5.6]\n",
      " [5.9 7.4]]\n",
      "Size: bottleneck_32, Best classifier: ExtraTrees, CV Score: 0.6138461538461539\n",
      "Epoch 1/40\n",
      " 1/26 [>.............................] - ETA: 23s - loss: 0.0449\n",
      "Epoch 1: val_loss improved from inf to 0.02592, saving model to model\\AE_bottleneck_36_best_model.keras\n",
      "26/26 [==============================] - 1s 11ms/step - loss: 0.0359 - val_loss: 0.0259\n",
      "Epoch 2/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0228\n",
      "Epoch 2: val_loss improved from 0.02592 to 0.02446, saving model to model\\AE_bottleneck_36_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0235 - val_loss: 0.0245\n",
      "Epoch 3/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0247\n",
      "Epoch 3: val_loss improved from 0.02446 to 0.02350, saving model to model\\AE_bottleneck_36_best_model.keras\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0227 - val_loss: 0.0235\n",
      "Epoch 4/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0256\n",
      "Epoch 4: val_loss improved from 0.02350 to 0.02173, saving model to model\\AE_bottleneck_36_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0217 - val_loss: 0.0217\n",
      "Epoch 5/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0189\n",
      "Epoch 5: val_loss improved from 0.02173 to 0.02016, saving model to model\\AE_bottleneck_36_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0199 - val_loss: 0.0202\n",
      "Epoch 6/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0193\n",
      "Epoch 6: val_loss improved from 0.02016 to 0.01972, saving model to model\\AE_bottleneck_36_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0190 - val_loss: 0.0197\n",
      "Epoch 7/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0187\n",
      "Epoch 7: val_loss improved from 0.01972 to 0.01956, saving model to model\\AE_bottleneck_36_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0187 - val_loss: 0.0196\n",
      "Epoch 8/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0182\n",
      "Epoch 8: val_loss improved from 0.01956 to 0.01941, saving model to model\\AE_bottleneck_36_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0186 - val_loss: 0.0194\n",
      "Epoch 9/40\n",
      "20/26 [======================>.......] - ETA: 0s - loss: 0.0191\n",
      "Epoch 9: val_loss improved from 0.01941 to 0.01924, saving model to model\\AE_bottleneck_36_best_model.keras\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0185 - val_loss: 0.0192\n",
      "Epoch 10/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0212\n",
      "Epoch 10: val_loss improved from 0.01924 to 0.01894, saving model to model\\AE_bottleneck_36_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0182 - val_loss: 0.0189\n",
      "Epoch 11/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0181\n",
      "Epoch 11: val_loss improved from 0.01894 to 0.01850, saving model to model\\AE_bottleneck_36_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0179 - val_loss: 0.0185\n",
      "Epoch 12/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0152\n",
      "Epoch 12: val_loss improved from 0.01850 to 0.01809, saving model to model\\AE_bottleneck_36_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0173 - val_loss: 0.0181\n",
      "Epoch 13/40\n",
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0168\n",
      "Epoch 13: val_loss improved from 0.01809 to 0.01782, saving model to model\\AE_bottleneck_36_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0167 - val_loss: 0.0178\n",
      "Epoch 14/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0220\n",
      "Epoch 14: val_loss improved from 0.01782 to 0.01734, saving model to model\\AE_bottleneck_36_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0164 - val_loss: 0.0173\n",
      "Epoch 15/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0125\n",
      "Epoch 15: val_loss improved from 0.01734 to 0.01702, saving model to model\\AE_bottleneck_36_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0160 - val_loss: 0.0170\n",
      "Epoch 16/40\n",
      "15/26 [================>.............] - ETA: 0s - loss: 0.0160\n",
      "Epoch 16: val_loss improved from 0.01702 to 0.01669, saving model to model\\AE_bottleneck_36_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0156 - val_loss: 0.0167\n",
      "Epoch 17/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0169\n",
      "Epoch 17: val_loss improved from 0.01669 to 0.01643, saving model to model\\AE_bottleneck_36_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0151 - val_loss: 0.0164\n",
      "Epoch 18/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0131\n",
      "Epoch 18: val_loss improved from 0.01643 to 0.01618, saving model to model\\AE_bottleneck_36_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0148 - val_loss: 0.0162\n",
      "Epoch 19/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0188\n",
      "Epoch 19: val_loss improved from 0.01618 to 0.01605, saving model to model\\AE_bottleneck_36_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0146 - val_loss: 0.0161\n",
      "Epoch 20/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0156\n",
      "Epoch 20: val_loss improved from 0.01605 to 0.01603, saving model to model\\AE_bottleneck_36_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0144 - val_loss: 0.0160\n",
      "Epoch 21/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0148\n",
      "Epoch 21: val_loss improved from 0.01603 to 0.01570, saving model to model\\AE_bottleneck_36_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0142 - val_loss: 0.0157\n",
      "Epoch 22/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0115\n",
      "Epoch 22: val_loss improved from 0.01570 to 0.01560, saving model to model\\AE_bottleneck_36_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0140 - val_loss: 0.0156\n",
      "Epoch 23/40\n",
      "18/26 [===================>..........] - ETA: 0s - loss: 0.0139\n",
      "Epoch 23: val_loss improved from 0.01560 to 0.01548, saving model to model\\AE_bottleneck_36_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0138 - val_loss: 0.0155\n",
      "Epoch 24/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0134\n",
      "Epoch 24: val_loss improved from 0.01548 to 0.01546, saving model to model\\AE_bottleneck_36_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0137 - val_loss: 0.0155\n",
      "Epoch 25/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0144\n",
      "Epoch 25: val_loss improved from 0.01546 to 0.01535, saving model to model\\AE_bottleneck_36_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0136 - val_loss: 0.0154\n",
      "Epoch 26/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0112\n",
      "Epoch 26: val_loss improved from 0.01535 to 0.01524, saving model to model\\AE_bottleneck_36_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0134 - val_loss: 0.0152\n",
      "Epoch 27/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0141\n",
      "Epoch 27: val_loss improved from 0.01524 to 0.01522, saving model to model\\AE_bottleneck_36_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0134 - val_loss: 0.0152\n",
      "Epoch 28/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0151\n",
      "Epoch 28: val_loss improved from 0.01522 to 0.01517, saving model to model\\AE_bottleneck_36_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0133 - val_loss: 0.0152\n",
      "Epoch 29/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0126\n",
      "Epoch 29: val_loss improved from 0.01517 to 0.01508, saving model to model\\AE_bottleneck_36_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0131 - val_loss: 0.0151\n",
      "Epoch 30/40\n",
      "12/26 [============>.................] - ETA: 0s - loss: 0.0131\n",
      "Epoch 30: val_loss did not improve from 0.01508\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0130 - val_loss: 0.0151\n",
      "Epoch 31/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0136\n",
      "Epoch 31: val_loss improved from 0.01508 to 0.01507, saving model to model\\AE_bottleneck_36_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0130 - val_loss: 0.0151\n",
      "Epoch 32/40\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0128\n",
      "Epoch 32: val_loss improved from 0.01507 to 0.01492, saving model to model\\AE_bottleneck_36_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0128 - val_loss: 0.0149\n",
      "Epoch 33/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0129\n",
      "Epoch 33: val_loss improved from 0.01492 to 0.01482, saving model to model\\AE_bottleneck_36_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0127 - val_loss: 0.0148\n",
      "Epoch 34/40\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0126\n",
      "Epoch 34: val_loss improved from 0.01482 to 0.01479, saving model to model\\AE_bottleneck_36_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0126 - val_loss: 0.0148\n",
      "Epoch 35/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0118\n",
      "Epoch 35: val_loss improved from 0.01479 to 0.01477, saving model to model\\AE_bottleneck_36_best_model.keras\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0125 - val_loss: 0.0148\n",
      "Epoch 36/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0124\n",
      "Epoch 36: val_loss improved from 0.01477 to 0.01475, saving model to model\\AE_bottleneck_36_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0125 - val_loss: 0.0148\n",
      "Epoch 37/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0110\n",
      "Epoch 37: val_loss improved from 0.01475 to 0.01467, saving model to model\\AE_bottleneck_36_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0124 - val_loss: 0.0147\n",
      "Epoch 38/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0124\n",
      "Epoch 38: val_loss improved from 0.01467 to 0.01465, saving model to model\\AE_bottleneck_36_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0123 - val_loss: 0.0146\n",
      "Epoch 39/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0122\n",
      "Epoch 39: val_loss improved from 0.01465 to 0.01465, saving model to model\\AE_bottleneck_36_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0123 - val_loss: 0.0146\n",
      "Epoch 40/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0091\n",
      "Epoch 40: val_loss improved from 0.01465 to 0.01459, saving model to model\\AE_bottleneck_36_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0122 - val_loss: 0.0146\n",
      "9/9 [==============================] - 0s 995us/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "LogisticRegression - Mean CV Score: 0.5364615384615385\n",
      "LogisticRegression - Mean Confusion Matrix:\n",
      "[[6.2 6.4]\n",
      " [5.6 7.7]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM - Mean CV Score: 0.5869230769230769\n",
      "SVM - Mean Confusion Matrix:\n",
      "[[7.  5.6]\n",
      " [5.1 8.2]]\n",
      "RandomForest - Mean CV Score: 0.6407692307692308\n",
      "RandomForest - Mean Confusion Matrix:\n",
      "[[7.8 4.8]\n",
      " [4.5 8.8]]\n",
      "KNN - Mean CV Score: 0.6329230769230769\n",
      "KNN - Mean Confusion Matrix:\n",
      "[[9.  3.6]\n",
      " [5.9 7.4]]\n",
      "GradientBoosting - Mean CV Score: 0.625076923076923\n",
      "GradientBoosting - Mean Confusion Matrix:\n",
      "[[7.8 4.8]\n",
      " [4.9 8.4]]\n",
      "AdaBoost - Mean CV Score: 0.6138461538461538\n",
      "AdaBoost - Mean Confusion Matrix:\n",
      "[[7.7 4.9]\n",
      " [5.1 8.2]]\n",
      "NaiveBayes - Mean CV Score: 0.571076923076923\n",
      "NaiveBayes - Mean Confusion Matrix:\n",
      "[[8.9 3.7]\n",
      " [7.4 5.9]]\n",
      "DecisionTree - Mean CV Score: 0.5904615384615385\n",
      "DecisionTree - Mean Confusion Matrix:\n",
      "[[6.5 6.1]\n",
      " [4.5 8.8]]\n",
      "ExtraTrees - Mean CV Score: 0.6098461538461539\n",
      "ExtraTrees - Mean Confusion Matrix:\n",
      "[[7.5 5.1]\n",
      " [5.  8.3]]\n",
      "XGBoost - Mean CV Score: 0.6218461538461538\n",
      "XGBoost - Mean Confusion Matrix:\n",
      "[[7.3 5.3]\n",
      " [4.5 8.8]]\n",
      "Size: bottleneck_36, Best classifier: RandomForest, CV Score: 0.6407692307692308\n",
      "Epoch 1/40\n",
      " 1/26 [>.............................] - ETA: 24s - loss: 0.0491\n",
      "Epoch 1: val_loss improved from inf to 0.02766, saving model to model\\AE_bottleneck_40_best_model.keras\n",
      "26/26 [==============================] - 1s 10ms/step - loss: 0.0386 - val_loss: 0.0277\n",
      "Epoch 2/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0257\n",
      "Epoch 2: val_loss improved from 0.02766 to 0.02436, saving model to model\\AE_bottleneck_40_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0239 - val_loss: 0.0244\n",
      "Epoch 3/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0233\n",
      "Epoch 3: val_loss improved from 0.02436 to 0.02361, saving model to model\\AE_bottleneck_40_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0227 - val_loss: 0.0236\n",
      "Epoch 4/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0231\n",
      "Epoch 4: val_loss improved from 0.02361 to 0.02305, saving model to model\\AE_bottleneck_40_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0223 - val_loss: 0.0231\n",
      "Epoch 5/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0172\n",
      "Epoch 5: val_loss improved from 0.02305 to 0.02163, saving model to model\\AE_bottleneck_40_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0214 - val_loss: 0.0216\n",
      "Epoch 6/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0201\n",
      "Epoch 6: val_loss improved from 0.02163 to 0.02014, saving model to model\\AE_bottleneck_40_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0197 - val_loss: 0.0201\n",
      "Epoch 7/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0190\n",
      "Epoch 7: val_loss improved from 0.02014 to 0.01975, saving model to model\\AE_bottleneck_40_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0190 - val_loss: 0.0198\n",
      "Epoch 8/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0147\n",
      "Epoch 8: val_loss improved from 0.01975 to 0.01960, saving model to model\\AE_bottleneck_40_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0187 - val_loss: 0.0196\n",
      "Epoch 9/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0222\n",
      "Epoch 9: val_loss improved from 0.01960 to 0.01945, saving model to model\\AE_bottleneck_40_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0185 - val_loss: 0.0195\n",
      "Epoch 10/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0184\n",
      "Epoch 10: val_loss improved from 0.01945 to 0.01932, saving model to model\\AE_bottleneck_40_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0184 - val_loss: 0.0193\n",
      "Epoch 11/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0198\n",
      "Epoch 11: val_loss improved from 0.01932 to 0.01914, saving model to model\\AE_bottleneck_40_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0183 - val_loss: 0.0191\n",
      "Epoch 12/40\n",
      "15/26 [================>.............] - ETA: 0s - loss: 0.0185\n",
      "Epoch 12: val_loss improved from 0.01914 to 0.01903, saving model to model\\AE_bottleneck_40_best_model.keras\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0182 - val_loss: 0.0190\n",
      "Epoch 13/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0192\n",
      "Epoch 13: val_loss improved from 0.01903 to 0.01865, saving model to model\\AE_bottleneck_40_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0179 - val_loss: 0.0187\n",
      "Epoch 14/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0163\n",
      "Epoch 14: val_loss improved from 0.01865 to 0.01816, saving model to model\\AE_bottleneck_40_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0173 - val_loss: 0.0182\n",
      "Epoch 15/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0187\n",
      "Epoch 15: val_loss improved from 0.01816 to 0.01766, saving model to model\\AE_bottleneck_40_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0168 - val_loss: 0.0177\n",
      "Epoch 16/40\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0162\n",
      "Epoch 16: val_loss improved from 0.01766 to 0.01730, saving model to model\\AE_bottleneck_40_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0162 - val_loss: 0.0173\n",
      "Epoch 17/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0167\n",
      "Epoch 17: val_loss improved from 0.01730 to 0.01699, saving model to model\\AE_bottleneck_40_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0159 - val_loss: 0.0170\n",
      "Epoch 18/40\n",
      "17/26 [==================>...........] - ETA: 0s - loss: 0.0151\n",
      "Epoch 18: val_loss improved from 0.01699 to 0.01679, saving model to model\\AE_bottleneck_40_best_model.keras\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0155 - val_loss: 0.0168\n",
      "Epoch 19/40\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0154\n",
      "Epoch 19: val_loss improved from 0.01679 to 0.01668, saving model to model\\AE_bottleneck_40_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0154 - val_loss: 0.0167\n",
      "Epoch 20/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0158\n",
      "Epoch 20: val_loss improved from 0.01668 to 0.01664, saving model to model\\AE_bottleneck_40_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0151 - val_loss: 0.0166\n",
      "Epoch 21/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0133\n",
      "Epoch 21: val_loss improved from 0.01664 to 0.01648, saving model to model\\AE_bottleneck_40_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0150 - val_loss: 0.0165\n",
      "Epoch 22/40\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0149\n",
      "Epoch 22: val_loss improved from 0.01648 to 0.01645, saving model to model\\AE_bottleneck_40_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0149 - val_loss: 0.0164\n",
      "Epoch 23/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0102\n",
      "Epoch 23: val_loss improved from 0.01645 to 0.01639, saving model to model\\AE_bottleneck_40_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0148 - val_loss: 0.0164\n",
      "Epoch 24/40\n",
      "18/26 [===================>..........] - ETA: 0s - loss: 0.0149\n",
      "Epoch 24: val_loss improved from 0.01639 to 0.01627, saving model to model\\AE_bottleneck_40_best_model.keras\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0147 - val_loss: 0.0163\n",
      "Epoch 25/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0134\n",
      "Epoch 25: val_loss did not improve from 0.01627\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0146 - val_loss: 0.0164\n",
      "Epoch 26/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0145\n",
      "Epoch 26: val_loss improved from 0.01627 to 0.01604, saving model to model\\AE_bottleneck_40_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0145 - val_loss: 0.0160\n",
      "Epoch 27/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0143\n",
      "Epoch 27: val_loss did not improve from 0.01604\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0143 - val_loss: 0.0161\n",
      "Epoch 28/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0135\n",
      "Epoch 28: val_loss did not improve from 0.01604\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0143 - val_loss: 0.0161\n",
      "Epoch 29/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0140\n",
      "Epoch 29: val_loss improved from 0.01604 to 0.01584, saving model to model\\AE_bottleneck_40_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0142 - val_loss: 0.0158\n",
      "Epoch 30/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0133\n",
      "Epoch 30: val_loss improved from 0.01584 to 0.01574, saving model to model\\AE_bottleneck_40_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0140 - val_loss: 0.0157\n",
      "Epoch 31/40\n",
      "21/26 [=======================>......] - ETA: 0s - loss: 0.0137\n",
      "Epoch 31: val_loss did not improve from 0.01574\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0139 - val_loss: 0.0159\n",
      "Epoch 32/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0162\n",
      "Epoch 32: val_loss improved from 0.01574 to 0.01558, saving model to model\\AE_bottleneck_40_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0138 - val_loss: 0.0156\n",
      "Epoch 33/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0122\n",
      "Epoch 33: val_loss improved from 0.01558 to 0.01548, saving model to model\\AE_bottleneck_40_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0136 - val_loss: 0.0155\n",
      "Epoch 34/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0152\n",
      "Epoch 34: val_loss improved from 0.01548 to 0.01541, saving model to model\\AE_bottleneck_40_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0134 - val_loss: 0.0154\n",
      "Epoch 35/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0123\n",
      "Epoch 35: val_loss improved from 0.01541 to 0.01526, saving model to model\\AE_bottleneck_40_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0133 - val_loss: 0.0153\n",
      "Epoch 36/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0152\n",
      "Epoch 36: val_loss improved from 0.01526 to 0.01525, saving model to model\\AE_bottleneck_40_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0131 - val_loss: 0.0152\n",
      "Epoch 37/40\n",
      "20/26 [======================>.......] - ETA: 0s - loss: 0.0130\n",
      "Epoch 37: val_loss improved from 0.01525 to 0.01521, saving model to model\\AE_bottleneck_40_best_model.keras\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0130 - val_loss: 0.0152\n",
      "Epoch 38/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0132\n",
      "Epoch 38: val_loss improved from 0.01521 to 0.01513, saving model to model\\AE_bottleneck_40_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0129 - val_loss: 0.0151\n",
      "Epoch 39/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0124\n",
      "Epoch 39: val_loss improved from 0.01513 to 0.01508, saving model to model\\AE_bottleneck_40_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0128 - val_loss: 0.0151\n",
      "Epoch 40/40\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0126\n",
      "Epoch 40: val_loss did not improve from 0.01508\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0126 - val_loss: 0.0151\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "LogisticRegression - Mean CV Score: 0.5906153846153845\n",
      "LogisticRegression - Mean Confusion Matrix:\n",
      "[[7.3 5.3]\n",
      " [5.3 8. ]]\n",
      "SVM - Mean CV Score: 0.5713846153846154\n",
      "SVM - Mean Confusion Matrix:\n",
      "[[7.2 5.4]\n",
      " [5.7 7.6]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest - Mean CV Score: 0.6060000000000001\n",
      "RandomForest - Mean Confusion Matrix:\n",
      "[[7.  5.6]\n",
      " [4.6 8.7]]\n",
      "KNN - Mean CV Score: 0.5524615384615383\n",
      "KNN - Mean Confusion Matrix:\n",
      "[[7.5 5.1]\n",
      " [6.5 6.8]]\n",
      "GradientBoosting - Mean CV Score: 0.5670769230769231\n",
      "GradientBoosting - Mean Confusion Matrix:\n",
      "[[6.5 6.1]\n",
      " [5.1 8.2]]\n",
      "AdaBoost - Mean CV Score: 0.579076923076923\n",
      "AdaBoost - Mean Confusion Matrix:\n",
      "[[7.2 5.4]\n",
      " [5.5 7.8]]\n",
      "NaiveBayes - Mean CV Score: 0.566923076923077\n",
      "NaiveBayes - Mean Confusion Matrix:\n",
      "[[9.7 2.9]\n",
      " [8.3 5. ]]\n",
      "DecisionTree - Mean CV Score: 0.5518461538461539\n",
      "DecisionTree - Mean Confusion Matrix:\n",
      "[[7.6 5. ]\n",
      " [6.6 6.7]]\n",
      "ExtraTrees - Mean CV Score: 0.5944615384615386\n",
      "ExtraTrees - Mean Confusion Matrix:\n",
      "[[7.7 4.9]\n",
      " [5.6 7.7]]\n",
      "XGBoost - Mean CV Score: 0.5781538461538462\n",
      "XGBoost - Mean Confusion Matrix:\n",
      "[[6.8 5.8]\n",
      " [5.1 8.2]]\n",
      "Size: bottleneck_40, Best classifier: RandomForest, CV Score: 0.6060000000000001\n",
      "Epoch 1/40\n",
      " 1/26 [>.............................] - ETA: 24s - loss: 0.0474\n",
      "Epoch 1: val_loss improved from inf to 0.02819, saving model to model\\AE_bottleneck_44_best_model.keras\n",
      "26/26 [==============================] - 1s 11ms/step - loss: 0.0395 - val_loss: 0.0282\n",
      "Epoch 2/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0336\n",
      "Epoch 2: val_loss improved from 0.02819 to 0.02471, saving model to model\\AE_bottleneck_44_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0242 - val_loss: 0.0247\n",
      "Epoch 3/40\n",
      "21/26 [=======================>......] - ETA: 0s - loss: 0.0219\n",
      "Epoch 3: val_loss improved from 0.02471 to 0.02374, saving model to model\\AE_bottleneck_44_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0227 - val_loss: 0.0237\n",
      "Epoch 4/40\n",
      "20/26 [======================>.......] - ETA: 0s - loss: 0.0218\n",
      "Epoch 4: val_loss improved from 0.02374 to 0.02246, saving model to model\\AE_bottleneck_44_best_model.keras\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0219 - val_loss: 0.0225\n",
      "Epoch 5/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0230\n",
      "Epoch 5: val_loss improved from 0.02246 to 0.02030, saving model to model\\AE_bottleneck_44_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0201 - val_loss: 0.0203\n",
      "Epoch 6/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0187\n",
      "Epoch 6: val_loss improved from 0.02030 to 0.01951, saving model to model\\AE_bottleneck_44_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0188 - val_loss: 0.0195\n",
      "Epoch 7/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0184\n",
      "Epoch 7: val_loss improved from 0.01951 to 0.01894, saving model to model\\AE_bottleneck_44_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0182 - val_loss: 0.0189\n",
      "Epoch 8/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0194\n",
      "Epoch 8: val_loss improved from 0.01894 to 0.01855, saving model to model\\AE_bottleneck_44_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0176 - val_loss: 0.0186\n",
      "Epoch 9/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0186\n",
      "Epoch 9: val_loss improved from 0.01855 to 0.01820, saving model to model\\AE_bottleneck_44_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0171 - val_loss: 0.0182\n",
      "Epoch 10/40\n",
      "21/26 [=======================>......] - ETA: 0s - loss: 0.0168\n",
      "Epoch 10: val_loss improved from 0.01820 to 0.01807, saving model to model\\AE_bottleneck_44_best_model.keras\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0168 - val_loss: 0.0181\n",
      "Epoch 11/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0167\n",
      "Epoch 11: val_loss improved from 0.01807 to 0.01798, saving model to model\\AE_bottleneck_44_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0167 - val_loss: 0.0180\n",
      "Epoch 12/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0177\n",
      "Epoch 12: val_loss did not improve from 0.01798\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0166 - val_loss: 0.0180\n",
      "Epoch 13/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0166\n",
      "Epoch 13: val_loss improved from 0.01798 to 0.01778, saving model to model\\AE_bottleneck_44_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0164 - val_loss: 0.0178\n",
      "Epoch 14/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0185\n",
      "Epoch 14: val_loss improved from 0.01778 to 0.01766, saving model to model\\AE_bottleneck_44_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0163 - val_loss: 0.0177\n",
      "Epoch 15/40\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0162\n",
      "Epoch 15: val_loss improved from 0.01766 to 0.01763, saving model to model\\AE_bottleneck_44_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0162 - val_loss: 0.0176\n",
      "Epoch 16/40\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0161\n",
      "Epoch 16: val_loss improved from 0.01763 to 0.01749, saving model to model\\AE_bottleneck_44_best_model.keras\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0161 - val_loss: 0.0175\n",
      "Epoch 17/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0159\n",
      "Epoch 17: val_loss improved from 0.01749 to 0.01748, saving model to model\\AE_bottleneck_44_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0160 - val_loss: 0.0175\n",
      "Epoch 18/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0169\n",
      "Epoch 18: val_loss improved from 0.01748 to 0.01733, saving model to model\\AE_bottleneck_44_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0158 - val_loss: 0.0173\n",
      "Epoch 19/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0153\n",
      "Epoch 19: val_loss improved from 0.01733 to 0.01695, saving model to model\\AE_bottleneck_44_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0155 - val_loss: 0.0169\n",
      "Epoch 20/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0128\n",
      "Epoch 20: val_loss improved from 0.01695 to 0.01672, saving model to model\\AE_bottleneck_44_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0152 - val_loss: 0.0167\n",
      "Epoch 21/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0135\n",
      "Epoch 21: val_loss improved from 0.01672 to 0.01659, saving model to model\\AE_bottleneck_44_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0150 - val_loss: 0.0166\n",
      "Epoch 22/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0128\n",
      "Epoch 22: val_loss improved from 0.01659 to 0.01651, saving model to model\\AE_bottleneck_44_best_model.keras\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0149 - val_loss: 0.0165\n",
      "Epoch 23/40\n",
      "18/26 [===================>..........] - ETA: 0s - loss: 0.0148\n",
      "Epoch 23: val_loss improved from 0.01651 to 0.01627, saving model to model\\AE_bottleneck_44_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0147 - val_loss: 0.0163\n",
      "Epoch 24/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0139\n",
      "Epoch 24: val_loss improved from 0.01627 to 0.01616, saving model to model\\AE_bottleneck_44_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0145 - val_loss: 0.0162\n",
      "Epoch 25/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0117\n",
      "Epoch 25: val_loss improved from 0.01616 to 0.01602, saving model to model\\AE_bottleneck_44_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0144 - val_loss: 0.0160\n",
      "Epoch 26/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0165\n",
      "Epoch 26: val_loss did not improve from 0.01602\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0142 - val_loss: 0.0160\n",
      "Epoch 27/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0158\n",
      "Epoch 27: val_loss improved from 0.01602 to 0.01586, saving model to model\\AE_bottleneck_44_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0142 - val_loss: 0.0159\n",
      "Epoch 28/40\n",
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0138\n",
      "Epoch 28: val_loss improved from 0.01586 to 0.01568, saving model to model\\AE_bottleneck_44_best_model.keras\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0139 - val_loss: 0.0157\n",
      "Epoch 29/40\n",
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0136\n",
      "Epoch 29: val_loss did not improve from 0.01568\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0137 - val_loss: 0.0157\n",
      "Epoch 30/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0127\n",
      "Epoch 30: val_loss improved from 0.01568 to 0.01565, saving model to model\\AE_bottleneck_44_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0136 - val_loss: 0.0157\n",
      "Epoch 31/40\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0134\n",
      "Epoch 31: val_loss improved from 0.01565 to 0.01547, saving model to model\\AE_bottleneck_44_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0134 - val_loss: 0.0155\n",
      "Epoch 32/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0127\n",
      "Epoch 32: val_loss improved from 0.01547 to 0.01541, saving model to model\\AE_bottleneck_44_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0132 - val_loss: 0.0154\n",
      "Epoch 33/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0103\n",
      "Epoch 33: val_loss improved from 0.01541 to 0.01538, saving model to model\\AE_bottleneck_44_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0131 - val_loss: 0.0154\n",
      "Epoch 34/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0121\n",
      "Epoch 34: val_loss improved from 0.01538 to 0.01529, saving model to model\\AE_bottleneck_44_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0130 - val_loss: 0.0153\n",
      "Epoch 35/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0100\n",
      "Epoch 35: val_loss improved from 0.01529 to 0.01526, saving model to model\\AE_bottleneck_44_best_model.keras\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0129 - val_loss: 0.0153\n",
      "Epoch 36/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0127\n",
      "Epoch 36: val_loss did not improve from 0.01526\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0128 - val_loss: 0.0153\n",
      "Epoch 37/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0132\n",
      "Epoch 37: val_loss improved from 0.01526 to 0.01524, saving model to model\\AE_bottleneck_44_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0127 - val_loss: 0.0152\n",
      "Epoch 38/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0123\n",
      "Epoch 38: val_loss improved from 0.01524 to 0.01517, saving model to model\\AE_bottleneck_44_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0126 - val_loss: 0.0152\n",
      "Epoch 39/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0106\n",
      "Epoch 39: val_loss improved from 0.01517 to 0.01506, saving model to model\\AE_bottleneck_44_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0126 - val_loss: 0.0151\n",
      "Epoch 40/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0109\n",
      "Epoch 40: val_loss did not improve from 0.01506\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0125 - val_loss: 0.0151\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "LogisticRegression - Mean CV Score: 0.6138461538461539\n",
      "LogisticRegression - Mean Confusion Matrix:\n",
      "[[7.9 4.7]\n",
      " [5.3 8. ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM - Mean CV Score: 0.5675384615384615\n",
      "SVM - Mean Confusion Matrix:\n",
      "[[7.4 5.2]\n",
      " [6.  7.3]]\n",
      "RandomForest - Mean CV Score: 0.5904615384615385\n",
      "RandomForest - Mean Confusion Matrix:\n",
      "[[7.2 5.4]\n",
      " [5.2 8.1]]\n",
      "KNN - Mean CV Score: 0.6218461538461538\n",
      "KNN - Mean Confusion Matrix:\n",
      "[[8.9 3.7]\n",
      " [6.1 7.2]]\n",
      "GradientBoosting - Mean CV Score: 0.6058461538461539\n",
      "GradientBoosting - Mean Confusion Matrix:\n",
      "[[7.5 5.1]\n",
      " [5.1 8.2]]\n",
      "AdaBoost - Mean CV Score: 0.5867692307692307\n",
      "AdaBoost - Mean Confusion Matrix:\n",
      "[[7.5 5.1]\n",
      " [5.6 7.7]]\n",
      "NaiveBayes - Mean CV Score: 0.5016923076923077\n",
      "NaiveBayes - Mean Confusion Matrix:\n",
      "[[10.9  1.7]\n",
      " [11.2  2.1]]\n",
      "DecisionTree - Mean CV Score: 0.5678461538461538\n",
      "DecisionTree - Mean Confusion Matrix:\n",
      "[[6.6 6. ]\n",
      " [5.2 8.1]]\n",
      "ExtraTrees - Mean CV Score: 0.5901538461538463\n",
      "ExtraTrees - Mean Confusion Matrix:\n",
      "[[7.2 5.4]\n",
      " [5.2 8.1]]\n",
      "XGBoost - Mean CV Score: 0.6172307692307692\n",
      "XGBoost - Mean Confusion Matrix:\n",
      "[[7.8 4.8]\n",
      " [5.1 8.2]]\n",
      "Size: bottleneck_44, Best classifier: KNN, CV Score: 0.6218461538461538\n",
      "Epoch 1/40\n",
      " 1/26 [>.............................] - ETA: 23s - loss: 0.0471\n",
      "Epoch 1: val_loss improved from inf to 0.02698, saving model to model\\AE_bottleneck_48_best_model.keras\n",
      "26/26 [==============================] - 1s 11ms/step - loss: 0.0362 - val_loss: 0.0270\n",
      "Epoch 2/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0223\n",
      "Epoch 2: val_loss improved from 0.02698 to 0.02391, saving model to model\\AE_bottleneck_48_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0236 - val_loss: 0.0239\n",
      "Epoch 3/40\n",
      "20/26 [======================>.......] - ETA: 0s - loss: 0.0216\n",
      "Epoch 3: val_loss improved from 0.02391 to 0.02329, saving model to model\\AE_bottleneck_48_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0225 - val_loss: 0.0233\n",
      "Epoch 4/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0246\n",
      "Epoch 4: val_loss improved from 0.02329 to 0.02184, saving model to model\\AE_bottleneck_48_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0218 - val_loss: 0.0218\n",
      "Epoch 5/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0225\n",
      "Epoch 5: val_loss improved from 0.02184 to 0.02026, saving model to model\\AE_bottleneck_48_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0199 - val_loss: 0.0203\n",
      "Epoch 6/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0189\n",
      "Epoch 6: val_loss improved from 0.02026 to 0.01937, saving model to model\\AE_bottleneck_48_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0189 - val_loss: 0.0194\n",
      "Epoch 7/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0182\n",
      "Epoch 7: val_loss improved from 0.01937 to 0.01910, saving model to model\\AE_bottleneck_48_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0185 - val_loss: 0.0191\n",
      "Epoch 8/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0139\n",
      "Epoch 8: val_loss improved from 0.01910 to 0.01866, saving model to model\\AE_bottleneck_48_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0180 - val_loss: 0.0187\n",
      "Epoch 9/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0174\n",
      "Epoch 9: val_loss improved from 0.01866 to 0.01823, saving model to model\\AE_bottleneck_48_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0175 - val_loss: 0.0182\n",
      "Epoch 10/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0164\n",
      "Epoch 10: val_loss improved from 0.01823 to 0.01769, saving model to model\\AE_bottleneck_48_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0168 - val_loss: 0.0177\n",
      "Epoch 11/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0159\n",
      "Epoch 11: val_loss improved from 0.01769 to 0.01728, saving model to model\\AE_bottleneck_48_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0162 - val_loss: 0.0173\n",
      "Epoch 12/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0130\n",
      "Epoch 12: val_loss improved from 0.01728 to 0.01687, saving model to model\\AE_bottleneck_48_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0157 - val_loss: 0.0169\n",
      "Epoch 13/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0152\n",
      "Epoch 13: val_loss improved from 0.01687 to 0.01652, saving model to model\\AE_bottleneck_48_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0152 - val_loss: 0.0165\n",
      "Epoch 14/40\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0146\n",
      "Epoch 14: val_loss improved from 0.01652 to 0.01594, saving model to model\\AE_bottleneck_48_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0146 - val_loss: 0.0159\n",
      "Epoch 15/40\n",
      "16/26 [=================>............] - ETA: 0s - loss: 0.0145\n",
      "Epoch 15: val_loss improved from 0.01594 to 0.01564, saving model to model\\AE_bottleneck_48_best_model.keras\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0141 - val_loss: 0.0156\n",
      "Epoch 16/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0127\n",
      "Epoch 16: val_loss improved from 0.01564 to 0.01547, saving model to model\\AE_bottleneck_48_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0138 - val_loss: 0.0155\n",
      "Epoch 17/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0140\n",
      "Epoch 17: val_loss did not improve from 0.01547\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0137 - val_loss: 0.0155\n",
      "Epoch 18/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0151\n",
      "Epoch 18: val_loss improved from 0.01547 to 0.01522, saving model to model\\AE_bottleneck_48_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0135 - val_loss: 0.0152\n",
      "Epoch 19/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0115\n",
      "Epoch 19: val_loss improved from 0.01522 to 0.01508, saving model to model\\AE_bottleneck_48_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0132 - val_loss: 0.0151\n",
      "Epoch 20/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0117\n",
      "Epoch 20: val_loss did not improve from 0.01508\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0131 - val_loss: 0.0151\n",
      "Epoch 21/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0112\n",
      "Epoch 21: val_loss improved from 0.01508 to 0.01500, saving model to model\\AE_bottleneck_48_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0130 - val_loss: 0.0150\n",
      "Epoch 22/40\n",
      "17/26 [==================>...........] - ETA: 0s - loss: 0.0129\n",
      "Epoch 22: val_loss did not improve from 0.01500\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0129 - val_loss: 0.0150\n",
      "Epoch 23/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0111\n",
      "Epoch 23: val_loss improved from 0.01500 to 0.01494, saving model to model\\AE_bottleneck_48_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0128 - val_loss: 0.0149\n",
      "Epoch 24/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0127\n",
      "Epoch 24: val_loss did not improve from 0.01494\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0127 - val_loss: 0.0150\n",
      "Epoch 25/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0147\n",
      "Epoch 25: val_loss improved from 0.01494 to 0.01492, saving model to model\\AE_bottleneck_48_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0126 - val_loss: 0.0149\n",
      "Epoch 26/40\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0125\n",
      "Epoch 26: val_loss improved from 0.01492 to 0.01484, saving model to model\\AE_bottleneck_48_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0125 - val_loss: 0.0148\n",
      "Epoch 27/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0119\n",
      "Epoch 27: val_loss improved from 0.01484 to 0.01475, saving model to model\\AE_bottleneck_48_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0124 - val_loss: 0.0148\n",
      "Epoch 28/40\n",
      "14/26 [===============>..............] - ETA: 0s - loss: 0.0128\n",
      "Epoch 28: val_loss improved from 0.01475 to 0.01473, saving model to model\\AE_bottleneck_48_best_model.keras\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0124 - val_loss: 0.0147\n",
      "Epoch 29/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0141\n",
      "Epoch 29: val_loss improved from 0.01473 to 0.01469, saving model to model\\AE_bottleneck_48_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0123 - val_loss: 0.0147\n",
      "Epoch 30/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0113\n",
      "Epoch 30: val_loss did not improve from 0.01469\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0122 - val_loss: 0.0147\n",
      "Epoch 31/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0110\n",
      "Epoch 31: val_loss did not improve from 0.01469\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0121 - val_loss: 0.0148\n",
      "Epoch 32/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0115\n",
      "Epoch 32: val_loss improved from 0.01469 to 0.01468, saving model to model\\AE_bottleneck_48_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0121 - val_loss: 0.0147\n",
      "Epoch 33/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0138\n",
      "Epoch 33: val_loss did not improve from 0.01468\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0120 - val_loss: 0.0147\n",
      "Epoch 34/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0143\n",
      "Epoch 34: val_loss improved from 0.01468 to 0.01465, saving model to model\\AE_bottleneck_48_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0120 - val_loss: 0.0147\n",
      "Epoch 35/40\n",
      "19/26 [====================>.........] - ETA: 0s - loss: 0.0120\n",
      "Epoch 35: val_loss improved from 0.01465 to 0.01457, saving model to model\\AE_bottleneck_48_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0119 - val_loss: 0.0146\n",
      "Epoch 36/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0093\n",
      "Epoch 36: val_loss did not improve from 0.01457\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0119 - val_loss: 0.0147\n",
      "Epoch 37/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0132\n",
      "Epoch 37: val_loss did not improve from 0.01457\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0119 - val_loss: 0.0146\n",
      "Epoch 38/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0102\n",
      "Epoch 38: val_loss improved from 0.01457 to 0.01448, saving model to model\\AE_bottleneck_48_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0118 - val_loss: 0.0145\n",
      "Epoch 39/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0101\n",
      "Epoch 39: val_loss did not improve from 0.01448\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0117 - val_loss: 0.0146\n",
      "Epoch 40/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0116\n",
      "Epoch 40: val_loss did not improve from 0.01448\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0117 - val_loss: 0.0146\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression - Mean CV Score: 0.5827692307692308\n",
      "LogisticRegression - Mean Confusion Matrix:\n",
      "[[6.8 5.8]\n",
      " [5.  8.3]]\n",
      "SVM - Mean CV Score: 0.5599999999999999\n",
      "SVM - Mean Confusion Matrix:\n",
      "[[7.2 5.4]\n",
      " [6.  7.3]]\n",
      "RandomForest - Mean CV Score: 0.6484615384615384\n",
      "RandomForest - Mean Confusion Matrix:\n",
      "[[8.  4.6]\n",
      " [4.5 8.8]]\n",
      "KNN - Mean CV Score: 0.5752307692307692\n",
      "KNN - Mean Confusion Matrix:\n",
      "[[8.3 4.3]\n",
      " [6.7 6.6]]\n",
      "GradientBoosting - Mean CV Score: 0.5909230769230769\n",
      "GradientBoosting - Mean Confusion Matrix:\n",
      "[[7.2 5.4]\n",
      " [5.2 8.1]]\n",
      "AdaBoost - Mean CV Score: 0.6293846153846154\n",
      "AdaBoost - Mean Confusion Matrix:\n",
      "[[8.5 4.1]\n",
      " [5.5 7.8]]\n",
      "NaiveBayes - Mean CV Score: 0.5403076923076924\n",
      "NaiveBayes - Mean Confusion Matrix:\n",
      "[[10.7  1.9]\n",
      " [10.   3.3]]\n",
      "DecisionTree - Mean CV Score: 0.5173846153846154\n",
      "DecisionTree - Mean Confusion Matrix:\n",
      "[[6.5 6.1]\n",
      " [6.4 6.9]]\n",
      "ExtraTrees - Mean CV Score: 0.6176923076923078\n",
      "ExtraTrees - Mean Confusion Matrix:\n",
      "[[8.  4.6]\n",
      " [5.3 8. ]]\n",
      "XGBoost - Mean CV Score: 0.5869230769230769\n",
      "XGBoost - Mean Confusion Matrix:\n",
      "[[7.6 5. ]\n",
      " [5.7 7.6]]\n",
      "Size: bottleneck_48, Best classifier: RandomForest, CV Score: 0.6484615384615384\n"
     ]
    }
   ],
   "source": [
    "dispatcher(AE,\"AE\",8,48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "21/26 [=======================>......] - ETA: 0s - loss: 0.0347 \n",
      "Epoch 1: val_loss improved from inf to 0.02560, saving model to model\\WAE_bottleneck_6_best_model.keras\n",
      "26/26 [==============================] - 1s 14ms/step - loss: 0.0329 - val_loss: 0.0256\n",
      "Epoch 2/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0234\n",
      "Epoch 2: val_loss improved from 0.02560 to 0.02341, saving model to model\\WAE_bottleneck_6_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0230 - val_loss: 0.0234\n",
      "Epoch 3/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0210\n",
      "Epoch 3: val_loss improved from 0.02341 to 0.02041, saving model to model\\WAE_bottleneck_6_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0208 - val_loss: 0.0204\n",
      "Epoch 4/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0190\n",
      "Epoch 4: val_loss improved from 0.02041 to 0.01961, saving model to model\\WAE_bottleneck_6_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0191 - val_loss: 0.0196\n",
      "Epoch 5/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0186\n",
      "Epoch 5: val_loss improved from 0.01961 to 0.01946, saving model to model\\WAE_bottleneck_6_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0188 - val_loss: 0.0195\n",
      "Epoch 6/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0182\n",
      "Epoch 6: val_loss improved from 0.01946 to 0.01923, saving model to model\\WAE_bottleneck_6_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0184 - val_loss: 0.0192\n",
      "Epoch 7/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0183\n",
      "Epoch 7: val_loss improved from 0.01923 to 0.01892, saving model to model\\WAE_bottleneck_6_best_model.keras\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0183 - val_loss: 0.0189\n",
      "Epoch 8/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0182\n",
      "Epoch 8: val_loss improved from 0.01892 to 0.01867, saving model to model\\WAE_bottleneck_6_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0179 - val_loss: 0.0187\n",
      "Epoch 9/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0170\n",
      "Epoch 9: val_loss improved from 0.01867 to 0.01806, saving model to model\\WAE_bottleneck_6_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0171 - val_loss: 0.0181\n",
      "Epoch 10/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0164\n",
      "Epoch 10: val_loss improved from 0.01806 to 0.01762, saving model to model\\WAE_bottleneck_6_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0166 - val_loss: 0.0176\n",
      "Epoch 11/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0164\n",
      "Epoch 11: val_loss improved from 0.01762 to 0.01746, saving model to model\\WAE_bottleneck_6_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0164 - val_loss: 0.0175\n",
      "Epoch 12/40\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0161\n",
      "Epoch 12: val_loss improved from 0.01746 to 0.01730, saving model to model\\WAE_bottleneck_6_best_model.keras\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0161 - val_loss: 0.0173\n",
      "Epoch 13/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0155\n",
      "Epoch 13: val_loss did not improve from 0.01730\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0158 - val_loss: 0.0173\n",
      "Epoch 14/40\n",
      "21/26 [=======================>......] - ETA: 0s - loss: 0.0156\n",
      "Epoch 14: val_loss improved from 0.01730 to 0.01707, saving model to model\\WAE_bottleneck_6_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0155 - val_loss: 0.0171\n",
      "Epoch 15/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0157\n",
      "Epoch 15: val_loss improved from 0.01707 to 0.01702, saving model to model\\WAE_bottleneck_6_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0153 - val_loss: 0.0170\n",
      "Epoch 16/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0150\n",
      "Epoch 16: val_loss improved from 0.01702 to 0.01695, saving model to model\\WAE_bottleneck_6_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0152 - val_loss: 0.0170\n",
      "Epoch 17/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0148\n",
      "Epoch 17: val_loss improved from 0.01695 to 0.01669, saving model to model\\WAE_bottleneck_6_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0149 - val_loss: 0.0167\n",
      "Epoch 18/40\n",
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0149\n",
      "Epoch 18: val_loss improved from 0.01669 to 0.01664, saving model to model\\WAE_bottleneck_6_best_model.keras\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0148 - val_loss: 0.0166\n",
      "Epoch 19/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0145\n",
      "Epoch 19: val_loss did not improve from 0.01664\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0147 - val_loss: 0.0167\n",
      "Epoch 20/40\n",
      "19/26 [====================>.........] - ETA: 0s - loss: 0.0147\n",
      "Epoch 20: val_loss did not improve from 0.01664\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0146 - val_loss: 0.0168\n",
      "Epoch 21/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0145\n",
      "Epoch 21: val_loss improved from 0.01664 to 0.01649, saving model to model\\WAE_bottleneck_6_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0144 - val_loss: 0.0165\n",
      "Epoch 22/40\n",
      "21/26 [=======================>......] - ETA: 0s - loss: 0.0143\n",
      "Epoch 22: val_loss did not improve from 0.01649\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0142 - val_loss: 0.0165\n",
      "Epoch 23/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0141\n",
      "Epoch 23: val_loss improved from 0.01649 to 0.01643, saving model to model\\WAE_bottleneck_6_best_model.keras\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 0.0141 - val_loss: 0.0164\n",
      "Epoch 24/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0140\n",
      "Epoch 24: val_loss did not improve from 0.01643\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0141 - val_loss: 0.0167\n",
      "Epoch 25/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0143\n",
      "Epoch 25: val_loss did not improve from 0.01643\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0141 - val_loss: 0.0167\n",
      "Epoch 26/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0142\n",
      "Epoch 26: val_loss did not improve from 0.01643\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0140 - val_loss: 0.0165\n",
      "Epoch 27/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0140\n",
      "Epoch 27: val_loss did not improve from 0.01643\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0138 - val_loss: 0.0165\n",
      "Epoch 28/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0138\n",
      "Epoch 28: val_loss did not improve from 0.01643\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0139 - val_loss: 0.0165\n",
      "Epoch 29/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0136\n",
      "Epoch 29: val_loss did not improve from 0.01643\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0138 - val_loss: 0.0167\n",
      "Epoch 30/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0133\n",
      "Epoch 30: val_loss did not improve from 0.01643\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0136 - val_loss: 0.0166\n",
      "Epoch 31/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0137\n",
      "Epoch 31: val_loss improved from 0.01643 to 0.01637, saving model to model\\WAE_bottleneck_6_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0136 - val_loss: 0.0164\n",
      "Epoch 32/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0134\n",
      "Epoch 32: val_loss did not improve from 0.01637\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0136 - val_loss: 0.0166\n",
      "Epoch 33/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0132\n",
      "Epoch 33: val_loss did not improve from 0.01637\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0134 - val_loss: 0.0166\n",
      "Epoch 34/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0136\n",
      "Epoch 34: val_loss did not improve from 0.01637\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0134 - val_loss: 0.0165\n",
      "Epoch 35/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0131\n",
      "Epoch 35: val_loss did not improve from 0.01637\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0132 - val_loss: 0.0165\n",
      "Epoch 36/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0130\n",
      "Epoch 36: val_loss did not improve from 0.01637\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0132 - val_loss: 0.0167\n",
      "Epoch 37/40\n",
      "18/26 [===================>..........] - ETA: 0s - loss: 0.0126\n",
      "Epoch 37: val_loss did not improve from 0.01637\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0132 - val_loss: 0.0167\n",
      "Epoch 38/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0131\n",
      "Epoch 38: val_loss did not improve from 0.01637\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0131 - val_loss: 0.0168\n",
      "Epoch 39/40\n",
      "21/26 [=======================>......] - ETA: 0s - loss: 0.0131\n",
      "Epoch 39: val_loss did not improve from 0.01637\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0131 - val_loss: 0.0166\n",
      "Epoch 40/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0130\n",
      "Epoch 40: val_loss did not improve from 0.01637\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0129 - val_loss: 0.0166\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "LogisticRegression - Mean CV Score: 0.5795384615384616\n",
      "LogisticRegression - Mean Confusion Matrix:\n",
      "[[6.8 5.8]\n",
      " [5.1 8.2]]\n",
      "SVM - Mean CV Score: 0.591076923076923\n",
      "SVM - Mean Confusion Matrix:\n",
      "[[8.  4.6]\n",
      " [6.  7.3]]\n",
      "RandomForest - Mean CV Score: 0.6293846153846153\n",
      "RandomForest - Mean Confusion Matrix:\n",
      "[[7.9 4.7]\n",
      " [4.9 8.4]]\n",
      "KNN - Mean CV Score: 0.5795384615384616\n",
      "KNN - Mean Confusion Matrix:\n",
      "[[7.5 5.1]\n",
      " [5.8 7.5]]\n",
      "GradientBoosting - Mean CV Score: 0.5249230769230768\n",
      "GradientBoosting - Mean Confusion Matrix:\n",
      "[[6.8 5.8]\n",
      " [6.5 6.8]]\n",
      "AdaBoost - Mean CV Score: 0.5713846153846154\n",
      "AdaBoost - Mean Confusion Matrix:\n",
      "[[7.2 5.4]\n",
      " [5.7 7.6]]\n",
      "NaiveBayes - Mean CV Score: 0.5478461538461539\n",
      "NaiveBayes - Mean Confusion Matrix:\n",
      "[[10.6  2. ]\n",
      " [ 9.7  3.6]]\n",
      "DecisionTree - Mean CV Score: 0.5061538461538462\n",
      "DecisionTree - Mean Confusion Matrix:\n",
      "[[5.7 6.9]\n",
      " [5.9 7.4]]\n",
      "ExtraTrees - Mean CV Score: 0.6216923076923077\n",
      "ExtraTrees - Mean Confusion Matrix:\n",
      "[[7.9 4.7]\n",
      " [5.1 8.2]]\n",
      "XGBoost - Mean CV Score: 0.5984615384615385\n",
      "XGBoost - Mean Confusion Matrix:\n",
      "[[7.3 5.3]\n",
      " [5.1 8.2]]\n",
      "Size: bottleneck_6, Best classifier: RandomForest, CV Score: 0.6293846153846153\n",
      "Epoch 1/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0332 \n",
      "Epoch 1: val_loss improved from inf to 0.02538, saving model to model\\WAE_bottleneck_10_best_model.keras\n",
      "26/26 [==============================] - 1s 11ms/step - loss: 0.0321 - val_loss: 0.0254\n",
      "Epoch 2/40\n",
      "11/26 [===========>..................] - ETA: 0s - loss: 0.0241\n",
      "Epoch 2: val_loss improved from 0.02538 to 0.02386, saving model to model\\WAE_bottleneck_10_best_model.keras\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0232 - val_loss: 0.0239\n",
      "Epoch 3/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0226\n",
      "Epoch 3: val_loss improved from 0.02386 to 0.02244, saving model to model\\WAE_bottleneck_10_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0224 - val_loss: 0.0224\n",
      "Epoch 4/40\n",
      "16/26 [=================>............] - ETA: 0s - loss: 0.0203\n",
      "Epoch 4: val_loss improved from 0.02244 to 0.02027, saving model to model\\WAE_bottleneck_10_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0203 - val_loss: 0.0203\n",
      "Epoch 5/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0192\n",
      "Epoch 5: val_loss improved from 0.02027 to 0.01957, saving model to model\\WAE_bottleneck_10_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0191 - val_loss: 0.0196\n",
      "Epoch 6/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0189\n",
      "Epoch 6: val_loss improved from 0.01957 to 0.01954, saving model to model\\WAE_bottleneck_10_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0188 - val_loss: 0.0195\n",
      "Epoch 7/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0187\n",
      "Epoch 7: val_loss improved from 0.01954 to 0.01920, saving model to model\\WAE_bottleneck_10_best_model.keras\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 0.0186 - val_loss: 0.0192\n",
      "Epoch 8/40\n",
      "21/26 [=======================>......] - ETA: 0s - loss: 0.0182\n",
      "Epoch 8: val_loss improved from 0.01920 to 0.01913, saving model to model\\WAE_bottleneck_10_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0184 - val_loss: 0.0191\n",
      "Epoch 9/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0182\n",
      "Epoch 9: val_loss improved from 0.01913 to 0.01900, saving model to model\\WAE_bottleneck_10_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0183 - val_loss: 0.0190\n",
      "Epoch 10/40\n",
      "21/26 [=======================>......] - ETA: 0s - loss: 0.0184\n",
      "Epoch 10: val_loss did not improve from 0.01900\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0182 - val_loss: 0.0190\n",
      "Epoch 11/40\n",
      "21/26 [=======================>......] - ETA: 0s - loss: 0.0178\n",
      "Epoch 11: val_loss did not improve from 0.01900\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0181 - val_loss: 0.0190\n",
      "Epoch 12/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0182\n",
      "Epoch 12: val_loss improved from 0.01900 to 0.01857, saving model to model\\WAE_bottleneck_10_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0180 - val_loss: 0.0186\n",
      "Epoch 13/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0177\n",
      "Epoch 13: val_loss improved from 0.01857 to 0.01804, saving model to model\\WAE_bottleneck_10_best_model.keras\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0173 - val_loss: 0.0180\n",
      "Epoch 14/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0165\n",
      "Epoch 14: val_loss improved from 0.01804 to 0.01786, saving model to model\\WAE_bottleneck_10_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0166 - val_loss: 0.0179\n",
      "Epoch 15/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0165\n",
      "Epoch 15: val_loss improved from 0.01786 to 0.01753, saving model to model\\WAE_bottleneck_10_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0165 - val_loss: 0.0175\n",
      "Epoch 16/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0162\n",
      "Epoch 16: val_loss improved from 0.01753 to 0.01753, saving model to model\\WAE_bottleneck_10_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0163 - val_loss: 0.0175\n",
      "Epoch 17/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0162\n",
      "Epoch 17: val_loss improved from 0.01753 to 0.01752, saving model to model\\WAE_bottleneck_10_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0159 - val_loss: 0.0175\n",
      "Epoch 18/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0157\n",
      "Epoch 18: val_loss improved from 0.01752 to 0.01750, saving model to model\\WAE_bottleneck_10_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0158 - val_loss: 0.0175\n",
      "Epoch 19/40\n",
      "13/26 [==============>...............] - ETA: 0s - loss: 0.0158\n",
      "Epoch 19: val_loss improved from 0.01750 to 0.01698, saving model to model\\WAE_bottleneck_10_best_model.keras\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 0.0156 - val_loss: 0.0170\n",
      "Epoch 20/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0150\n",
      "Epoch 20: val_loss did not improve from 0.01698\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0153 - val_loss: 0.0171\n",
      "Epoch 21/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0150\n",
      "Epoch 21: val_loss improved from 0.01698 to 0.01663, saving model to model\\WAE_bottleneck_10_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0149 - val_loss: 0.0166\n",
      "Epoch 22/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0146\n",
      "Epoch 22: val_loss did not improve from 0.01663\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0147 - val_loss: 0.0167\n",
      "Epoch 23/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0146\n",
      "Epoch 23: val_loss improved from 0.01663 to 0.01643, saving model to model\\WAE_bottleneck_10_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0146 - val_loss: 0.0164\n",
      "Epoch 24/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0144\n",
      "Epoch 24: val_loss did not improve from 0.01643\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0144 - val_loss: 0.0164\n",
      "Epoch 25/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0142\n",
      "Epoch 25: val_loss improved from 0.01643 to 0.01638, saving model to model\\WAE_bottleneck_10_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0143 - val_loss: 0.0164\n",
      "Epoch 26/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0140\n",
      "Epoch 26: val_loss improved from 0.01638 to 0.01634, saving model to model\\WAE_bottleneck_10_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0142 - val_loss: 0.0163\n",
      "Epoch 27/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0142\n",
      "Epoch 27: val_loss did not improve from 0.01634\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0142 - val_loss: 0.0165\n",
      "Epoch 28/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0140\n",
      "Epoch 28: val_loss did not improve from 0.01634\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0140 - val_loss: 0.0164\n",
      "Epoch 29/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0142\n",
      "Epoch 29: val_loss improved from 0.01634 to 0.01627, saving model to model\\WAE_bottleneck_10_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0140 - val_loss: 0.0163\n",
      "Epoch 30/40\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0137\n",
      "Epoch 30: val_loss did not improve from 0.01627\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0137 - val_loss: 0.0163\n",
      "Epoch 31/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0136\n",
      "Epoch 31: val_loss did not improve from 0.01627\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0136 - val_loss: 0.0163\n",
      "Epoch 32/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0136\n",
      "Epoch 32: val_loss did not improve from 0.01627\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0136 - val_loss: 0.0163\n",
      "Epoch 33/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0130\n",
      "Epoch 33: val_loss improved from 0.01627 to 0.01606, saving model to model\\WAE_bottleneck_10_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0133 - val_loss: 0.0161\n",
      "Epoch 34/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0131\n",
      "Epoch 34: val_loss did not improve from 0.01606\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0132 - val_loss: 0.0162\n",
      "Epoch 35/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0131\n",
      "Epoch 35: val_loss did not improve from 0.01606\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0132 - val_loss: 0.0163\n",
      "Epoch 36/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0130\n",
      "Epoch 36: val_loss improved from 0.01606 to 0.01606, saving model to model\\WAE_bottleneck_10_best_model.keras\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 0.0130 - val_loss: 0.0161\n",
      "Epoch 37/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0126\n",
      "Epoch 37: val_loss improved from 0.01606 to 0.01587, saving model to model\\WAE_bottleneck_10_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0127 - val_loss: 0.0159\n",
      "Epoch 38/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0125\n",
      "Epoch 38: val_loss did not improve from 0.01587\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0127 - val_loss: 0.0159\n",
      "Epoch 39/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0127\n",
      "Epoch 39: val_loss did not improve from 0.01587\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0126 - val_loss: 0.0159\n",
      "Epoch 40/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0123\n",
      "Epoch 40: val_loss improved from 0.01587 to 0.01581, saving model to model\\WAE_bottleneck_10_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0123 - val_loss: 0.0158\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "LogisticRegression - Mean CV Score: 0.579076923076923\n",
      "LogisticRegression - Mean Confusion Matrix:\n",
      "[[6.8 5.8]\n",
      " [5.1 8.2]]\n",
      "SVM - Mean CV Score: 0.5598461538461539\n",
      "SVM - Mean Confusion Matrix:\n",
      "[[7.2 5.4]\n",
      " [6.  7.3]]\n",
      "RandomForest - Mean CV Score: 0.6252307692307693\n",
      "RandomForest - Mean Confusion Matrix:\n",
      "[[7.4 5.2]\n",
      " [4.5 8.8]]\n",
      "KNN - Mean CV Score: 0.584\n",
      "KNN - Mean Confusion Matrix:\n",
      "[[8.  4.6]\n",
      " [6.2 7.1]]\n",
      "GradientBoosting - Mean CV Score: 0.61\n",
      "GradientBoosting - Mean Confusion Matrix:\n",
      "[[7.5 5.1]\n",
      " [5.  8.3]]\n",
      "AdaBoost - Mean CV Score: 0.5906153846153848\n",
      "AdaBoost - Mean Confusion Matrix:\n",
      "[[7.6 5. ]\n",
      " [5.6 7.7]]\n",
      "NaiveBayes - Mean CV Score: 0.4978461538461539\n",
      "NaiveBayes - Mean Confusion Matrix:\n",
      "[[12.5  0.1]\n",
      " [12.9  0.4]]\n",
      "DecisionTree - Mean CV Score: 0.5636923076923077\n",
      "DecisionTree - Mean Confusion Matrix:\n",
      "[[6.8 5.8]\n",
      " [5.5 7.8]]\n",
      "ExtraTrees - Mean CV Score: 0.6290769230769231\n",
      "ExtraTrees - Mean Confusion Matrix:\n",
      "[[8.1 4.5]\n",
      " [5.1 8.2]]\n",
      "XGBoost - Mean CV Score: 0.602\n",
      "XGBoost - Mean Confusion Matrix:\n",
      "[[7.1 5.5]\n",
      " [4.8 8.5]]\n",
      "Size: bottleneck_10, Best classifier: ExtraTrees, CV Score: 0.6290769230769231\n",
      "Epoch 1/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0320 \n",
      "Epoch 1: val_loss improved from inf to 0.02473, saving model to model\\WAE_bottleneck_14_best_model.keras\n",
      "26/26 [==============================] - 1s 12ms/step - loss: 0.0313 - val_loss: 0.0247\n",
      "Epoch 2/40\n",
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0227\n",
      "Epoch 2: val_loss improved from 0.02473 to 0.02346, saving model to model\\WAE_bottleneck_14_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0228 - val_loss: 0.0235\n",
      "Epoch 3/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0211\n",
      "Epoch 3: val_loss improved from 0.02346 to 0.02053, saving model to model\\WAE_bottleneck_14_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0213 - val_loss: 0.0205\n",
      "Epoch 4/40\n",
      "19/26 [====================>.........] - ETA: 0s - loss: 0.0194\n",
      "Epoch 4: val_loss improved from 0.02053 to 0.01902, saving model to model\\WAE_bottleneck_14_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0190 - val_loss: 0.0190\n",
      "Epoch 5/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0180\n",
      "Epoch 5: val_loss improved from 0.01902 to 0.01844, saving model to model\\WAE_bottleneck_14_best_model.keras\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 0.0178 - val_loss: 0.0184\n",
      "Epoch 6/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0169\n",
      "Epoch 6: val_loss improved from 0.01844 to 0.01781, saving model to model\\WAE_bottleneck_14_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0172 - val_loss: 0.0178\n",
      "Epoch 7/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0166\n",
      "Epoch 7: val_loss improved from 0.01781 to 0.01775, saving model to model\\WAE_bottleneck_14_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0167 - val_loss: 0.0178\n",
      "Epoch 8/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0165\n",
      "Epoch 8: val_loss improved from 0.01775 to 0.01748, saving model to model\\WAE_bottleneck_14_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0165 - val_loss: 0.0175\n",
      "Epoch 9/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0161\n",
      "Epoch 9: val_loss improved from 0.01748 to 0.01733, saving model to model\\WAE_bottleneck_14_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0162 - val_loss: 0.0173\n",
      "Epoch 10/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0159\n",
      "Epoch 10: val_loss improved from 0.01733 to 0.01711, saving model to model\\WAE_bottleneck_14_best_model.keras\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 0.0160 - val_loss: 0.0171\n",
      "Epoch 11/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0153\n",
      "Epoch 11: val_loss improved from 0.01711 to 0.01694, saving model to model\\WAE_bottleneck_14_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0155 - val_loss: 0.0169\n",
      "Epoch 12/40\n",
      "21/26 [=======================>......] - ETA: 0s - loss: 0.0154\n",
      "Epoch 12: val_loss improved from 0.01694 to 0.01653, saving model to model\\WAE_bottleneck_14_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0150 - val_loss: 0.0165\n",
      "Epoch 13/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0147\n",
      "Epoch 13: val_loss did not improve from 0.01653\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0147 - val_loss: 0.0167\n",
      "Epoch 14/40\n",
      "21/26 [=======================>......] - ETA: 0s - loss: 0.0145\n",
      "Epoch 14: val_loss improved from 0.01653 to 0.01636, saving model to model\\WAE_bottleneck_14_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0145 - val_loss: 0.0164\n",
      "Epoch 15/40\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0144\n",
      "Epoch 15: val_loss did not improve from 0.01636\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0144 - val_loss: 0.0164\n",
      "Epoch 16/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0143\n",
      "Epoch 16: val_loss improved from 0.01636 to 0.01629, saving model to model\\WAE_bottleneck_14_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0142 - val_loss: 0.0163\n",
      "Epoch 17/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0139\n",
      "Epoch 17: val_loss improved from 0.01629 to 0.01606, saving model to model\\WAE_bottleneck_14_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0139 - val_loss: 0.0161\n",
      "Epoch 18/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0136\n",
      "Epoch 18: val_loss improved from 0.01606 to 0.01599, saving model to model\\WAE_bottleneck_14_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0137 - val_loss: 0.0160\n",
      "Epoch 19/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0132\n",
      "Epoch 19: val_loss improved from 0.01599 to 0.01587, saving model to model\\WAE_bottleneck_14_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0135 - val_loss: 0.0159\n",
      "Epoch 20/40\n",
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0132\n",
      "Epoch 20: val_loss improved from 0.01587 to 0.01578, saving model to model\\WAE_bottleneck_14_best_model.keras\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0132 - val_loss: 0.0158\n",
      "Epoch 21/40\n",
      "19/26 [====================>.........] - ETA: 0s - loss: 0.0129\n",
      "Epoch 21: val_loss improved from 0.01578 to 0.01557, saving model to model\\WAE_bottleneck_14_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0129 - val_loss: 0.0156\n",
      "Epoch 22/40\n",
      "21/26 [=======================>......] - ETA: 0s - loss: 0.0128\n",
      "Epoch 22: val_loss did not improve from 0.01557\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0128 - val_loss: 0.0158\n",
      "Epoch 23/40\n",
      "21/26 [=======================>......] - ETA: 0s - loss: 0.0125\n",
      "Epoch 23: val_loss improved from 0.01557 to 0.01551, saving model to model\\WAE_bottleneck_14_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0126 - val_loss: 0.0155\n",
      "Epoch 24/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0123\n",
      "Epoch 24: val_loss did not improve from 0.01551\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0123 - val_loss: 0.0158\n",
      "Epoch 25/40\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0121\n",
      "Epoch 25: val_loss improved from 0.01551 to 0.01539, saving model to model\\WAE_bottleneck_14_best_model.keras\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0121 - val_loss: 0.0154\n",
      "Epoch 26/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0121\n",
      "Epoch 26: val_loss did not improve from 0.01539\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 27/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0116\n",
      "Epoch 27: val_loss improved from 0.01539 to 0.01533, saving model to model\\WAE_bottleneck_14_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0118 - val_loss: 0.0153\n",
      "Epoch 28/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0116\n",
      "Epoch 28: val_loss did not improve from 0.01533\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0117 - val_loss: 0.0156\n",
      "Epoch 29/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0117\n",
      "Epoch 29: val_loss did not improve from 0.01533\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0117 - val_loss: 0.0154\n",
      "Epoch 30/40\n",
      "11/26 [===========>..................] - ETA: 0s - loss: 0.0116\n",
      "Epoch 30: val_loss did not improve from 0.01533\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0115 - val_loss: 0.0155\n",
      "Epoch 31/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0115\n",
      "Epoch 31: val_loss did not improve from 0.01533\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0115 - val_loss: 0.0154\n",
      "Epoch 32/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0115\n",
      "Epoch 32: val_loss did not improve from 0.01533\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0114 - val_loss: 0.0153\n",
      "Epoch 33/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0112\n",
      "Epoch 33: val_loss did not improve from 0.01533\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0112 - val_loss: 0.0155\n",
      "Epoch 34/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0110\n",
      "Epoch 34: val_loss did not improve from 0.01533\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0111 - val_loss: 0.0157\n",
      "Epoch 35/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0109\n",
      "Epoch 35: val_loss improved from 0.01533 to 0.01531, saving model to model\\WAE_bottleneck_14_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0110 - val_loss: 0.0153\n",
      "Epoch 36/40\n",
      "15/26 [================>.............] - ETA: 0s - loss: 0.0111\n",
      "Epoch 36: val_loss did not improve from 0.01531\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0108 - val_loss: 0.0155\n",
      "Epoch 37/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0108\n",
      "Epoch 37: val_loss did not improve from 0.01531\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0108 - val_loss: 0.0157\n",
      "Epoch 38/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0107\n",
      "Epoch 38: val_loss did not improve from 0.01531\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0108 - val_loss: 0.0155\n",
      "Epoch 39/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0105\n",
      "Epoch 39: val_loss did not improve from 0.01531\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0105 - val_loss: 0.0156\n",
      "Epoch 40/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0106\n",
      "Epoch 40: val_loss did not improve from 0.01531\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0105 - val_loss: 0.0155\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "LogisticRegression - Mean CV Score: 0.5753846153846153\n",
      "LogisticRegression - Mean Confusion Matrix:\n",
      "[[7.  5.6]\n",
      " [5.4 7.9]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM - Mean CV Score: 0.5987692307692308\n",
      "SVM - Mean Confusion Matrix:\n",
      "[[7.  5.6]\n",
      " [4.8 8.5]]\n",
      "RandomForest - Mean CV Score: 0.6255384615384616\n",
      "RandomForest - Mean Confusion Matrix:\n",
      "[[7.4 5.2]\n",
      " [4.5 8.8]]\n",
      "KNN - Mean CV Score: 0.6295384615384615\n",
      "KNN - Mean Confusion Matrix:\n",
      "[[8.7 3.9]\n",
      " [5.7 7.6]]\n",
      "GradientBoosting - Mean CV Score: 0.6143076923076923\n",
      "GradientBoosting - Mean Confusion Matrix:\n",
      "[[7.6 5. ]\n",
      " [5.  8.3]]\n",
      "AdaBoost - Mean CV Score: 0.5949230769230768\n",
      "AdaBoost - Mean Confusion Matrix:\n",
      "[[7.8 4.8]\n",
      " [5.7 7.6]]\n",
      "NaiveBayes - Mean CV Score: 0.5907692307692307\n",
      "NaiveBayes - Mean Confusion Matrix:\n",
      "[[8.1 4.5]\n",
      " [6.1 7.2]]\n",
      "DecisionTree - Mean CV Score: 0.5364615384615385\n",
      "DecisionTree - Mean Confusion Matrix:\n",
      "[[6.8 5.8]\n",
      " [6.2 7.1]]\n",
      "ExtraTrees - Mean CV Score: 0.6024615384615385\n",
      "ExtraTrees - Mean Confusion Matrix:\n",
      "[[7.6 5. ]\n",
      " [5.3 8. ]]\n",
      "XGBoost - Mean CV Score: 0.6446153846153846\n",
      "XGBoost - Mean Confusion Matrix:\n",
      "[[8.  4.6]\n",
      " [4.6 8.7]]\n",
      "Size: bottleneck_14, Best classifier: XGBoost, CV Score: 0.6446153846153846\n",
      "Epoch 1/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0318 \n",
      "Epoch 1: val_loss improved from inf to 0.02494, saving model to model\\WAE_bottleneck_18_best_model.keras\n",
      "26/26 [==============================] - 1s 11ms/step - loss: 0.0309 - val_loss: 0.0249\n",
      "Epoch 2/40\n",
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0228\n",
      "Epoch 2: val_loss improved from 0.02494 to 0.02262, saving model to model\\WAE_bottleneck_18_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0226 - val_loss: 0.0226\n",
      "Epoch 3/40\n",
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0203\n",
      "Epoch 3: val_loss improved from 0.02262 to 0.02049, saving model to model\\WAE_bottleneck_18_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0202 - val_loss: 0.0205\n",
      "Epoch 4/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0191\n",
      "Epoch 4: val_loss improved from 0.02049 to 0.01952, saving model to model\\WAE_bottleneck_18_best_model.keras\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 0.0189 - val_loss: 0.0195\n",
      "Epoch 5/40\n",
      "17/26 [==================>...........] - ETA: 0s - loss: 0.0181\n",
      "Epoch 5: val_loss improved from 0.01952 to 0.01904, saving model to model\\WAE_bottleneck_18_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0185 - val_loss: 0.0190\n",
      "Epoch 6/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0175\n",
      "Epoch 6: val_loss improved from 0.01904 to 0.01819, saving model to model\\WAE_bottleneck_18_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0176 - val_loss: 0.0182\n",
      "Epoch 7/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0170\n",
      "Epoch 7: val_loss improved from 0.01819 to 0.01796, saving model to model\\WAE_bottleneck_18_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0169 - val_loss: 0.0180\n",
      "Epoch 8/40\n",
      "21/26 [=======================>......] - ETA: 0s - loss: 0.0168\n",
      "Epoch 8: val_loss improved from 0.01796 to 0.01778, saving model to model\\WAE_bottleneck_18_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0166 - val_loss: 0.0178\n",
      "Epoch 9/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0164\n",
      "Epoch 9: val_loss improved from 0.01778 to 0.01762, saving model to model\\WAE_bottleneck_18_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0163 - val_loss: 0.0176\n",
      "Epoch 10/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0158\n",
      "Epoch 10: val_loss improved from 0.01762 to 0.01731, saving model to model\\WAE_bottleneck_18_best_model.keras\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0159 - val_loss: 0.0173\n",
      "Epoch 11/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0153\n",
      "Epoch 11: val_loss improved from 0.01731 to 0.01696, saving model to model\\WAE_bottleneck_18_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0156 - val_loss: 0.0170\n",
      "Epoch 12/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0151\n",
      "Epoch 12: val_loss improved from 0.01696 to 0.01692, saving model to model\\WAE_bottleneck_18_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0151 - val_loss: 0.0169\n",
      "Epoch 13/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0150\n",
      "Epoch 13: val_loss improved from 0.01692 to 0.01681, saving model to model\\WAE_bottleneck_18_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0149 - val_loss: 0.0168\n",
      "Epoch 14/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0150\n",
      "Epoch 14: val_loss did not improve from 0.01681\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0149 - val_loss: 0.0168\n",
      "Epoch 15/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0147\n",
      "Epoch 15: val_loss improved from 0.01681 to 0.01637, saving model to model\\WAE_bottleneck_18_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0147 - val_loss: 0.0164\n",
      "Epoch 16/40\n",
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0143\n",
      "Epoch 16: val_loss did not improve from 0.01637\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0141 - val_loss: 0.0164\n",
      "Epoch 17/40\n",
      "14/26 [===============>..............] - ETA: 0s - loss: 0.0142\n",
      "Epoch 17: val_loss improved from 0.01637 to 0.01599, saving model to model\\WAE_bottleneck_18_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0138 - val_loss: 0.0160\n",
      "Epoch 18/40\n",
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0133\n",
      "Epoch 18: val_loss improved from 0.01599 to 0.01581, saving model to model\\WAE_bottleneck_18_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0133 - val_loss: 0.0158\n",
      "Epoch 19/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0130\n",
      "Epoch 19: val_loss improved from 0.01581 to 0.01549, saving model to model\\WAE_bottleneck_18_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0131 - val_loss: 0.0155\n",
      "Epoch 20/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0127\n",
      "Epoch 20: val_loss improved from 0.01549 to 0.01546, saving model to model\\WAE_bottleneck_18_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0129 - val_loss: 0.0155\n",
      "Epoch 21/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0126\n",
      "Epoch 21: val_loss improved from 0.01546 to 0.01538, saving model to model\\WAE_bottleneck_18_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0126 - val_loss: 0.0154\n",
      "Epoch 22/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0124\n",
      "Epoch 22: val_loss did not improve from 0.01538\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0124 - val_loss: 0.0154\n",
      "Epoch 23/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0122\n",
      "Epoch 23: val_loss improved from 0.01538 to 0.01514, saving model to model\\WAE_bottleneck_18_best_model.keras\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 0.0123 - val_loss: 0.0151\n",
      "Epoch 24/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0120\n",
      "Epoch 24: val_loss did not improve from 0.01514\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0122 - val_loss: 0.0153\n",
      "Epoch 25/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0118\n",
      "Epoch 25: val_loss did not improve from 0.01514\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0119 - val_loss: 0.0152\n",
      "Epoch 26/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0116\n",
      "Epoch 26: val_loss did not improve from 0.01514\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0117 - val_loss: 0.0152\n",
      "Epoch 27/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0116\n",
      "Epoch 27: val_loss improved from 0.01514 to 0.01500, saving model to model\\WAE_bottleneck_18_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0116 - val_loss: 0.0150\n",
      "Epoch 28/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0111\n",
      "Epoch 28: val_loss improved from 0.01500 to 0.01487, saving model to model\\WAE_bottleneck_18_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0113 - val_loss: 0.0149\n",
      "Epoch 29/40\n",
      "12/26 [============>.................] - ETA: 0s - loss: 0.0115\n",
      "Epoch 29: val_loss did not improve from 0.01487\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0113 - val_loss: 0.0151\n",
      "Epoch 30/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0112\n",
      "Epoch 30: val_loss improved from 0.01487 to 0.01474, saving model to model\\WAE_bottleneck_18_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0112 - val_loss: 0.0147\n",
      "Epoch 31/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0107\n",
      "Epoch 31: val_loss did not improve from 0.01474\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0109 - val_loss: 0.0149\n",
      "Epoch 32/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0107\n",
      "Epoch 32: val_loss did not improve from 0.01474\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0107 - val_loss: 0.0149\n",
      "Epoch 33/40\n",
      "20/26 [======================>.......] - ETA: 0s - loss: 0.0105\n",
      "Epoch 33: val_loss did not improve from 0.01474\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0106 - val_loss: 0.0148\n",
      "Epoch 34/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0102\n",
      "Epoch 34: val_loss did not improve from 0.01474\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0105 - val_loss: 0.0150\n",
      "Epoch 35/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0103\n",
      "Epoch 35: val_loss did not improve from 0.01474\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0104 - val_loss: 0.0150\n",
      "Epoch 36/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0104\n",
      "Epoch 36: val_loss did not improve from 0.01474\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0104 - val_loss: 0.0150\n",
      "Epoch 37/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0102\n",
      "Epoch 37: val_loss did not improve from 0.01474\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0103 - val_loss: 0.0149\n",
      "Epoch 38/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0102\n",
      "Epoch 38: val_loss did not improve from 0.01474\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0102 - val_loss: 0.0148\n",
      "Epoch 39/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0100\n",
      "Epoch 39: val_loss did not improve from 0.01474\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.0148\n",
      "Epoch 40/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0098\n",
      "Epoch 40: val_loss improved from 0.01474 to 0.01474, saving model to model\\WAE_bottleneck_18_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0098 - val_loss: 0.0147\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "LogisticRegression - Mean CV Score: 0.6093846153846154\n",
      "LogisticRegression - Mean Confusion Matrix:\n",
      "[[7.8 4.8]\n",
      " [5.3 8. ]]\n",
      "SVM - Mean CV Score: 0.6023076923076923\n",
      "SVM - Mean Confusion Matrix:\n",
      "[[6.9 5.7]\n",
      " [4.6 8.7]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest - Mean CV Score: 0.6369230769230769\n",
      "RandomForest - Mean Confusion Matrix:\n",
      "[[7.6 5. ]\n",
      " [4.4 8.9]]\n",
      "KNN - Mean CV Score: 0.6293846153846154\n",
      "KNN - Mean Confusion Matrix:\n",
      "[[8.  4.6]\n",
      " [5.  8.3]]\n",
      "GradientBoosting - Mean CV Score: 0.6175384615384616\n",
      "GradientBoosting - Mean Confusion Matrix:\n",
      "[[7.4 5.2]\n",
      " [4.7 8.6]]\n",
      "AdaBoost - Mean CV Score: 0.6178461538461538\n",
      "AdaBoost - Mean Confusion Matrix:\n",
      "[[7.8 4.8]\n",
      " [5.1 8.2]]\n",
      "NaiveBayes - Mean CV Score: 0.6096923076923078\n",
      "NaiveBayes - Mean Confusion Matrix:\n",
      "[[9.4 3.2]\n",
      " [6.9 6.4]]\n",
      "DecisionTree - Mean CV Score: 0.5793846153846153\n",
      "DecisionTree - Mean Confusion Matrix:\n",
      "[[7.2 5.4]\n",
      " [5.5 7.8]]\n",
      "ExtraTrees - Mean CV Score: 0.6795384615384615\n",
      "ExtraTrees - Mean Confusion Matrix:\n",
      "[[8.3 4.3]\n",
      " [4.  9.3]]\n",
      "XGBoost - Mean CV Score: 0.5944615384615384\n",
      "XGBoost - Mean Confusion Matrix:\n",
      "[[7.3 5.3]\n",
      " [5.2 8.1]]\n",
      "Size: bottleneck_18, Best classifier: ExtraTrees, CV Score: 0.6795384615384615\n",
      "Epoch 1/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0329 \n",
      "Epoch 1: val_loss improved from inf to 0.02571, saving model to model\\WAE_bottleneck_22_best_model.keras\n",
      "26/26 [==============================] - 1s 11ms/step - loss: 0.0321 - val_loss: 0.0257\n",
      "Epoch 2/40\n",
      "12/26 [============>.................] - ETA: 0s - loss: 0.0228\n",
      "Epoch 2: val_loss improved from 0.02571 to 0.02404, saving model to model\\WAE_bottleneck_22_best_model.keras\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0232 - val_loss: 0.0240\n",
      "Epoch 3/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0226\n",
      "Epoch 3: val_loss improved from 0.02404 to 0.02315, saving model to model\\WAE_bottleneck_22_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0226 - val_loss: 0.0231\n",
      "Epoch 4/40\n",
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0209\n",
      "Epoch 4: val_loss improved from 0.02315 to 0.02056, saving model to model\\WAE_bottleneck_22_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0209 - val_loss: 0.0206\n",
      "Epoch 5/40\n",
      "18/26 [===================>..........] - ETA: 0s - loss: 0.0189\n",
      "Epoch 5: val_loss improved from 0.02056 to 0.01969, saving model to model\\WAE_bottleneck_22_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0191 - val_loss: 0.0197\n",
      "Epoch 6/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0188\n",
      "Epoch 6: val_loss improved from 0.01969 to 0.01923, saving model to model\\WAE_bottleneck_22_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0188 - val_loss: 0.0192\n",
      "Epoch 7/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0179\n",
      "Epoch 7: val_loss improved from 0.01923 to 0.01858, saving model to model\\WAE_bottleneck_22_best_model.keras\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0182 - val_loss: 0.0186\n",
      "Epoch 8/40\n",
      "19/26 [====================>.........] - ETA: 0s - loss: 0.0168\n",
      "Epoch 8: val_loss improved from 0.01858 to 0.01795, saving model to model\\WAE_bottleneck_22_best_model.keras\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0173 - val_loss: 0.0179\n",
      "Epoch 9/40\n",
      "19/26 [====================>.........] - ETA: 0s - loss: 0.0168\n",
      "Epoch 9: val_loss improved from 0.01795 to 0.01773, saving model to model\\WAE_bottleneck_22_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0169 - val_loss: 0.0177\n",
      "Epoch 10/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0167\n",
      "Epoch 10: val_loss improved from 0.01773 to 0.01758, saving model to model\\WAE_bottleneck_22_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0166 - val_loss: 0.0176\n",
      "Epoch 11/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0165\n",
      "Epoch 11: val_loss improved from 0.01758 to 0.01751, saving model to model\\WAE_bottleneck_22_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0164 - val_loss: 0.0175\n",
      "Epoch 12/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0162\n",
      "Epoch 12: val_loss improved from 0.01751 to 0.01736, saving model to model\\WAE_bottleneck_22_best_model.keras\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0161 - val_loss: 0.0174\n",
      "Epoch 13/40\n",
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0161\n",
      "Epoch 13: val_loss improved from 0.01736 to 0.01726, saving model to model\\WAE_bottleneck_22_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0160 - val_loss: 0.0173\n",
      "Epoch 14/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0159\n",
      "Epoch 14: val_loss did not improve from 0.01726\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0158 - val_loss: 0.0173\n",
      "Epoch 15/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0157\n",
      "Epoch 15: val_loss improved from 0.01726 to 0.01717, saving model to model\\WAE_bottleneck_22_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0157 - val_loss: 0.0172\n",
      "Epoch 16/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0155\n",
      "Epoch 16: val_loss improved from 0.01717 to 0.01704, saving model to model\\WAE_bottleneck_22_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0155 - val_loss: 0.0170\n",
      "Epoch 17/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0151\n",
      "Epoch 17: val_loss improved from 0.01704 to 0.01699, saving model to model\\WAE_bottleneck_22_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0153 - val_loss: 0.0170\n",
      "Epoch 18/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0152\n",
      "Epoch 18: val_loss improved from 0.01699 to 0.01672, saving model to model\\WAE_bottleneck_22_best_model.keras\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0151 - val_loss: 0.0167\n",
      "Epoch 19/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0149\n",
      "Epoch 19: val_loss improved from 0.01672 to 0.01663, saving model to model\\WAE_bottleneck_22_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0148 - val_loss: 0.0166\n",
      "Epoch 20/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0145\n",
      "Epoch 20: val_loss improved from 0.01663 to 0.01633, saving model to model\\WAE_bottleneck_22_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0144 - val_loss: 0.0163\n",
      "Epoch 21/40\n",
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0142\n",
      "Epoch 21: val_loss improved from 0.01633 to 0.01611, saving model to model\\WAE_bottleneck_22_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0142 - val_loss: 0.0161\n",
      "Epoch 22/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0139\n",
      "Epoch 22: val_loss did not improve from 0.01611\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0140 - val_loss: 0.0162\n",
      "Epoch 23/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0135\n",
      "Epoch 23: val_loss improved from 0.01611 to 0.01582, saving model to model\\WAE_bottleneck_22_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0137 - val_loss: 0.0158\n",
      "Epoch 24/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0134\n",
      "Epoch 24: val_loss improved from 0.01582 to 0.01566, saving model to model\\WAE_bottleneck_22_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0135 - val_loss: 0.0157\n",
      "Epoch 25/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0131\n",
      "Epoch 25: val_loss improved from 0.01566 to 0.01555, saving model to model\\WAE_bottleneck_22_best_model.keras\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0133 - val_loss: 0.0155\n",
      "Epoch 26/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0132\n",
      "Epoch 26: val_loss did not improve from 0.01555\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0130 - val_loss: 0.0157\n",
      "Epoch 27/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0128\n",
      "Epoch 27: val_loss did not improve from 0.01555\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0129 - val_loss: 0.0156\n",
      "Epoch 28/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0127\n",
      "Epoch 28: val_loss improved from 0.01555 to 0.01553, saving model to model\\WAE_bottleneck_22_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0129 - val_loss: 0.0155\n",
      "Epoch 29/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0128\n",
      "Epoch 29: val_loss did not improve from 0.01553\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0127 - val_loss: 0.0159\n",
      "Epoch 30/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0126\n",
      "Epoch 30: val_loss did not improve from 0.01553\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0126 - val_loss: 0.0157\n",
      "Epoch 31/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0124\n",
      "Epoch 31: val_loss did not improve from 0.01553\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0124 - val_loss: 0.0156\n",
      "Epoch 32/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0122\n",
      "Epoch 32: val_loss did not improve from 0.01553\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0123 - val_loss: 0.0156\n",
      "Epoch 33/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0123\n",
      "Epoch 33: val_loss did not improve from 0.01553\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 34/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0122\n",
      "Epoch 34: val_loss did not improve from 0.01553\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0120 - val_loss: 0.0157\n",
      "Epoch 35/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0118\n",
      "Epoch 35: val_loss did not improve from 0.01553\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0119 - val_loss: 0.0156\n",
      "Epoch 36/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0115\n",
      "Epoch 36: val_loss did not improve from 0.01553\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0118 - val_loss: 0.0156\n",
      "Epoch 37/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0116\n",
      "Epoch 37: val_loss did not improve from 0.01553\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0117 - val_loss: 0.0156\n",
      "Epoch 38/40\n",
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0115\n",
      "Epoch 38: val_loss improved from 0.01553 to 0.01546, saving model to model\\WAE_bottleneck_22_best_model.keras\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 0.0115 - val_loss: 0.0155\n",
      "Epoch 39/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0115\n",
      "Epoch 39: val_loss did not improve from 0.01546\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0114 - val_loss: 0.0156\n",
      "Epoch 40/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0112\n",
      "Epoch 40: val_loss did not improve from 0.01546\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0113 - val_loss: 0.0155\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "LogisticRegression - Mean CV Score: 0.5713846153846154\n",
      "LogisticRegression - Mean Confusion Matrix:\n",
      "[[7.  5.6]\n",
      " [5.5 7.8]]\n",
      "SVM - Mean CV Score: 0.583076923076923\n",
      "SVM - Mean Confusion Matrix:\n",
      "[[6.6 6. ]\n",
      " [4.8 8.5]]\n",
      "RandomForest - Mean CV Score: 0.6060000000000001\n",
      "RandomForest - Mean Confusion Matrix:\n",
      "[[7.1 5.5]\n",
      " [4.7 8.6]]\n",
      "KNN - Mean CV Score: 0.5866153846153846\n",
      "KNN - Mean Confusion Matrix:\n",
      "[[8.1 4.5]\n",
      " [6.2 7.1]]\n",
      "GradientBoosting - Mean CV Score: 0.578923076923077\n",
      "GradientBoosting - Mean Confusion Matrix:\n",
      "[[6.5 6.1]\n",
      " [4.8 8.5]]\n",
      "AdaBoost - Mean CV Score: 0.5367692307692307\n",
      "AdaBoost - Mean Confusion Matrix:\n",
      "[[7.2 5.4]\n",
      " [6.6 6.7]]\n",
      "NaiveBayes - Mean CV Score: 0.5481538461538461\n",
      "NaiveBayes - Mean Confusion Matrix:\n",
      "[[10.2  2.4]\n",
      " [ 9.3  4. ]]\n",
      "DecisionTree - Mean CV Score: 0.6056923076923078\n",
      "DecisionTree - Mean Confusion Matrix:\n",
      "[[7.2 5.4]\n",
      " [4.8 8.5]]\n",
      "ExtraTrees - Mean CV Score: 0.5866153846153846\n",
      "ExtraTrees - Mean Confusion Matrix:\n",
      "[[7.1 5.5]\n",
      " [5.2 8.1]]\n",
      "XGBoost - Mean CV Score: 0.5713846153846154\n",
      "XGBoost - Mean Confusion Matrix:\n",
      "[[6.7 5.9]\n",
      " [5.2 8.1]]\n",
      "Size: bottleneck_22, Best classifier: RandomForest, CV Score: 0.6060000000000001\n",
      "Epoch 1/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0336 \n",
      "Epoch 1: val_loss improved from inf to 0.02579, saving model to model\\WAE_bottleneck_26_best_model.keras\n",
      "26/26 [==============================] - 1s 12ms/step - loss: 0.0321 - val_loss: 0.0258\n",
      "Epoch 2/40\n",
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0231\n",
      "Epoch 2: val_loss improved from 0.02579 to 0.02416, saving model to model\\WAE_bottleneck_26_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0231 - val_loss: 0.0242\n",
      "Epoch 3/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0217\n",
      "Epoch 3: val_loss improved from 0.02416 to 0.02156, saving model to model\\WAE_bottleneck_26_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0219 - val_loss: 0.0216\n",
      "Epoch 4/40\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0195\n",
      "Epoch 4: val_loss improved from 0.02156 to 0.01990, saving model to model\\WAE_bottleneck_26_best_model.keras\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 0.0195 - val_loss: 0.0199\n",
      "Epoch 5/40\n",
      "18/26 [===================>..........] - ETA: 0s - loss: 0.0189\n",
      "Epoch 5: val_loss improved from 0.01990 to 0.01942, saving model to model\\WAE_bottleneck_26_best_model.keras\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0188 - val_loss: 0.0194\n",
      "Epoch 6/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0184\n",
      "Epoch 6: val_loss improved from 0.01942 to 0.01882, saving model to model\\WAE_bottleneck_26_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0184 - val_loss: 0.0188\n",
      "Epoch 7/40\n",
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0176\n",
      "Epoch 7: val_loss improved from 0.01882 to 0.01835, saving model to model\\WAE_bottleneck_26_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0175 - val_loss: 0.0183\n",
      "Epoch 8/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0168\n",
      "Epoch 8: val_loss improved from 0.01835 to 0.01796, saving model to model\\WAE_bottleneck_26_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0169 - val_loss: 0.0180\n",
      "Epoch 9/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0167\n",
      "Epoch 9: val_loss improved from 0.01796 to 0.01785, saving model to model\\WAE_bottleneck_26_best_model.keras\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 0.0165 - val_loss: 0.0179\n",
      "Epoch 10/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0163\n",
      "Epoch 10: val_loss improved from 0.01785 to 0.01730, saving model to model\\WAE_bottleneck_26_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0162 - val_loss: 0.0173\n",
      "Epoch 11/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0156\n",
      "Epoch 11: val_loss improved from 0.01730 to 0.01696, saving model to model\\WAE_bottleneck_26_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0157 - val_loss: 0.0170\n",
      "Epoch 12/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0153\n",
      "Epoch 12: val_loss improved from 0.01696 to 0.01662, saving model to model\\WAE_bottleneck_26_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0154 - val_loss: 0.0166\n",
      "Epoch 13/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0148\n",
      "Epoch 13: val_loss improved from 0.01662 to 0.01660, saving model to model\\WAE_bottleneck_26_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0149 - val_loss: 0.0166\n",
      "Epoch 14/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0145\n",
      "Epoch 14: val_loss improved from 0.01660 to 0.01641, saving model to model\\WAE_bottleneck_26_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0146 - val_loss: 0.0164\n",
      "Epoch 15/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0144\n",
      "Epoch 15: val_loss improved from 0.01641 to 0.01630, saving model to model\\WAE_bottleneck_26_best_model.keras\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0143 - val_loss: 0.0163\n",
      "Epoch 16/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0141\n",
      "Epoch 16: val_loss improved from 0.01630 to 0.01610, saving model to model\\WAE_bottleneck_26_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0141 - val_loss: 0.0161\n",
      "Epoch 17/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0138\n",
      "Epoch 17: val_loss did not improve from 0.01610\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0139 - val_loss: 0.0161\n",
      "Epoch 18/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0140\n",
      "Epoch 18: val_loss improved from 0.01610 to 0.01609, saving model to model\\WAE_bottleneck_26_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0137 - val_loss: 0.0161\n",
      "Epoch 19/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0134\n",
      "Epoch 19: val_loss improved from 0.01609 to 0.01592, saving model to model\\WAE_bottleneck_26_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0135 - val_loss: 0.0159\n",
      "Epoch 20/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0132\n",
      "Epoch 20: val_loss improved from 0.01592 to 0.01587, saving model to model\\WAE_bottleneck_26_best_model.keras\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0132 - val_loss: 0.0159\n",
      "Epoch 21/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0132\n",
      "Epoch 21: val_loss improved from 0.01587 to 0.01582, saving model to model\\WAE_bottleneck_26_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0130 - val_loss: 0.0158\n",
      "Epoch 22/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0128\n",
      "Epoch 22: val_loss improved from 0.01582 to 0.01582, saving model to model\\WAE_bottleneck_26_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0129 - val_loss: 0.0158\n",
      "Epoch 23/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0127\n",
      "Epoch 23: val_loss improved from 0.01582 to 0.01575, saving model to model\\WAE_bottleneck_26_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0128 - val_loss: 0.0157\n",
      "Epoch 24/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0127\n",
      "Epoch 24: val_loss did not improve from 0.01575\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0126 - val_loss: 0.0158\n",
      "Epoch 25/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0125\n",
      "Epoch 25: val_loss improved from 0.01575 to 0.01565, saving model to model\\WAE_bottleneck_26_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0125 - val_loss: 0.0157\n",
      "Epoch 26/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0125\n",
      "Epoch 26: val_loss did not improve from 0.01565\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0124 - val_loss: 0.0157\n",
      "Epoch 27/40\n",
      "12/26 [============>.................] - ETA: 0s - loss: 0.0128\n",
      "Epoch 27: val_loss did not improve from 0.01565\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0124 - val_loss: 0.0157\n",
      "Epoch 28/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0120\n",
      "Epoch 28: val_loss improved from 0.01565 to 0.01556, saving model to model\\WAE_bottleneck_26_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0119 - val_loss: 0.0156\n",
      "Epoch 29/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0117\n",
      "Epoch 29: val_loss improved from 0.01556 to 0.01537, saving model to model\\WAE_bottleneck_26_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0117 - val_loss: 0.0154\n",
      "Epoch 30/40\n",
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0115\n",
      "Epoch 30: val_loss improved from 0.01537 to 0.01532, saving model to model\\WAE_bottleneck_26_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0115 - val_loss: 0.0153\n",
      "Epoch 31/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0114\n",
      "Epoch 31: val_loss improved from 0.01532 to 0.01523, saving model to model\\WAE_bottleneck_26_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0113 - val_loss: 0.0152\n",
      "Epoch 32/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0111\n",
      "Epoch 32: val_loss improved from 0.01523 to 0.01504, saving model to model\\WAE_bottleneck_26_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0111 - val_loss: 0.0150\n",
      "Epoch 33/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0109\n",
      "Epoch 33: val_loss did not improve from 0.01504\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0109 - val_loss: 0.0153\n",
      "Epoch 34/40\n",
      "19/26 [====================>.........] - ETA: 0s - loss: 0.0107\n",
      "Epoch 34: val_loss improved from 0.01504 to 0.01491, saving model to model\\WAE_bottleneck_26_best_model.keras\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0108 - val_loss: 0.0149\n",
      "Epoch 35/40\n",
      "21/26 [=======================>......] - ETA: 0s - loss: 0.0110\n",
      "Epoch 35: val_loss improved from 0.01491 to 0.01479, saving model to model\\WAE_bottleneck_26_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0107 - val_loss: 0.0148\n",
      "Epoch 36/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0104\n",
      "Epoch 36: val_loss did not improve from 0.01479\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0104 - val_loss: 0.0149\n",
      "Epoch 37/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0103\n",
      "Epoch 37: val_loss did not improve from 0.01479\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0103 - val_loss: 0.0150\n",
      "Epoch 38/40\n",
      "14/26 [===============>..............] - ETA: 0s - loss: 0.0103\n",
      "Epoch 38: val_loss did not improve from 0.01479\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0103 - val_loss: 0.0151\n",
      "Epoch 39/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0102\n",
      "Epoch 39: val_loss did not improve from 0.01479\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0102 - val_loss: 0.0149\n",
      "Epoch 40/40\n",
      "19/26 [====================>.........] - ETA: 0s - loss: 0.0098\n",
      "Epoch 40: val_loss did not improve from 0.01479\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0101 - val_loss: 0.0149\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "LogisticRegression - Mean CV Score: 0.5481538461538461\n",
      "LogisticRegression - Mean Confusion Matrix:\n",
      "[[6.6 6. ]\n",
      " [5.7 7.6]]\n",
      "SVM - Mean CV Score: 0.5947692307692307\n",
      "SVM - Mean Confusion Matrix:\n",
      "[[7.6 5. ]\n",
      " [5.5 7.8]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest - Mean CV Score: 0.5867692307692307\n",
      "RandomForest - Mean Confusion Matrix:\n",
      "[[7.3 5.3]\n",
      " [5.4 7.9]]\n",
      "KNN - Mean CV Score: 0.5869230769230769\n",
      "KNN - Mean Confusion Matrix:\n",
      "[[8.  4.6]\n",
      " [6.1 7.2]]\n",
      "GradientBoosting - Mean CV Score: 0.5643076923076923\n",
      "GradientBoosting - Mean Confusion Matrix:\n",
      "[[7.3 5.3]\n",
      " [6.  7.3]]\n",
      "AdaBoost - Mean CV Score: 0.5636923076923077\n",
      "AdaBoost - Mean Confusion Matrix:\n",
      "[[7.6 5. ]\n",
      " [6.3 7. ]]\n",
      "NaiveBayes - Mean CV Score: 0.4978461538461539\n",
      "NaiveBayes - Mean Confusion Matrix:\n",
      "[[12.5  0.1]\n",
      " [12.9  0.4]]\n",
      "DecisionTree - Mean CV Score: 0.5675384615384615\n",
      "DecisionTree - Mean Confusion Matrix:\n",
      "[[7.4 5.2]\n",
      " [6.  7.3]]\n",
      "ExtraTrees - Mean CV Score: 0.6024615384615384\n",
      "ExtraTrees - Mean Confusion Matrix:\n",
      "[[7.7 4.9]\n",
      " [5.4 7.9]]\n",
      "XGBoost - Mean CV Score: 0.5598461538461539\n",
      "XGBoost - Mean Confusion Matrix:\n",
      "[[6.9 5.7]\n",
      " [5.7 7.6]]\n",
      "Size: bottleneck_26, Best classifier: ExtraTrees, CV Score: 0.6024615384615384\n",
      "Epoch 1/40\n",
      "18/26 [===================>..........] - ETA: 0s - loss: 0.0323 \n",
      "Epoch 1: val_loss improved from inf to 0.02469, saving model to model\\WAE_bottleneck_30_best_model.keras\n",
      "26/26 [==============================] - 1s 12ms/step - loss: 0.0300 - val_loss: 0.0247\n",
      "Epoch 2/40\n",
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0231\n",
      "Epoch 2: val_loss improved from 0.02469 to 0.02340, saving model to model\\WAE_bottleneck_30_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0229 - val_loss: 0.0234\n",
      "Epoch 3/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0212\n",
      "Epoch 3: val_loss improved from 0.02340 to 0.02087, saving model to model\\WAE_bottleneck_30_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0214 - val_loss: 0.0209\n",
      "Epoch 4/40\n",
      "19/26 [====================>.........] - ETA: 0s - loss: 0.0197\n",
      "Epoch 4: val_loss improved from 0.02087 to 0.01992, saving model to model\\WAE_bottleneck_30_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0195 - val_loss: 0.0199\n",
      "Epoch 5/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0187\n",
      "Epoch 5: val_loss improved from 0.01992 to 0.01896, saving model to model\\WAE_bottleneck_30_best_model.keras\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0187 - val_loss: 0.0190\n",
      "Epoch 6/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0180\n",
      "Epoch 6: val_loss improved from 0.01896 to 0.01852, saving model to model\\WAE_bottleneck_30_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0179 - val_loss: 0.0185\n",
      "Epoch 7/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0173\n",
      "Epoch 7: val_loss improved from 0.01852 to 0.01784, saving model to model\\WAE_bottleneck_30_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0172 - val_loss: 0.0178\n",
      "Epoch 8/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0171\n",
      "Epoch 8: val_loss improved from 0.01784 to 0.01771, saving model to model\\WAE_bottleneck_30_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0169 - val_loss: 0.0177\n",
      "Epoch 9/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0166\n",
      "Epoch 9: val_loss improved from 0.01771 to 0.01753, saving model to model\\WAE_bottleneck_30_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0166 - val_loss: 0.0175\n",
      "Epoch 10/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0164\n",
      "Epoch 10: val_loss improved from 0.01753 to 0.01730, saving model to model\\WAE_bottleneck_30_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0163 - val_loss: 0.0173\n",
      "Epoch 11/40\n",
      "21/26 [=======================>......] - ETA: 0s - loss: 0.0162\n",
      "Epoch 11: val_loss improved from 0.01730 to 0.01709, saving model to model\\WAE_bottleneck_30_best_model.keras\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 0.0160 - val_loss: 0.0171\n",
      "Epoch 12/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0157\n",
      "Epoch 12: val_loss did not improve from 0.01709\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0158 - val_loss: 0.0171\n",
      "Epoch 13/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0160\n",
      "Epoch 13: val_loss improved from 0.01709 to 0.01684, saving model to model\\WAE_bottleneck_30_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0157 - val_loss: 0.0168\n",
      "Epoch 14/40\n",
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0152\n",
      "Epoch 14: val_loss improved from 0.01684 to 0.01665, saving model to model\\WAE_bottleneck_30_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0153 - val_loss: 0.0167\n",
      "Epoch 15/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0151\n",
      "Epoch 15: val_loss improved from 0.01665 to 0.01653, saving model to model\\WAE_bottleneck_30_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0150 - val_loss: 0.0165\n",
      "Epoch 16/40\n",
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0148\n",
      "Epoch 16: val_loss did not improve from 0.01653\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0149 - val_loss: 0.0169\n",
      "Epoch 17/40\n",
      "17/26 [==================>...........] - ETA: 0s - loss: 0.0149\n",
      "Epoch 17: val_loss improved from 0.01653 to 0.01630, saving model to model\\WAE_bottleneck_30_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0146 - val_loss: 0.0163\n",
      "Epoch 18/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0141\n",
      "Epoch 18: val_loss improved from 0.01630 to 0.01617, saving model to model\\WAE_bottleneck_30_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0142 - val_loss: 0.0162\n",
      "Epoch 19/40\n",
      "21/26 [=======================>......] - ETA: 0s - loss: 0.0141\n",
      "Epoch 19: val_loss improved from 0.01617 to 0.01587, saving model to model\\WAE_bottleneck_30_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0138 - val_loss: 0.0159\n",
      "Epoch 20/40\n",
      "19/26 [====================>.........] - ETA: 0s - loss: 0.0132\n",
      "Epoch 20: val_loss improved from 0.01587 to 0.01558, saving model to model\\WAE_bottleneck_30_best_model.keras\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0133 - val_loss: 0.0156\n",
      "Epoch 21/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0131\n",
      "Epoch 21: val_loss improved from 0.01558 to 0.01553, saving model to model\\WAE_bottleneck_30_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0131 - val_loss: 0.0155\n",
      "Epoch 22/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0129\n",
      "Epoch 22: val_loss improved from 0.01553 to 0.01543, saving model to model\\WAE_bottleneck_30_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0128 - val_loss: 0.0154\n",
      "Epoch 23/40\n",
      "14/26 [===============>..............] - ETA: 0s - loss: 0.0128\n",
      "Epoch 23: val_loss did not improve from 0.01543\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0127 - val_loss: 0.0154\n",
      "Epoch 24/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0124\n",
      "Epoch 24: val_loss improved from 0.01543 to 0.01514, saving model to model\\WAE_bottleneck_30_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0125 - val_loss: 0.0151\n",
      "Epoch 25/40\n",
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0122\n",
      "Epoch 25: val_loss did not improve from 0.01514\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0123 - val_loss: 0.0152\n",
      "Epoch 26/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0122\n",
      "Epoch 26: val_loss did not improve from 0.01514\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0122 - val_loss: 0.0152\n",
      "Epoch 27/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0122\n",
      "Epoch 27: val_loss did not improve from 0.01514\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0121 - val_loss: 0.0152\n",
      "Epoch 28/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0119\n",
      "Epoch 28: val_loss did not improve from 0.01514\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0120 - val_loss: 0.0152\n",
      "Epoch 29/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0120\n",
      "Epoch 29: val_loss did not improve from 0.01514\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0119 - val_loss: 0.0153\n",
      "Epoch 30/40\n",
      "15/26 [================>.............] - ETA: 0s - loss: 0.0116\n",
      "Epoch 30: val_loss did not improve from 0.01514\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0117 - val_loss: 0.0152\n",
      "Epoch 31/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0115\n",
      "Epoch 31: val_loss did not improve from 0.01514\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0116 - val_loss: 0.0153\n",
      "Epoch 32/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0115\n",
      "Epoch 32: val_loss did not improve from 0.01514\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0116 - val_loss: 0.0153\n",
      "Epoch 33/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0117\n",
      "Epoch 33: val_loss did not improve from 0.01514\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0116 - val_loss: 0.0152\n",
      "Epoch 34/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0113\n",
      "Epoch 34: val_loss did not improve from 0.01514\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0115 - val_loss: 0.0153\n",
      "Epoch 35/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0112\n",
      "Epoch 35: val_loss did not improve from 0.01514\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0112 - val_loss: 0.0155\n",
      "Epoch 36/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0112\n",
      "Epoch 36: val_loss did not improve from 0.01514\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0112 - val_loss: 0.0151\n",
      "Epoch 37/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0110\n",
      "Epoch 37: val_loss did not improve from 0.01514\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0111 - val_loss: 0.0153\n",
      "Epoch 38/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0110\n",
      "Epoch 38: val_loss did not improve from 0.01514\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0109 - val_loss: 0.0153\n",
      "Epoch 39/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0109\n",
      "Epoch 39: val_loss did not improve from 0.01514\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0110 - val_loss: 0.0154\n",
      "Epoch 40/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0107\n",
      "Epoch 40: val_loss did not improve from 0.01514\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0107 - val_loss: 0.0152\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "LogisticRegression - Mean CV Score: 0.5673846153846153\n",
      "LogisticRegression - Mean Confusion Matrix:\n",
      "[[6.6 6. ]\n",
      " [5.2 8.1]]\n",
      "SVM - Mean CV Score: 0.556\n",
      "SVM - Mean Confusion Matrix:\n",
      "[[6.7 5.9]\n",
      " [5.6 7.7]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest - Mean CV Score: 0.5632307692307693\n",
      "RandomForest - Mean Confusion Matrix:\n",
      "[[6.6 6. ]\n",
      " [5.3 8. ]]\n",
      "KNN - Mean CV Score: 0.5715384615384614\n",
      "KNN - Mean Confusion Matrix:\n",
      "[[7.8 4.8]\n",
      " [6.3 7. ]]\n",
      "GradientBoosting - Mean CV Score: 0.5752307692307692\n",
      "GradientBoosting - Mean Confusion Matrix:\n",
      "[[6.7 5.9]\n",
      " [5.1 8.2]]\n",
      "AdaBoost - Mean CV Score: 0.5444615384615383\n",
      "AdaBoost - Mean Confusion Matrix:\n",
      "[[6.5 6.1]\n",
      " [5.7 7.6]]\n",
      "NaiveBayes - Mean CV Score: 0.5675384615384615\n",
      "NaiveBayes - Mean Confusion Matrix:\n",
      "[[10.   2.6]\n",
      " [ 8.6  4.7]]\n",
      "DecisionTree - Mean CV Score: 0.5329230769230768\n",
      "DecisionTree - Mean Confusion Matrix:\n",
      "[[6.4 6.2]\n",
      " [5.9 7.4]]\n",
      "ExtraTrees - Mean CV Score: 0.5673846153846153\n",
      "ExtraTrees - Mean Confusion Matrix:\n",
      "[[7.1 5.5]\n",
      " [5.7 7.6]]\n",
      "XGBoost - Mean CV Score: 0.5749230769230769\n",
      "XGBoost - Mean Confusion Matrix:\n",
      "[[7.4 5.2]\n",
      " [5.8 7.5]]\n",
      "Size: bottleneck_30, Best classifier: GradientBoosting, CV Score: 0.5752307692307692\n",
      "Epoch 1/40\n",
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0309 \n",
      "Epoch 1: val_loss improved from inf to 0.02465, saving model to model\\WAE_bottleneck_34_best_model.keras\n",
      "26/26 [==============================] - 2s 13ms/step - loss: 0.0307 - val_loss: 0.0246\n",
      "Epoch 2/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0232\n",
      "Epoch 2: val_loss improved from 0.02465 to 0.02379, saving model to model\\WAE_bottleneck_34_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0230 - val_loss: 0.0238\n",
      "Epoch 3/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0219\n",
      "Epoch 3: val_loss improved from 0.02379 to 0.02169, saving model to model\\WAE_bottleneck_34_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0219 - val_loss: 0.0217\n",
      "Epoch 4/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0203\n",
      "Epoch 4: val_loss improved from 0.02169 to 0.02017, saving model to model\\WAE_bottleneck_34_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0199 - val_loss: 0.0202\n",
      "Epoch 5/40\n",
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0188\n",
      "Epoch 5: val_loss improved from 0.02017 to 0.01922, saving model to model\\WAE_bottleneck_34_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0187 - val_loss: 0.0192\n",
      "Epoch 6/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0178\n",
      "Epoch 6: val_loss improved from 0.01922 to 0.01834, saving model to model\\WAE_bottleneck_34_best_model.keras\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 0.0178 - val_loss: 0.0183\n",
      "Epoch 7/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0171\n",
      "Epoch 7: val_loss improved from 0.01834 to 0.01781, saving model to model\\WAE_bottleneck_34_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0170 - val_loss: 0.0178\n",
      "Epoch 8/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0166\n",
      "Epoch 8: val_loss improved from 0.01781 to 0.01767, saving model to model\\WAE_bottleneck_34_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0166 - val_loss: 0.0177\n",
      "Epoch 9/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0165\n",
      "Epoch 9: val_loss improved from 0.01767 to 0.01762, saving model to model\\WAE_bottleneck_34_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0165 - val_loss: 0.0176\n",
      "Epoch 10/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0158\n",
      "Epoch 10: val_loss improved from 0.01762 to 0.01727, saving model to model\\WAE_bottleneck_34_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0161 - val_loss: 0.0173\n",
      "Epoch 11/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0156\n",
      "Epoch 11: val_loss improved from 0.01727 to 0.01713, saving model to model\\WAE_bottleneck_34_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0157 - val_loss: 0.0171\n",
      "Epoch 12/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0152\n",
      "Epoch 12: val_loss improved from 0.01713 to 0.01670, saving model to model\\WAE_bottleneck_34_best_model.keras\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0152 - val_loss: 0.0167\n",
      "Epoch 13/40\n",
      "17/26 [==================>...........] - ETA: 0s - loss: 0.0147\n",
      "Epoch 13: val_loss improved from 0.01670 to 0.01639, saving model to model\\WAE_bottleneck_34_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0148 - val_loss: 0.0164\n",
      "Epoch 14/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0143\n",
      "Epoch 14: val_loss improved from 0.01639 to 0.01622, saving model to model\\WAE_bottleneck_34_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0145 - val_loss: 0.0162\n",
      "Epoch 15/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0143\n",
      "Epoch 15: val_loss improved from 0.01622 to 0.01604, saving model to model\\WAE_bottleneck_34_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0141 - val_loss: 0.0160\n",
      "Epoch 16/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0138\n",
      "Epoch 16: val_loss improved from 0.01604 to 0.01580, saving model to model\\WAE_bottleneck_34_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0137 - val_loss: 0.0158\n",
      "Epoch 17/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0132\n",
      "Epoch 17: val_loss improved from 0.01580 to 0.01573, saving model to model\\WAE_bottleneck_34_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0135 - val_loss: 0.0157\n",
      "Epoch 18/40\n",
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0131\n",
      "Epoch 18: val_loss improved from 0.01573 to 0.01563, saving model to model\\WAE_bottleneck_34_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0132 - val_loss: 0.0156\n",
      "Epoch 19/40\n",
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0130\n",
      "Epoch 19: val_loss improved from 0.01563 to 0.01553, saving model to model\\WAE_bottleneck_34_best_model.keras\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 0.0130 - val_loss: 0.0155\n",
      "Epoch 20/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0126\n",
      "Epoch 20: val_loss did not improve from 0.01553\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0128 - val_loss: 0.0155\n",
      "Epoch 21/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0127\n",
      "Epoch 21: val_loss improved from 0.01553 to 0.01531, saving model to model\\WAE_bottleneck_34_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0127 - val_loss: 0.0153\n",
      "Epoch 22/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0124\n",
      "Epoch 22: val_loss did not improve from 0.01531\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0124 - val_loss: 0.0155\n",
      "Epoch 23/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0123\n",
      "Epoch 23: val_loss did not improve from 0.01531\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0123 - val_loss: 0.0154\n",
      "Epoch 24/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0120\n",
      "Epoch 24: val_loss improved from 0.01531 to 0.01520, saving model to model\\WAE_bottleneck_34_best_model.keras\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 0.0121 - val_loss: 0.0152\n",
      "Epoch 25/40\n",
      "20/26 [======================>.......] - ETA: 0s - loss: 0.0118\n",
      "Epoch 25: val_loss did not improve from 0.01520\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0119 - val_loss: 0.0154\n",
      "Epoch 26/40\n",
      "20/26 [======================>.......] - ETA: 0s - loss: 0.0116\n",
      "Epoch 26: val_loss improved from 0.01520 to 0.01516, saving model to model\\WAE_bottleneck_34_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0117 - val_loss: 0.0152\n",
      "Epoch 27/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0117\n",
      "Epoch 27: val_loss did not improve from 0.01516\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0116 - val_loss: 0.0153\n",
      "Epoch 28/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0114\n",
      "Epoch 28: val_loss did not improve from 0.01516\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0114 - val_loss: 0.0152\n",
      "Epoch 29/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0110\n",
      "Epoch 29: val_loss did not improve from 0.01516\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0113 - val_loss: 0.0155\n",
      "Epoch 30/40\n",
      "10/26 [==========>...................] - ETA: 0s - loss: 0.0113\n",
      "Epoch 30: val_loss improved from 0.01516 to 0.01501, saving model to model\\WAE_bottleneck_34_best_model.keras\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0112 - val_loss: 0.0150\n",
      "Epoch 31/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0110\n",
      "Epoch 31: val_loss did not improve from 0.01501\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0110 - val_loss: 0.0151\n",
      "Epoch 32/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0108\n",
      "Epoch 32: val_loss did not improve from 0.01501\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0108 - val_loss: 0.0153\n",
      "Epoch 33/40\n",
      "21/26 [=======================>......] - ETA: 0s - loss: 0.0106\n",
      "Epoch 33: val_loss did not improve from 0.01501\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0106 - val_loss: 0.0153\n",
      "Epoch 34/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0103\n",
      "Epoch 34: val_loss improved from 0.01501 to 0.01492, saving model to model\\WAE_bottleneck_34_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0104 - val_loss: 0.0149\n",
      "Epoch 35/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0104\n",
      "Epoch 35: val_loss did not improve from 0.01492\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0103 - val_loss: 0.0151\n",
      "Epoch 36/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0101\n",
      "Epoch 36: val_loss did not improve from 0.01492\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0101 - val_loss: 0.0150\n",
      "Epoch 37/40\n",
      "12/26 [============>.................] - ETA: 0s - loss: 0.0100\n",
      "Epoch 37: val_loss did not improve from 0.01492\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0101 - val_loss: 0.0150\n",
      "Epoch 38/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0100\n",
      "Epoch 38: val_loss did not improve from 0.01492\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.0150\n",
      "Epoch 39/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0100\n",
      "Epoch 39: val_loss did not improve from 0.01492\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0099 - val_loss: 0.0150\n",
      "Epoch 40/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0096\n",
      "Epoch 40: val_loss did not improve from 0.01492\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0097 - val_loss: 0.0150\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "LogisticRegression - Mean CV Score: 0.602\n",
      "LogisticRegression - Mean Confusion Matrix:\n",
      "[[7.5 5.1]\n",
      " [5.2 8.1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM - Mean CV Score: 0.5753846153846153\n",
      "SVM - Mean Confusion Matrix:\n",
      "[[6.7 5.9]\n",
      " [5.1 8.2]]\n",
      "RandomForest - Mean CV Score: 0.6327692307692308\n",
      "RandomForest - Mean Confusion Matrix:\n",
      "[[7.7 4.9]\n",
      " [4.6 8.7]]\n",
      "KNN - Mean CV Score: 0.5946153846153845\n",
      "KNN - Mean Confusion Matrix:\n",
      "[[8.2 4.4]\n",
      " [6.1 7.2]]\n",
      "GradientBoosting - Mean CV Score: 0.5907692307692307\n",
      "GradientBoosting - Mean Confusion Matrix:\n",
      "[[7.6 5. ]\n",
      " [5.6 7.7]]\n",
      "AdaBoost - Mean CV Score: 0.5867692307692309\n",
      "AdaBoost - Mean Confusion Matrix:\n",
      "[[7.1 5.5]\n",
      " [5.2 8.1]]\n",
      "NaiveBayes - Mean CV Score: 0.5323076923076924\n",
      "NaiveBayes - Mean Confusion Matrix:\n",
      "[[10.3  2.3]\n",
      " [ 9.8  3.5]]\n",
      "DecisionTree - Mean CV Score: 0.548\n",
      "DecisionTree - Mean Confusion Matrix:\n",
      "[[6.6 6. ]\n",
      " [5.7 7.6]]\n",
      "ExtraTrees - Mean CV Score: 0.6253846153846154\n",
      "ExtraTrees - Mean Confusion Matrix:\n",
      "[[7.9 4.7]\n",
      " [5.  8.3]]\n",
      "XGBoost - Mean CV Score: 0.6213846153846154\n",
      "XGBoost - Mean Confusion Matrix:\n",
      "[[7.1 5.5]\n",
      " [4.3 9. ]]\n",
      "Size: bottleneck_34, Best classifier: RandomForest, CV Score: 0.6327692307692308\n",
      "Epoch 1/40\n",
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0310\n",
      "Epoch 1: val_loss improved from inf to 0.02482, saving model to model\\WAE_bottleneck_38_best_model.keras\n",
      "26/26 [==============================] - 1s 14ms/step - loss: 0.0310 - val_loss: 0.0248\n",
      "Epoch 2/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0233\n",
      "Epoch 2: val_loss improved from 0.02482 to 0.02360, saving model to model\\WAE_bottleneck_38_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0228 - val_loss: 0.0236\n",
      "Epoch 3/40\n",
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0215\n",
      "Epoch 3: val_loss improved from 0.02360 to 0.02102, saving model to model\\WAE_bottleneck_38_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0213 - val_loss: 0.0210\n",
      "Epoch 4/40\n",
      "16/26 [=================>............] - ETA: 0s - loss: 0.0197\n",
      "Epoch 4: val_loss improved from 0.02102 to 0.02004, saving model to model\\WAE_bottleneck_38_best_model.keras\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0193 - val_loss: 0.0200\n",
      "Epoch 5/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0189\n",
      "Epoch 5: val_loss improved from 0.02004 to 0.01957, saving model to model\\WAE_bottleneck_38_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0189 - val_loss: 0.0196\n",
      "Epoch 6/40\n",
      "12/26 [============>.................] - ETA: 0s - loss: 0.0191\n",
      "Epoch 6: val_loss improved from 0.01957 to 0.01924, saving model to model\\WAE_bottleneck_38_best_model.keras\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0186 - val_loss: 0.0192\n",
      "Epoch 7/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0185\n",
      "Epoch 7: val_loss improved from 0.01924 to 0.01879, saving model to model\\WAE_bottleneck_38_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0182 - val_loss: 0.0188\n",
      "Epoch 8/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0177\n",
      "Epoch 8: val_loss improved from 0.01879 to 0.01815, saving model to model\\WAE_bottleneck_38_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0177 - val_loss: 0.0181\n",
      "Epoch 9/40\n",
      "21/26 [=======================>......] - ETA: 0s - loss: 0.0165\n",
      "Epoch 9: val_loss improved from 0.01815 to 0.01788, saving model to model\\WAE_bottleneck_38_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0167 - val_loss: 0.0179\n",
      "Epoch 10/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0162\n",
      "Epoch 10: val_loss improved from 0.01788 to 0.01747, saving model to model\\WAE_bottleneck_38_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0163 - val_loss: 0.0175\n",
      "Epoch 11/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0159\n",
      "Epoch 11: val_loss improved from 0.01747 to 0.01703, saving model to model\\WAE_bottleneck_38_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0159 - val_loss: 0.0170\n",
      "Epoch 12/40\n",
      "21/26 [=======================>......] - ETA: 0s - loss: 0.0150\n",
      "Epoch 12: val_loss improved from 0.01703 to 0.01666, saving model to model\\WAE_bottleneck_38_best_model.keras\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 0.0153 - val_loss: 0.0167\n",
      "Epoch 13/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0145\n",
      "Epoch 13: val_loss improved from 0.01666 to 0.01632, saving model to model\\WAE_bottleneck_38_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0148 - val_loss: 0.0163\n",
      "Epoch 14/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0147\n",
      "Epoch 14: val_loss improved from 0.01632 to 0.01630, saving model to model\\WAE_bottleneck_38_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0145 - val_loss: 0.0163\n",
      "Epoch 15/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0141\n",
      "Epoch 15: val_loss improved from 0.01630 to 0.01597, saving model to model\\WAE_bottleneck_38_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0142 - val_loss: 0.0160\n",
      "Epoch 16/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0138\n",
      "Epoch 16: val_loss improved from 0.01597 to 0.01550, saving model to model\\WAE_bottleneck_38_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0137 - val_loss: 0.0155\n",
      "Epoch 17/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0131\n",
      "Epoch 17: val_loss improved from 0.01550 to 0.01546, saving model to model\\WAE_bottleneck_38_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0134 - val_loss: 0.0155\n",
      "Epoch 18/40\n",
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0130\n",
      "Epoch 18: val_loss improved from 0.01546 to 0.01543, saving model to model\\WAE_bottleneck_38_best_model.keras\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 0.0131 - val_loss: 0.0154\n",
      "Epoch 19/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0127\n",
      "Epoch 19: val_loss improved from 0.01543 to 0.01543, saving model to model\\WAE_bottleneck_38_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0128 - val_loss: 0.0154\n",
      "Epoch 20/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0126\n",
      "Epoch 20: val_loss improved from 0.01543 to 0.01501, saving model to model\\WAE_bottleneck_38_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0125 - val_loss: 0.0150\n",
      "Epoch 21/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0123\n",
      "Epoch 21: val_loss improved from 0.01501 to 0.01498, saving model to model\\WAE_bottleneck_38_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0122 - val_loss: 0.0150\n",
      "Epoch 22/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0122\n",
      "Epoch 22: val_loss did not improve from 0.01498\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0122 - val_loss: 0.0151\n",
      "Epoch 23/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0122\n",
      "Epoch 23: val_loss did not improve from 0.01498\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0121 - val_loss: 0.0150\n",
      "Epoch 24/40\n",
      "12/26 [============>.................] - ETA: 0s - loss: 0.0115\n",
      "Epoch 24: val_loss improved from 0.01498 to 0.01489, saving model to model\\WAE_bottleneck_38_best_model.keras\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0118 - val_loss: 0.0149\n",
      "Epoch 25/40\n",
      "20/26 [======================>.......] - ETA: 0s - loss: 0.0113\n",
      "Epoch 25: val_loss did not improve from 0.01489\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0118 - val_loss: 0.0151\n",
      "Epoch 26/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0116\n",
      "Epoch 26: val_loss improved from 0.01489 to 0.01482, saving model to model\\WAE_bottleneck_38_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0115 - val_loss: 0.0148\n",
      "Epoch 27/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0112\n",
      "Epoch 27: val_loss did not improve from 0.01482\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0112 - val_loss: 0.0150\n",
      "Epoch 28/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0111\n",
      "Epoch 28: val_loss did not improve from 0.01482\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0111 - val_loss: 0.0150\n",
      "Epoch 29/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0106\n",
      "Epoch 29: val_loss improved from 0.01482 to 0.01481, saving model to model\\WAE_bottleneck_38_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0109 - val_loss: 0.0148\n",
      "Epoch 30/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0106\n",
      "Epoch 30: val_loss did not improve from 0.01481\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0107 - val_loss: 0.0149\n",
      "Epoch 31/40\n",
      "15/26 [================>.............] - ETA: 0s - loss: 0.0105\n",
      "Epoch 31: val_loss did not improve from 0.01481\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0106 - val_loss: 0.0151\n",
      "Epoch 32/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0104\n",
      "Epoch 32: val_loss improved from 0.01481 to 0.01447, saving model to model\\WAE_bottleneck_38_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0104 - val_loss: 0.0145\n",
      "Epoch 33/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0102\n",
      "Epoch 33: val_loss did not improve from 0.01447\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0102 - val_loss: 0.0146\n",
      "Epoch 34/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0103\n",
      "Epoch 34: val_loss did not improve from 0.01447\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0101 - val_loss: 0.0147\n",
      "Epoch 35/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0098\n",
      "Epoch 35: val_loss improved from 0.01447 to 0.01446, saving model to model\\WAE_bottleneck_38_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0099 - val_loss: 0.0145\n",
      "Epoch 36/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0097\n",
      "Epoch 36: val_loss did not improve from 0.01446\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0098 - val_loss: 0.0146\n",
      "Epoch 37/40\n",
      "18/26 [===================>..........] - ETA: 0s - loss: 0.0095\n",
      "Epoch 37: val_loss did not improve from 0.01446\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0097 - val_loss: 0.0146\n",
      "Epoch 38/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0097\n",
      "Epoch 38: val_loss did not improve from 0.01446\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0096 - val_loss: 0.0145\n",
      "Epoch 39/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0093\n",
      "Epoch 39: val_loss did not improve from 0.01446\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0094 - val_loss: 0.0146\n",
      "Epoch 40/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0094\n",
      "Epoch 40: val_loss did not improve from 0.01446\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0093 - val_loss: 0.0147\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "LogisticRegression - Mean CV Score: 0.6024615384615385\n",
      "LogisticRegression - Mean Confusion Matrix:\n",
      "[[7.6 5. ]\n",
      " [5.3 8. ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM - Mean CV Score: 0.594923076923077\n",
      "SVM - Mean Confusion Matrix:\n",
      "[[6.9 5.7]\n",
      " [4.8 8.5]]\n",
      "RandomForest - Mean CV Score: 0.6104615384615385\n",
      "RandomForest - Mean Confusion Matrix:\n",
      "[[7.4 5.2]\n",
      " [4.9 8.4]]\n",
      "KNN - Mean CV Score: 0.5712307692307691\n",
      "KNN - Mean Confusion Matrix:\n",
      "[[7.2 5.4]\n",
      " [5.7 7.6]]\n",
      "GradientBoosting - Mean CV Score: 0.5673846153846153\n",
      "GradientBoosting - Mean Confusion Matrix:\n",
      "[[7.2 5.4]\n",
      " [5.8 7.5]]\n",
      "AdaBoost - Mean CV Score: 0.5136923076923077\n",
      "AdaBoost - Mean Confusion Matrix:\n",
      "[[5.7 6.9]\n",
      " [5.7 7.6]]\n",
      "NaiveBayes - Mean CV Score: 0.5563076923076923\n",
      "NaiveBayes - Mean Confusion Matrix:\n",
      "[[10.3  2.3]\n",
      " [ 9.2  4.1]]\n",
      "DecisionTree - Mean CV Score: 0.5564615384615385\n",
      "DecisionTree - Mean Confusion Matrix:\n",
      "[[6.2 6.4]\n",
      " [5.1 8.2]]\n",
      "ExtraTrees - Mean CV Score: 0.5909230769230769\n",
      "ExtraTrees - Mean Confusion Matrix:\n",
      "[[7.5 5.1]\n",
      " [5.5 7.8]]\n",
      "XGBoost - Mean CV Score: 0.5987692307692308\n",
      "XGBoost - Mean Confusion Matrix:\n",
      "[[7.2 5.4]\n",
      " [5.  8.3]]\n",
      "Size: bottleneck_38, Best classifier: RandomForest, CV Score: 0.6104615384615385\n",
      "Epoch 1/40\n",
      "21/26 [=======================>......] - ETA: 0s - loss: 0.0334 \n",
      "Epoch 1: val_loss improved from inf to 0.02523, saving model to model\\WAE_bottleneck_42_best_model.keras\n",
      "26/26 [==============================] - 1s 12ms/step - loss: 0.0315 - val_loss: 0.0252\n",
      "Epoch 2/40\n",
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0229\n",
      "Epoch 2: val_loss improved from 0.02523 to 0.02393, saving model to model\\WAE_bottleneck_42_best_model.keras\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0230 - val_loss: 0.0239\n",
      "Epoch 3/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0216\n",
      "Epoch 3: val_loss improved from 0.02393 to 0.02093, saving model to model\\WAE_bottleneck_42_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0215 - val_loss: 0.0209\n",
      "Epoch 4/40\n",
      "17/26 [==================>...........] - ETA: 0s - loss: 0.0200\n",
      "Epoch 4: val_loss improved from 0.02093 to 0.02030, saving model to model\\WAE_bottleneck_42_best_model.keras\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0194 - val_loss: 0.0203\n",
      "Epoch 5/40\n",
      "19/26 [====================>.........] - ETA: 0s - loss: 0.0188\n",
      "Epoch 5: val_loss improved from 0.02030 to 0.01960, saving model to model\\WAE_bottleneck_42_best_model.keras\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0190 - val_loss: 0.0196\n",
      "Epoch 6/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0187\n",
      "Epoch 6: val_loss improved from 0.01960 to 0.01919, saving model to model\\WAE_bottleneck_42_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0186 - val_loss: 0.0192\n",
      "Epoch 7/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0180\n",
      "Epoch 7: val_loss improved from 0.01919 to 0.01881, saving model to model\\WAE_bottleneck_42_best_model.keras\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0181 - val_loss: 0.0188\n",
      "Epoch 8/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0178\n",
      "Epoch 8: val_loss improved from 0.01881 to 0.01826, saving model to model\\WAE_bottleneck_42_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0175 - val_loss: 0.0183\n",
      "Epoch 9/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0171\n",
      "Epoch 9: val_loss improved from 0.01826 to 0.01790, saving model to model\\WAE_bottleneck_42_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0168 - val_loss: 0.0179\n",
      "Epoch 10/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0166\n",
      "Epoch 10: val_loss improved from 0.01790 to 0.01770, saving model to model\\WAE_bottleneck_42_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0165 - val_loss: 0.0177\n",
      "Epoch 11/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0162\n",
      "Epoch 11: val_loss improved from 0.01770 to 0.01754, saving model to model\\WAE_bottleneck_42_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0162 - val_loss: 0.0175\n",
      "Epoch 12/40\n",
      "21/26 [=======================>......] - ETA: 0s - loss: 0.0159\n",
      "Epoch 12: val_loss improved from 0.01754 to 0.01750, saving model to model\\WAE_bottleneck_42_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0160 - val_loss: 0.0175\n",
      "Epoch 13/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0158\n",
      "Epoch 13: val_loss improved from 0.01750 to 0.01719, saving model to model\\WAE_bottleneck_42_best_model.keras\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0158 - val_loss: 0.0172\n",
      "Epoch 14/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0155\n",
      "Epoch 14: val_loss improved from 0.01719 to 0.01681, saving model to model\\WAE_bottleneck_42_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0154 - val_loss: 0.0168\n",
      "Epoch 15/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0148\n",
      "Epoch 15: val_loss improved from 0.01681 to 0.01661, saving model to model\\WAE_bottleneck_42_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0149 - val_loss: 0.0166\n",
      "Epoch 16/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0146\n",
      "Epoch 16: val_loss improved from 0.01661 to 0.01639, saving model to model\\WAE_bottleneck_42_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0146 - val_loss: 0.0164\n",
      "Epoch 17/40\n",
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0144\n",
      "Epoch 17: val_loss improved from 0.01639 to 0.01617, saving model to model\\WAE_bottleneck_42_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0144 - val_loss: 0.0162\n",
      "Epoch 18/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0141\n",
      "Epoch 18: val_loss improved from 0.01617 to 0.01607, saving model to model\\WAE_bottleneck_42_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0141 - val_loss: 0.0161\n",
      "Epoch 19/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0140\n",
      "Epoch 19: val_loss improved from 0.01607 to 0.01593, saving model to model\\WAE_bottleneck_42_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0138 - val_loss: 0.0159\n",
      "Epoch 20/40\n",
      "14/26 [===============>..............] - ETA: 0s - loss: 0.0134\n",
      "Epoch 20: val_loss improved from 0.01593 to 0.01581, saving model to model\\WAE_bottleneck_42_best_model.keras\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0137 - val_loss: 0.0158\n",
      "Epoch 21/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0134\n",
      "Epoch 21: val_loss did not improve from 0.01581\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0135 - val_loss: 0.0159\n",
      "Epoch 22/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0135\n",
      "Epoch 22: val_loss did not improve from 0.01581\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0134 - val_loss: 0.0159\n",
      "Epoch 23/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0134\n",
      "Epoch 23: val_loss improved from 0.01581 to 0.01572, saving model to model\\WAE_bottleneck_42_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0132 - val_loss: 0.0157\n",
      "Epoch 24/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0131\n",
      "Epoch 24: val_loss improved from 0.01572 to 0.01566, saving model to model\\WAE_bottleneck_42_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0130 - val_loss: 0.0157\n",
      "Epoch 25/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0128\n",
      "Epoch 25: val_loss did not improve from 0.01566\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0130 - val_loss: 0.0159\n",
      "Epoch 26/40\n",
      "19/26 [====================>.........] - ETA: 0s - loss: 0.0125\n",
      "Epoch 26: val_loss improved from 0.01566 to 0.01549, saving model to model\\WAE_bottleneck_42_best_model.keras\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0127 - val_loss: 0.0155\n",
      "Epoch 27/40\n",
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0125\n",
      "Epoch 27: val_loss did not improve from 0.01549\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0126 - val_loss: 0.0157\n",
      "Epoch 28/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0124\n",
      "Epoch 28: val_loss improved from 0.01549 to 0.01534, saving model to model\\WAE_bottleneck_42_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0124 - val_loss: 0.0153\n",
      "Epoch 29/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0121\n",
      "Epoch 29: val_loss improved from 0.01534 to 0.01518, saving model to model\\WAE_bottleneck_42_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0120 - val_loss: 0.0152\n",
      "Epoch 30/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0117\n",
      "Epoch 30: val_loss did not improve from 0.01518\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0118 - val_loss: 0.0154\n",
      "Epoch 31/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0118\n",
      "Epoch 31: val_loss did not improve from 0.01518\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0116 - val_loss: 0.0152\n",
      "Epoch 32/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0115\n",
      "Epoch 32: val_loss improved from 0.01518 to 0.01517, saving model to model\\WAE_bottleneck_42_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0115 - val_loss: 0.0152\n",
      "Epoch 33/40\n",
      "13/26 [==============>...............] - ETA: 0s - loss: 0.0107\n",
      "Epoch 33: val_loss did not improve from 0.01517\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0114 - val_loss: 0.0154\n",
      "Epoch 34/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0113\n",
      "Epoch 34: val_loss did not improve from 0.01517\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0113 - val_loss: 0.0154\n",
      "Epoch 35/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0111\n",
      "Epoch 35: val_loss did not improve from 0.01517\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0110 - val_loss: 0.0153\n",
      "Epoch 36/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0110\n",
      "Epoch 36: val_loss did not improve from 0.01517\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0110 - val_loss: 0.0155\n",
      "Epoch 37/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0108\n",
      "Epoch 37: val_loss improved from 0.01517 to 0.01516, saving model to model\\WAE_bottleneck_42_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0109 - val_loss: 0.0152\n",
      "Epoch 38/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0105\n",
      "Epoch 38: val_loss improved from 0.01516 to 0.01509, saving model to model\\WAE_bottleneck_42_best_model.keras\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0107 - val_loss: 0.0151\n",
      "Epoch 39/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0106\n",
      "Epoch 39: val_loss did not improve from 0.01509\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0105 - val_loss: 0.0151\n",
      "Epoch 40/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0106\n",
      "Epoch 40: val_loss did not improve from 0.01509\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0105 - val_loss: 0.0156\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "LogisticRegression - Mean CV Score: 0.5749230769230769\n",
      "LogisticRegression - Mean Confusion Matrix:\n",
      "[[6.9 5.7]\n",
      " [5.3 8. ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM - Mean CV Score: 0.6066153846153846\n",
      "SVM - Mean Confusion Matrix:\n",
      "[[7.5 5.1]\n",
      " [5.1 8.2]]\n",
      "RandomForest - Mean CV Score: 0.5827692307692308\n",
      "RandomForest - Mean Confusion Matrix:\n",
      "[[7.5 5.1]\n",
      " [5.7 7.6]]\n",
      "KNN - Mean CV Score: 0.571076923076923\n",
      "KNN - Mean Confusion Matrix:\n",
      "[[7.5 5.1]\n",
      " [6.  7.3]]\n",
      "GradientBoosting - Mean CV Score: 0.5715384615384614\n",
      "GradientBoosting - Mean Confusion Matrix:\n",
      "[[6.9 5.7]\n",
      " [5.4 7.9]]\n",
      "AdaBoost - Mean CV Score: 0.5598461538461539\n",
      "AdaBoost - Mean Confusion Matrix:\n",
      "[[6.9 5.7]\n",
      " [5.7 7.6]]\n",
      "NaiveBayes - Mean CV Score: 0.5401538461538462\n",
      "NaiveBayes - Mean Confusion Matrix:\n",
      "[[12.1  0.5]\n",
      " [11.4  1.9]]\n",
      "DecisionTree - Mean CV Score: 0.553076923076923\n",
      "DecisionTree - Mean Confusion Matrix:\n",
      "[[6.2 6.4]\n",
      " [5.2 8.1]]\n",
      "ExtraTrees - Mean CV Score: 0.5946153846153845\n",
      "ExtraTrees - Mean Confusion Matrix:\n",
      "[[7.4 5.2]\n",
      " [5.3 8. ]]\n",
      "XGBoost - Mean CV Score: 0.5987692307692307\n",
      "XGBoost - Mean Confusion Matrix:\n",
      "[[7.8 4.8]\n",
      " [5.6 7.7]]\n",
      "Size: bottleneck_42, Best classifier: SVM, CV Score: 0.6066153846153846\n",
      "Epoch 1/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0322 \n",
      "Epoch 1: val_loss improved from inf to 0.02498, saving model to model\\WAE_bottleneck_46_best_model.keras\n",
      "26/26 [==============================] - 1s 11ms/step - loss: 0.0311 - val_loss: 0.0250\n",
      "Epoch 2/40\n",
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0231\n",
      "Epoch 2: val_loss improved from 0.02498 to 0.02392, saving model to model\\WAE_bottleneck_46_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0231 - val_loss: 0.0239\n",
      "Epoch 3/40\n",
      "20/26 [======================>.......] - ETA: 0s - loss: 0.0222\n",
      "Epoch 3: val_loss improved from 0.02392 to 0.02312, saving model to model\\WAE_bottleneck_46_best_model.keras\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 0.0225 - val_loss: 0.0231\n",
      "Epoch 4/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0209\n",
      "Epoch 4: val_loss improved from 0.02312 to 0.02018, saving model to model\\WAE_bottleneck_46_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0208 - val_loss: 0.0202\n",
      "Epoch 5/40\n",
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0190\n",
      "Epoch 5: val_loss improved from 0.02018 to 0.01942, saving model to model\\WAE_bottleneck_46_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0192 - val_loss: 0.0194\n",
      "Epoch 6/40\n",
      "16/26 [=================>............] - ETA: 0s - loss: 0.0184\n",
      "Epoch 6: val_loss improved from 0.01942 to 0.01876, saving model to model\\WAE_bottleneck_46_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0184 - val_loss: 0.0188\n",
      "Epoch 7/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0177\n",
      "Epoch 7: val_loss improved from 0.01876 to 0.01812, saving model to model\\WAE_bottleneck_46_best_model.keras\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0176 - val_loss: 0.0181\n",
      "Epoch 8/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0170\n",
      "Epoch 8: val_loss improved from 0.01812 to 0.01774, saving model to model\\WAE_bottleneck_46_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0170 - val_loss: 0.0177\n",
      "Epoch 9/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0165\n",
      "Epoch 9: val_loss improved from 0.01774 to 0.01757, saving model to model\\WAE_bottleneck_46_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0165 - val_loss: 0.0176\n",
      "Epoch 10/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0161\n",
      "Epoch 10: val_loss improved from 0.01757 to 0.01732, saving model to model\\WAE_bottleneck_46_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0163 - val_loss: 0.0173\n",
      "Epoch 11/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0158\n",
      "Epoch 11: val_loss improved from 0.01732 to 0.01706, saving model to model\\WAE_bottleneck_46_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0160 - val_loss: 0.0171\n",
      "Epoch 12/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0161\n",
      "Epoch 12: val_loss did not improve from 0.01706\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0158 - val_loss: 0.0171\n",
      "Epoch 13/40\n",
      "21/26 [=======================>......] - ETA: 0s - loss: 0.0155\n",
      "Epoch 13: val_loss improved from 0.01706 to 0.01688, saving model to model\\WAE_bottleneck_46_best_model.keras\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 0.0155 - val_loss: 0.0169\n",
      "Epoch 14/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0151\n",
      "Epoch 14: val_loss improved from 0.01688 to 0.01631, saving model to model\\WAE_bottleneck_46_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0152 - val_loss: 0.0163\n",
      "Epoch 15/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0145\n",
      "Epoch 15: val_loss improved from 0.01631 to 0.01598, saving model to model\\WAE_bottleneck_46_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0145 - val_loss: 0.0160\n",
      "Epoch 16/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0140\n",
      "Epoch 16: val_loss improved from 0.01598 to 0.01574, saving model to model\\WAE_bottleneck_46_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0139 - val_loss: 0.0157\n",
      "Epoch 17/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0135\n",
      "Epoch 17: val_loss improved from 0.01574 to 0.01572, saving model to model\\WAE_bottleneck_46_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0135 - val_loss: 0.0157\n",
      "Epoch 18/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0132\n",
      "Epoch 18: val_loss improved from 0.01572 to 0.01563, saving model to model\\WAE_bottleneck_46_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0133 - val_loss: 0.0156\n",
      "Epoch 19/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0132\n",
      "Epoch 19: val_loss improved from 0.01563 to 0.01532, saving model to model\\WAE_bottleneck_46_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0131 - val_loss: 0.0153\n",
      "Epoch 20/40\n",
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0129\n",
      "Epoch 20: val_loss did not improve from 0.01532\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0128 - val_loss: 0.0154\n",
      "Epoch 21/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0125\n",
      "Epoch 21: val_loss did not improve from 0.01532\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0126 - val_loss: 0.0154\n",
      "Epoch 22/40\n",
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0124\n",
      "Epoch 22: val_loss did not improve from 0.01532\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0124 - val_loss: 0.0154\n",
      "Epoch 23/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0123\n",
      "Epoch 23: val_loss did not improve from 0.01532\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0122 - val_loss: 0.0154\n",
      "Epoch 24/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0121\n",
      "Epoch 24: val_loss improved from 0.01532 to 0.01531, saving model to model\\WAE_bottleneck_46_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0121 - val_loss: 0.0153\n",
      "Epoch 25/40\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0119\n",
      "Epoch 25: val_loss did not improve from 0.01531\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0119 - val_loss: 0.0155\n",
      "Epoch 26/40\n",
      "18/26 [===================>..........] - ETA: 0s - loss: 0.0116\n",
      "Epoch 26: val_loss did not improve from 0.01531\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0118 - val_loss: 0.0154\n",
      "Epoch 27/40\n",
      "21/26 [=======================>......] - ETA: 0s - loss: 0.0118\n",
      "Epoch 27: val_loss did not improve from 0.01531\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0118 - val_loss: 0.0154\n",
      "Epoch 28/40\n",
      "19/26 [====================>.........] - ETA: 0s - loss: 0.0119\n",
      "Epoch 28: val_loss did not improve from 0.01531\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0116 - val_loss: 0.0158\n",
      "Epoch 29/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0116\n",
      "Epoch 29: val_loss did not improve from 0.01531\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0116 - val_loss: 0.0154\n",
      "Epoch 30/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0116\n",
      "Epoch 30: val_loss did not improve from 0.01531\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0116 - val_loss: 0.0154\n",
      "Epoch 31/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0112\n",
      "Epoch 31: val_loss did not improve from 0.01531\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0114 - val_loss: 0.0153\n",
      "Epoch 32/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0112\n",
      "Epoch 32: val_loss did not improve from 0.01531\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0111 - val_loss: 0.0157\n",
      "Epoch 33/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0108\n",
      "Epoch 33: val_loss improved from 0.01531 to 0.01523, saving model to model\\WAE_bottleneck_46_best_model.keras\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0109 - val_loss: 0.0152\n",
      "Epoch 34/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0108\n",
      "Epoch 34: val_loss did not improve from 0.01523\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0108 - val_loss: 0.0154\n",
      "Epoch 35/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0107\n",
      "Epoch 35: val_loss improved from 0.01523 to 0.01520, saving model to model\\WAE_bottleneck_46_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0107 - val_loss: 0.0152\n",
      "Epoch 36/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0106\n",
      "Epoch 36: val_loss improved from 0.01520 to 0.01507, saving model to model\\WAE_bottleneck_46_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0105 - val_loss: 0.0151\n",
      "Epoch 37/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0102\n",
      "Epoch 37: val_loss did not improve from 0.01507\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0103 - val_loss: 0.0152\n",
      "Epoch 38/40\n",
      "20/26 [======================>.......] - ETA: 0s - loss: 0.0103\n",
      "Epoch 38: val_loss improved from 0.01507 to 0.01496, saving model to model\\WAE_bottleneck_46_best_model.keras\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0103 - val_loss: 0.0150\n",
      "Epoch 39/40\n",
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0099\n",
      "Epoch 39: val_loss did not improve from 0.01496\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.0152\n",
      "Epoch 40/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0098\n",
      "Epoch 40: val_loss did not improve from 0.01496\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0099 - val_loss: 0.0151\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "LogisticRegression - Mean CV Score: 0.6215384615384616\n",
      "LogisticRegression - Mean Confusion Matrix:\n",
      "[[7.6 5. ]\n",
      " [4.8 8.5]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM - Mean CV Score: 0.5867692307692307\n",
      "SVM - Mean Confusion Matrix:\n",
      "[[6.6 6. ]\n",
      " [4.7 8.6]]\n",
      "RandomForest - Mean CV Score: 0.6141538461538462\n",
      "RandomForest - Mean Confusion Matrix:\n",
      "[[7.2 5.4]\n",
      " [4.6 8.7]]\n",
      "KNN - Mean CV Score: 0.6175384615384616\n",
      "KNN - Mean Confusion Matrix:\n",
      "[[8.3 4.3]\n",
      " [5.6 7.7]]\n",
      "GradientBoosting - Mean CV Score: 0.5603076923076923\n",
      "GradientBoosting - Mean Confusion Matrix:\n",
      "[[6.4 6.2]\n",
      " [5.2 8.1]]\n",
      "AdaBoost - Mean CV Score: 0.5912307692307691\n",
      "AdaBoost - Mean Confusion Matrix:\n",
      "[[7.9 4.7]\n",
      " [5.9 7.4]]\n",
      "NaiveBayes - Mean CV Score: 0.5327692307692308\n",
      "NaiveBayes - Mean Confusion Matrix:\n",
      "[[11.3  1.3]\n",
      " [10.8  2.5]]\n",
      "DecisionTree - Mean CV Score: 0.5209230769230769\n",
      "DecisionTree - Mean Confusion Matrix:\n",
      "[[6.  6.6]\n",
      " [5.8 7.5]]\n",
      "ExtraTrees - Mean CV Score: 0.5833846153846153\n",
      "ExtraTrees - Mean Confusion Matrix:\n",
      "[[7.1 5.5]\n",
      " [5.3 8. ]]\n",
      "XGBoost - Mean CV Score: 0.5715384615384614\n",
      "XGBoost - Mean Confusion Matrix:\n",
      "[[6.9 5.7]\n",
      " [5.4 7.9]]\n",
      "Size: bottleneck_46, Best classifier: LogisticRegression, CV Score: 0.6215384615384616\n"
     ]
    }
   ],
   "source": [
    "dispatcher(Wider_AE,\"WAE\",6,48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\JCH\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "Epoch 1/40\n",
      " 1/26 [>.............................] - ETA: 24s - loss: 0.0481\n",
      "Epoch 1: val_loss improved from inf to 0.02982, saving model to model\\SAE_bottleneck_6_best_model.keras\n",
      "26/26 [==============================] - 1s 11ms/step - loss: 0.0403 - val_loss: 0.0298\n",
      "Epoch 2/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0352\n",
      "Epoch 2: val_loss improved from 0.02982 to 0.02477, saving model to model\\SAE_bottleneck_6_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0244 - val_loss: 0.0248\n",
      "Epoch 3/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0180\n",
      "Epoch 3: val_loss improved from 0.02477 to 0.02429, saving model to model\\SAE_bottleneck_6_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0231 - val_loss: 0.0243\n",
      "Epoch 4/40\n",
      "16/26 [=================>............] - ETA: 0s - loss: 0.0229\n",
      "Epoch 4: val_loss improved from 0.02429 to 0.02405, saving model to model\\SAE_bottleneck_6_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0228 - val_loss: 0.0240\n",
      "Epoch 5/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0282\n",
      "Epoch 5: val_loss improved from 0.02405 to 0.02374, saving model to model\\SAE_bottleneck_6_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0227 - val_loss: 0.0237\n",
      "Epoch 6/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0260\n",
      "Epoch 6: val_loss improved from 0.02374 to 0.02361, saving model to model\\SAE_bottleneck_6_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0226 - val_loss: 0.0236\n",
      "Epoch 7/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0218\n",
      "Epoch 7: val_loss improved from 0.02361 to 0.02348, saving model to model\\SAE_bottleneck_6_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0225 - val_loss: 0.0235\n",
      "Epoch 8/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0218\n",
      "Epoch 8: val_loss improved from 0.02348 to 0.02346, saving model to model\\SAE_bottleneck_6_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0225 - val_loss: 0.0235\n",
      "Epoch 9/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0177\n",
      "Epoch 9: val_loss improved from 0.02346 to 0.02314, saving model to model\\SAE_bottleneck_6_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0224 - val_loss: 0.0231\n",
      "Epoch 10/40\n",
      "10/26 [==========>...................] - ETA: 0s - loss: 0.0221\n",
      "Epoch 10: val_loss improved from 0.02314 to 0.02163, saving model to model\\SAE_bottleneck_6_best_model.keras\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0217 - val_loss: 0.0216\n",
      "Epoch 11/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0199\n",
      "Epoch 11: val_loss improved from 0.02163 to 0.02023, saving model to model\\SAE_bottleneck_6_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0198 - val_loss: 0.0202\n",
      "Epoch 12/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0210\n",
      "Epoch 12: val_loss improved from 0.02023 to 0.01967, saving model to model\\SAE_bottleneck_6_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0190 - val_loss: 0.0197\n",
      "Epoch 13/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0174\n",
      "Epoch 13: val_loss improved from 0.01967 to 0.01943, saving model to model\\SAE_bottleneck_6_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0187 - val_loss: 0.0194\n",
      "Epoch 14/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0163\n",
      "Epoch 14: val_loss improved from 0.01943 to 0.01931, saving model to model\\SAE_bottleneck_6_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0187 - val_loss: 0.0193\n",
      "Epoch 15/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0196\n",
      "Epoch 15: val_loss improved from 0.01931 to 0.01920, saving model to model\\SAE_bottleneck_6_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0185 - val_loss: 0.0192\n",
      "Epoch 16/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0200\n",
      "Epoch 16: val_loss did not improve from 0.01920\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0184 - val_loss: 0.0192\n",
      "Epoch 17/40\n",
      "13/26 [==============>...............] - ETA: 0s - loss: 0.0194\n",
      "Epoch 17: val_loss improved from 0.01920 to 0.01911, saving model to model\\SAE_bottleneck_6_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0184 - val_loss: 0.0191\n",
      "Epoch 18/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0201\n",
      "Epoch 18: val_loss did not improve from 0.01911\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0182 - val_loss: 0.0191\n",
      "Epoch 19/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0186\n",
      "Epoch 19: val_loss improved from 0.01911 to 0.01872, saving model to model\\SAE_bottleneck_6_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0181 - val_loss: 0.0187\n",
      "Epoch 20/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0193\n",
      "Epoch 20: val_loss improved from 0.01872 to 0.01843, saving model to model\\SAE_bottleneck_6_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0178 - val_loss: 0.0184\n",
      "Epoch 21/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0156\n",
      "Epoch 21: val_loss improved from 0.01843 to 0.01816, saving model to model\\SAE_bottleneck_6_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0173 - val_loss: 0.0182\n",
      "Epoch 22/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0158\n",
      "Epoch 22: val_loss improved from 0.01816 to 0.01801, saving model to model\\SAE_bottleneck_6_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0170 - val_loss: 0.0180\n",
      "Epoch 23/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0198\n",
      "Epoch 23: val_loss improved from 0.01801 to 0.01786, saving model to model\\SAE_bottleneck_6_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0167 - val_loss: 0.0179\n",
      "Epoch 24/40\n",
      "14/26 [===============>..............] - ETA: 0s - loss: 0.0166\n",
      "Epoch 24: val_loss improved from 0.01786 to 0.01773, saving model to model\\SAE_bottleneck_6_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0166 - val_loss: 0.0177\n",
      "Epoch 25/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0137\n",
      "Epoch 25: val_loss improved from 0.01773 to 0.01772, saving model to model\\SAE_bottleneck_6_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0165 - val_loss: 0.0177\n",
      "Epoch 26/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0215\n",
      "Epoch 26: val_loss improved from 0.01772 to 0.01761, saving model to model\\SAE_bottleneck_6_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0164 - val_loss: 0.0176\n",
      "Epoch 27/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0183\n",
      "Epoch 27: val_loss improved from 0.01761 to 0.01755, saving model to model\\SAE_bottleneck_6_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0164 - val_loss: 0.0176\n",
      "Epoch 28/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0150\n",
      "Epoch 28: val_loss did not improve from 0.01755\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0163 - val_loss: 0.0176\n",
      "Epoch 29/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0168\n",
      "Epoch 29: val_loss improved from 0.01755 to 0.01749, saving model to model\\SAE_bottleneck_6_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0162 - val_loss: 0.0175\n",
      "Epoch 30/40\n",
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0162\n",
      "Epoch 30: val_loss improved from 0.01749 to 0.01745, saving model to model\\SAE_bottleneck_6_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0162 - val_loss: 0.0175\n",
      "Epoch 31/40\n",
      "14/26 [===============>..............] - ETA: 0s - loss: 0.0165\n",
      "Epoch 31: val_loss did not improve from 0.01745\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0161 - val_loss: 0.0175\n",
      "Epoch 32/40\n",
      "20/26 [======================>.......] - ETA: 0s - loss: 0.0160\n",
      "Epoch 32: val_loss did not improve from 0.01745\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0161 - val_loss: 0.0175\n",
      "Epoch 33/40\n",
      "21/26 [=======================>......] - ETA: 0s - loss: 0.0161\n",
      "Epoch 33: val_loss improved from 0.01745 to 0.01735, saving model to model\\SAE_bottleneck_6_best_model.keras\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0160 - val_loss: 0.0174\n",
      "Epoch 34/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0158\n",
      "Epoch 34: val_loss improved from 0.01735 to 0.01729, saving model to model\\SAE_bottleneck_6_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0160 - val_loss: 0.0173\n",
      "Epoch 35/40\n",
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0160\n",
      "Epoch 35: val_loss did not improve from 0.01729\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0159 - val_loss: 0.0173\n",
      "Epoch 36/40\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0159\n",
      "Epoch 36: val_loss improved from 0.01729 to 0.01727, saving model to model\\SAE_bottleneck_6_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0159 - val_loss: 0.0173\n",
      "Epoch 37/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0199\n",
      "Epoch 37: val_loss improved from 0.01727 to 0.01725, saving model to model\\SAE_bottleneck_6_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0159 - val_loss: 0.0173\n",
      "Epoch 38/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0171\n",
      "Epoch 38: val_loss did not improve from 0.01725\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0159 - val_loss: 0.0173\n",
      "Epoch 39/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0140\n",
      "Epoch 39: val_loss improved from 0.01725 to 0.01716, saving model to model\\SAE_bottleneck_6_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0158 - val_loss: 0.0172\n",
      "Epoch 40/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0185\n",
      "Epoch 40: val_loss did not improve from 0.01716\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0158 - val_loss: 0.0172\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "LogisticRegression - Mean CV Score: 0.4481538461538461\n",
      "LogisticRegression - Mean Confusion Matrix:\n",
      "[[4.6 8. ]\n",
      " [6.3 7. ]]\n",
      "SVM - Mean CV Score: 0.5136923076923077\n",
      "SVM - Mean Confusion Matrix:\n",
      "[[6.9 5.7]\n",
      " [6.9 6.4]]\n",
      "RandomForest - Mean CV Score: 0.5446153846153845\n",
      "RandomForest - Mean Confusion Matrix:\n",
      "[[6.6 6. ]\n",
      " [5.8 7.5]]\n",
      "KNN - Mean CV Score: 0.5986153846153845\n",
      "KNN - Mean Confusion Matrix:\n",
      "[[7.6 5. ]\n",
      " [5.4 7.9]]\n",
      "GradientBoosting - Mean CV Score: 0.5336923076923077\n",
      "GradientBoosting - Mean Confusion Matrix:\n",
      "[[6.6 6. ]\n",
      " [6.1 7.2]]\n",
      "AdaBoost - Mean CV Score: 0.5215384615384615\n",
      "AdaBoost - Mean Confusion Matrix:\n",
      "[[6.3 6.3]\n",
      " [6.1 7.2]]\n",
      "NaiveBayes - Mean CV Score: 0.5016923076923077\n",
      "NaiveBayes - Mean Confusion Matrix:\n",
      "[[12.5  0.1]\n",
      " [12.8  0.5]]\n",
      "DecisionTree - Mean CV Score: 0.5407692307692308\n",
      "DecisionTree - Mean Confusion Matrix:\n",
      "[[6.8 5.8]\n",
      " [6.1 7.2]]\n",
      "ExtraTrees - Mean CV Score: 0.5489230769230768\n",
      "ExtraTrees - Mean Confusion Matrix:\n",
      "[[7.  5.6]\n",
      " [6.1 7.2]]\n",
      "XGBoost - Mean CV Score: 0.5369230769230768\n",
      "XGBoost - Mean Confusion Matrix:\n",
      "[[6.7 5.9]\n",
      " [6.1 7.2]]\n",
      "Size: bottleneck_6, Best classifier: KNN, CV Score: 0.5986153846153845\n",
      "Epoch 1/40\n",
      " 1/26 [>.............................] - ETA: 25s - loss: 0.0461\n",
      "Epoch 1: val_loss improved from inf to 0.02731, saving model to model\\SAE_bottleneck_10_best_model.keras\n",
      "26/26 [==============================] - 1s 11ms/step - loss: 0.0370 - val_loss: 0.0273\n",
      "Epoch 2/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0227\n",
      "Epoch 2: val_loss improved from 0.02731 to 0.02414, saving model to model\\SAE_bottleneck_10_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0237 - val_loss: 0.0241\n",
      "Epoch 3/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0185\n",
      "Epoch 3: val_loss improved from 0.02414 to 0.02366, saving model to model\\SAE_bottleneck_10_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0227 - val_loss: 0.0237\n",
      "Epoch 4/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0182\n",
      "Epoch 4: val_loss improved from 0.02366 to 0.02333, saving model to model\\SAE_bottleneck_10_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0225 - val_loss: 0.0233\n",
      "Epoch 5/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0153\n",
      "Epoch 5: val_loss improved from 0.02333 to 0.02191, saving model to model\\SAE_bottleneck_10_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0217 - val_loss: 0.0219\n",
      "Epoch 6/40\n",
      "18/26 [===================>..........] - ETA: 0s - loss: 0.0208\n",
      "Epoch 6: val_loss improved from 0.02191 to 0.02035, saving model to model\\SAE_bottleneck_10_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0201 - val_loss: 0.0204\n",
      "Epoch 7/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0228\n",
      "Epoch 7: val_loss improved from 0.02035 to 0.01971, saving model to model\\SAE_bottleneck_10_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0192 - val_loss: 0.0197\n",
      "Epoch 8/40\n",
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0189\n",
      "Epoch 8: val_loss improved from 0.01971 to 0.01953, saving model to model\\SAE_bottleneck_10_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0188 - val_loss: 0.0195\n",
      "Epoch 9/40\n",
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0186\n",
      "Epoch 9: val_loss improved from 0.01953 to 0.01947, saving model to model\\SAE_bottleneck_10_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0186 - val_loss: 0.0195\n",
      "Epoch 10/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0180\n",
      "Epoch 10: val_loss improved from 0.01947 to 0.01940, saving model to model\\SAE_bottleneck_10_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0186 - val_loss: 0.0194\n",
      "Epoch 11/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0165\n",
      "Epoch 11: val_loss improved from 0.01940 to 0.01930, saving model to model\\SAE_bottleneck_10_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0184 - val_loss: 0.0193\n",
      "Epoch 12/40\n",
      "13/26 [==============>...............] - ETA: 0s - loss: 0.0177\n",
      "Epoch 12: val_loss improved from 0.01930 to 0.01918, saving model to model\\SAE_bottleneck_10_best_model.keras\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0183 - val_loss: 0.0192\n",
      "Epoch 13/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0166\n",
      "Epoch 13: val_loss improved from 0.01918 to 0.01905, saving model to model\\SAE_bottleneck_10_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0182 - val_loss: 0.0191\n",
      "Epoch 14/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0151\n",
      "Epoch 14: val_loss improved from 0.01905 to 0.01872, saving model to model\\SAE_bottleneck_10_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0179 - val_loss: 0.0187\n",
      "Epoch 15/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0148\n",
      "Epoch 15: val_loss improved from 0.01872 to 0.01810, saving model to model\\SAE_bottleneck_10_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0174 - val_loss: 0.0181\n",
      "Epoch 16/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0219\n",
      "Epoch 16: val_loss improved from 0.01810 to 0.01778, saving model to model\\SAE_bottleneck_10_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0168 - val_loss: 0.0178\n",
      "Epoch 17/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0184\n",
      "Epoch 17: val_loss improved from 0.01778 to 0.01759, saving model to model\\SAE_bottleneck_10_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0164 - val_loss: 0.0176\n",
      "Epoch 18/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0138\n",
      "Epoch 18: val_loss improved from 0.01759 to 0.01743, saving model to model\\SAE_bottleneck_10_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0163 - val_loss: 0.0174\n",
      "Epoch 19/40\n",
      "15/26 [================>.............] - ETA: 0s - loss: 0.0161\n",
      "Epoch 19: val_loss improved from 0.01743 to 0.01742, saving model to model\\SAE_bottleneck_10_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0161 - val_loss: 0.0174\n",
      "Epoch 20/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0174\n",
      "Epoch 20: val_loss improved from 0.01742 to 0.01735, saving model to model\\SAE_bottleneck_10_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0159 - val_loss: 0.0173\n",
      "Epoch 21/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0136\n",
      "Epoch 21: val_loss improved from 0.01735 to 0.01735, saving model to model\\SAE_bottleneck_10_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0157 - val_loss: 0.0173\n",
      "Epoch 22/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0134\n",
      "Epoch 22: val_loss improved from 0.01735 to 0.01720, saving model to model\\SAE_bottleneck_10_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0156 - val_loss: 0.0172\n",
      "Epoch 23/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0152\n",
      "Epoch 23: val_loss improved from 0.01720 to 0.01716, saving model to model\\SAE_bottleneck_10_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0153 - val_loss: 0.0172\n",
      "Epoch 24/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0174\n",
      "Epoch 24: val_loss improved from 0.01716 to 0.01699, saving model to model\\SAE_bottleneck_10_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0152 - val_loss: 0.0170\n",
      "Epoch 25/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0175\n",
      "Epoch 25: val_loss improved from 0.01699 to 0.01699, saving model to model\\SAE_bottleneck_10_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0151 - val_loss: 0.0170\n",
      "Epoch 26/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0172\n",
      "Epoch 26: val_loss improved from 0.01699 to 0.01690, saving model to model\\SAE_bottleneck_10_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0150 - val_loss: 0.0169\n",
      "Epoch 27/40\n",
      "12/26 [============>.................] - ETA: 0s - loss: 0.0152\n",
      "Epoch 27: val_loss did not improve from 0.01690\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0149 - val_loss: 0.0169\n",
      "Epoch 28/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0139\n",
      "Epoch 28: val_loss improved from 0.01690 to 0.01689, saving model to model\\SAE_bottleneck_10_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0148 - val_loss: 0.0169\n",
      "Epoch 29/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0121\n",
      "Epoch 29: val_loss improved from 0.01689 to 0.01675, saving model to model\\SAE_bottleneck_10_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0147 - val_loss: 0.0168\n",
      "Epoch 30/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0181\n",
      "Epoch 30: val_loss did not improve from 0.01675\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0147 - val_loss: 0.0168\n",
      "Epoch 31/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0131\n",
      "Epoch 31: val_loss improved from 0.01675 to 0.01670, saving model to model\\SAE_bottleneck_10_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0146 - val_loss: 0.0167\n",
      "Epoch 32/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0132\n",
      "Epoch 32: val_loss did not improve from 0.01670\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0145 - val_loss: 0.0168\n",
      "Epoch 33/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0158\n",
      "Epoch 33: val_loss did not improve from 0.01670\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0145 - val_loss: 0.0168\n",
      "Epoch 34/40\n",
      "19/26 [====================>.........] - ETA: 0s - loss: 0.0145\n",
      "Epoch 34: val_loss improved from 0.01670 to 0.01664, saving model to model\\SAE_bottleneck_10_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0144 - val_loss: 0.0166\n",
      "Epoch 35/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0148\n",
      "Epoch 35: val_loss did not improve from 0.01664\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0143 - val_loss: 0.0167\n",
      "Epoch 36/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0154\n",
      "Epoch 36: val_loss improved from 0.01664 to 0.01661, saving model to model\\SAE_bottleneck_10_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0143 - val_loss: 0.0166\n",
      "Epoch 37/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0152\n",
      "Epoch 37: val_loss did not improve from 0.01661\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0142 - val_loss: 0.0166\n",
      "Epoch 38/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0131\n",
      "Epoch 38: val_loss did not improve from 0.01661\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0142 - val_loss: 0.0166\n",
      "Epoch 39/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0175\n",
      "Epoch 39: val_loss improved from 0.01661 to 0.01655, saving model to model\\SAE_bottleneck_10_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0142 - val_loss: 0.0166\n",
      "Epoch 40/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0130\n",
      "Epoch 40: val_loss improved from 0.01655 to 0.01653, saving model to model\\SAE_bottleneck_10_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0141 - val_loss: 0.0165\n",
      "9/9 [==============================] - 0s 996us/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "LogisticRegression - Mean CV Score: 0.5598461538461539\n",
      "LogisticRegression - Mean Confusion Matrix:\n",
      "[[7.1 5.5]\n",
      " [5.9 7.4]]\n",
      "SVM - Mean CV Score: 0.5404615384615384\n",
      "SVM - Mean Confusion Matrix:\n",
      "[[7.3 5.3]\n",
      " [6.6 6.7]]\n",
      "RandomForest - Mean CV Score: 0.5984615384615384\n",
      "RandomForest - Mean Confusion Matrix:\n",
      "[[7.5 5.1]\n",
      " [5.3 8. ]]\n",
      "KNN - Mean CV Score: 0.5599999999999999\n",
      "KNN - Mean Confusion Matrix:\n",
      "[[7.8 4.8]\n",
      " [6.6 6.7]]\n",
      "GradientBoosting - Mean CV Score: 0.5827692307692308\n",
      "GradientBoosting - Mean Confusion Matrix:\n",
      "[[7.6 5. ]\n",
      " [5.8 7.5]]\n",
      "AdaBoost - Mean CV Score: 0.5404615384615384\n",
      "AdaBoost - Mean Confusion Matrix:\n",
      "[[7.2 5.4]\n",
      " [6.5 6.8]]\n",
      "NaiveBayes - Mean CV Score: 0.5561538461538461\n",
      "NaiveBayes - Mean Confusion Matrix:\n",
      "[[8.8 3.8]\n",
      " [7.7 5.6]]\n",
      "DecisionTree - Mean CV Score: 0.5252307692307692\n",
      "DecisionTree - Mean Confusion Matrix:\n",
      "[[6.9 5.7]\n",
      " [6.6 6.7]]\n",
      "ExtraTrees - Mean CV Score: 0.5907692307692308\n",
      "ExtraTrees - Mean Confusion Matrix:\n",
      "[[7.2 5.4]\n",
      " [5.2 8.1]]\n",
      "XGBoost - Mean CV Score: 0.6172307692307692\n",
      "XGBoost - Mean Confusion Matrix:\n",
      "[[7.2 5.4]\n",
      " [4.5 8.8]]\n",
      "Size: bottleneck_10, Best classifier: XGBoost, CV Score: 0.6172307692307692\n",
      "Epoch 1/40\n",
      " 1/26 [>.............................] - ETA: 24s - loss: 0.0462\n",
      "Epoch 1: val_loss improved from inf to 0.02736, saving model to model\\SAE_bottleneck_14_best_model.keras\n",
      "26/26 [==============================] - 1s 11ms/step - loss: 0.0376 - val_loss: 0.0274\n",
      "Epoch 2/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0236\n",
      "Epoch 2: val_loss improved from 0.02736 to 0.02397, saving model to model\\SAE_bottleneck_14_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0237 - val_loss: 0.0240\n",
      "Epoch 3/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0236\n",
      "Epoch 3: val_loss improved from 0.02397 to 0.02310, saving model to model\\SAE_bottleneck_14_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0224 - val_loss: 0.0231\n",
      "Epoch 4/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0202\n",
      "Epoch 4: val_loss improved from 0.02310 to 0.02125, saving model to model\\SAE_bottleneck_14_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0212 - val_loss: 0.0213\n",
      "Epoch 5/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0224\n",
      "Epoch 5: val_loss improved from 0.02125 to 0.01962, saving model to model\\SAE_bottleneck_14_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0194 - val_loss: 0.0196\n",
      "Epoch 6/40\n",
      "10/26 [==========>...................] - ETA: 0s - loss: 0.0192\n",
      "Epoch 6: val_loss improved from 0.01962 to 0.01893, saving model to model\\SAE_bottleneck_14_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0184 - val_loss: 0.0189\n",
      "Epoch 7/40\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0177\n",
      "Epoch 7: val_loss improved from 0.01893 to 0.01828, saving model to model\\SAE_bottleneck_14_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0177 - val_loss: 0.0183\n",
      "Epoch 8/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0206\n",
      "Epoch 8: val_loss improved from 0.01828 to 0.01809, saving model to model\\SAE_bottleneck_14_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0172 - val_loss: 0.0181\n",
      "Epoch 9/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0150\n",
      "Epoch 9: val_loss improved from 0.01809 to 0.01773, saving model to model\\SAE_bottleneck_14_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0168 - val_loss: 0.0177\n",
      "Epoch 10/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0214\n",
      "Epoch 10: val_loss improved from 0.01773 to 0.01731, saving model to model\\SAE_bottleneck_14_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0165 - val_loss: 0.0173\n",
      "Epoch 11/40\n",
      "15/26 [================>.............] - ETA: 0s - loss: 0.0158\n",
      "Epoch 11: val_loss improved from 0.01731 to 0.01697, saving model to model\\SAE_bottleneck_14_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0160 - val_loss: 0.0170\n",
      "Epoch 12/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0189\n",
      "Epoch 12: val_loss improved from 0.01697 to 0.01666, saving model to model\\SAE_bottleneck_14_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0156 - val_loss: 0.0167\n",
      "Epoch 13/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0126\n",
      "Epoch 13: val_loss improved from 0.01666 to 0.01653, saving model to model\\SAE_bottleneck_14_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0154 - val_loss: 0.0165\n",
      "Epoch 14/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0191\n",
      "Epoch 14: val_loss improved from 0.01653 to 0.01632, saving model to model\\SAE_bottleneck_14_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0150 - val_loss: 0.0163\n",
      "Epoch 15/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0140\n",
      "Epoch 15: val_loss improved from 0.01632 to 0.01616, saving model to model\\SAE_bottleneck_14_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0148 - val_loss: 0.0162\n",
      "Epoch 16/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0172\n",
      "Epoch 16: val_loss improved from 0.01616 to 0.01601, saving model to model\\SAE_bottleneck_14_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0146 - val_loss: 0.0160\n",
      "Epoch 17/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0120\n",
      "Epoch 17: val_loss improved from 0.01601 to 0.01583, saving model to model\\SAE_bottleneck_14_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0143 - val_loss: 0.0158\n",
      "Epoch 18/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0144\n",
      "Epoch 18: val_loss improved from 0.01583 to 0.01571, saving model to model\\SAE_bottleneck_14_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0142 - val_loss: 0.0157\n",
      "Epoch 19/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0133\n",
      "Epoch 19: val_loss improved from 0.01571 to 0.01560, saving model to model\\SAE_bottleneck_14_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0140 - val_loss: 0.0156\n",
      "Epoch 20/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0129\n",
      "Epoch 20: val_loss improved from 0.01560 to 0.01553, saving model to model\\SAE_bottleneck_14_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0138 - val_loss: 0.0155\n",
      "Epoch 21/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0116\n",
      "Epoch 21: val_loss did not improve from 0.01553\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0137 - val_loss: 0.0155\n",
      "Epoch 22/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0144\n",
      "Epoch 22: val_loss improved from 0.01553 to 0.01549, saving model to model\\SAE_bottleneck_14_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0136 - val_loss: 0.0155\n",
      "Epoch 23/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0126\n",
      "Epoch 23: val_loss improved from 0.01549 to 0.01547, saving model to model\\SAE_bottleneck_14_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0135 - val_loss: 0.0155\n",
      "Epoch 24/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0127\n",
      "Epoch 24: val_loss improved from 0.01547 to 0.01544, saving model to model\\SAE_bottleneck_14_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0134 - val_loss: 0.0154\n",
      "Epoch 25/40\n",
      "19/26 [====================>.........] - ETA: 0s - loss: 0.0135\n",
      "Epoch 25: val_loss improved from 0.01544 to 0.01535, saving model to model\\SAE_bottleneck_14_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0133 - val_loss: 0.0153\n",
      "Epoch 26/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0146\n",
      "Epoch 26: val_loss improved from 0.01535 to 0.01532, saving model to model\\SAE_bottleneck_14_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0132 - val_loss: 0.0153\n",
      "Epoch 27/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0095\n",
      "Epoch 27: val_loss improved from 0.01532 to 0.01523, saving model to model\\SAE_bottleneck_14_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0132 - val_loss: 0.0152\n",
      "Epoch 28/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0120\n",
      "Epoch 28: val_loss improved from 0.01523 to 0.01519, saving model to model\\SAE_bottleneck_14_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0131 - val_loss: 0.0152\n",
      "Epoch 29/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0116\n",
      "Epoch 29: val_loss improved from 0.01519 to 0.01519, saving model to model\\SAE_bottleneck_14_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0130 - val_loss: 0.0152\n",
      "Epoch 30/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0139\n",
      "Epoch 30: val_loss improved from 0.01519 to 0.01514, saving model to model\\SAE_bottleneck_14_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0129 - val_loss: 0.0151\n",
      "Epoch 31/40\n",
      "10/26 [==========>...................] - ETA: 0s - loss: 0.0132\n",
      "Epoch 31: val_loss improved from 0.01514 to 0.01502, saving model to model\\SAE_bottleneck_14_best_model.keras\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0128 - val_loss: 0.0150\n",
      "Epoch 32/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0110\n",
      "Epoch 32: val_loss improved from 0.01502 to 0.01499, saving model to model\\SAE_bottleneck_14_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0127 - val_loss: 0.0150\n",
      "Epoch 33/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0128\n",
      "Epoch 33: val_loss improved from 0.01499 to 0.01490, saving model to model\\SAE_bottleneck_14_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0126 - val_loss: 0.0149\n",
      "Epoch 34/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0109\n",
      "Epoch 34: val_loss improved from 0.01490 to 0.01486, saving model to model\\SAE_bottleneck_14_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0125 - val_loss: 0.0149\n",
      "Epoch 35/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0119\n",
      "Epoch 35: val_loss did not improve from 0.01486\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0125 - val_loss: 0.0149\n",
      "Epoch 36/40\n",
      "19/26 [====================>.........] - ETA: 0s - loss: 0.0126\n",
      "Epoch 36: val_loss improved from 0.01486 to 0.01476, saving model to model\\SAE_bottleneck_14_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0124 - val_loss: 0.0148\n",
      "Epoch 37/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0138\n",
      "Epoch 37: val_loss improved from 0.01476 to 0.01471, saving model to model\\SAE_bottleneck_14_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0123 - val_loss: 0.0147\n",
      "Epoch 38/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0101\n",
      "Epoch 38: val_loss improved from 0.01471 to 0.01467, saving model to model\\SAE_bottleneck_14_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0122 - val_loss: 0.0147\n",
      "Epoch 39/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0125\n",
      "Epoch 39: val_loss improved from 0.01467 to 0.01464, saving model to model\\SAE_bottleneck_14_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0121 - val_loss: 0.0146\n",
      "Epoch 40/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0120\n",
      "Epoch 40: val_loss did not improve from 0.01464\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0121 - val_loss: 0.0147\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "LogisticRegression - Mean CV Score: 0.5675384615384615\n",
      "LogisticRegression - Mean Confusion Matrix:\n",
      "[[6.4 6.2]\n",
      " [5.  8.3]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM - Mean CV Score: 0.622\n",
      "SVM - Mean Confusion Matrix:\n",
      "[[6.8 5.8]\n",
      " [4.  9.3]]\n",
      "RandomForest - Mean CV Score: 0.6447692307692308\n",
      "RandomForest - Mean Confusion Matrix:\n",
      "[[7.5 5.1]\n",
      " [4.1 9.2]]\n",
      "KNN - Mean CV Score: 0.5867692307692307\n",
      "KNN - Mean Confusion Matrix:\n",
      "[[7.4 5.2]\n",
      " [5.5 7.8]]\n",
      "GradientBoosting - Mean CV Score: 0.6178461538461539\n",
      "GradientBoosting - Mean Confusion Matrix:\n",
      "[[7.4 5.2]\n",
      " [4.7 8.6]]\n",
      "AdaBoost - Mean CV Score: 0.5749230769230769\n",
      "AdaBoost - Mean Confusion Matrix:\n",
      "[[7.  5.6]\n",
      " [5.4 7.9]]\n",
      "NaiveBayes - Mean CV Score: 0.548\n",
      "NaiveBayes - Mean Confusion Matrix:\n",
      "[[8.3 4.3]\n",
      " [7.4 5.9]]\n",
      "DecisionTree - Mean CV Score: 0.5409230769230768\n",
      "DecisionTree - Mean Confusion Matrix:\n",
      "[[7.1 5.5]\n",
      " [6.4 6.9]]\n",
      "ExtraTrees - Mean CV Score: 0.6216923076923077\n",
      "ExtraTrees - Mean Confusion Matrix:\n",
      "[[7.4 5.2]\n",
      " [4.6 8.7]]\n",
      "XGBoost - Mean CV Score: 0.6132307692307692\n",
      "XGBoost - Mean Confusion Matrix:\n",
      "[[6.8 5.8]\n",
      " [4.2 9.1]]\n",
      "Size: bottleneck_14, Best classifier: RandomForest, CV Score: 0.6447692307692308\n",
      "Epoch 1/40\n",
      " 1/26 [>.............................] - ETA: 23s - loss: 0.0463\n",
      "Epoch 1: val_loss improved from inf to 0.02783, saving model to model\\SAE_bottleneck_18_best_model.keras\n",
      "26/26 [==============================] - 1s 11ms/step - loss: 0.0382 - val_loss: 0.0278\n",
      "Epoch 2/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0279\n",
      "Epoch 2: val_loss improved from 0.02783 to 0.02395, saving model to model\\SAE_bottleneck_18_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0239 - val_loss: 0.0240\n",
      "Epoch 3/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0173\n",
      "Epoch 3: val_loss improved from 0.02395 to 0.02289, saving model to model\\SAE_bottleneck_18_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0223 - val_loss: 0.0229\n",
      "Epoch 4/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0222\n",
      "Epoch 4: val_loss improved from 0.02289 to 0.02096, saving model to model\\SAE_bottleneck_18_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0209 - val_loss: 0.0210\n",
      "Epoch 5/40\n",
      "14/26 [===============>..............] - ETA: 0s - loss: 0.0195\n",
      "Epoch 5: val_loss improved from 0.02096 to 0.01989, saving model to model\\SAE_bottleneck_18_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0194 - val_loss: 0.0199\n",
      "Epoch 6/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0155\n",
      "Epoch 6: val_loss improved from 0.01989 to 0.01951, saving model to model\\SAE_bottleneck_18_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0189 - val_loss: 0.0195\n",
      "Epoch 7/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0148\n",
      "Epoch 7: val_loss improved from 0.01951 to 0.01927, saving model to model\\SAE_bottleneck_18_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0187 - val_loss: 0.0193\n",
      "Epoch 8/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0192\n",
      "Epoch 8: val_loss improved from 0.01927 to 0.01906, saving model to model\\SAE_bottleneck_18_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0185 - val_loss: 0.0191\n",
      "Epoch 9/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0210\n",
      "Epoch 9: val_loss improved from 0.01906 to 0.01870, saving model to model\\SAE_bottleneck_18_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0181 - val_loss: 0.0187\n",
      "Epoch 10/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0213\n",
      "Epoch 10: val_loss improved from 0.01870 to 0.01817, saving model to model\\SAE_bottleneck_18_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0175 - val_loss: 0.0182\n",
      "Epoch 11/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0190\n",
      "Epoch 11: val_loss improved from 0.01817 to 0.01759, saving model to model\\SAE_bottleneck_18_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0169 - val_loss: 0.0176\n",
      "Epoch 12/40\n",
      "17/26 [==================>...........] - ETA: 0s - loss: 0.0163\n",
      "Epoch 12: val_loss improved from 0.01759 to 0.01741, saving model to model\\SAE_bottleneck_18_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0164 - val_loss: 0.0174\n",
      "Epoch 13/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0155\n",
      "Epoch 13: val_loss improved from 0.01741 to 0.01716, saving model to model\\SAE_bottleneck_18_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0161 - val_loss: 0.0172\n",
      "Epoch 14/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0162\n",
      "Epoch 14: val_loss improved from 0.01716 to 0.01707, saving model to model\\SAE_bottleneck_18_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0159 - val_loss: 0.0171\n",
      "Epoch 15/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0173\n",
      "Epoch 15: val_loss improved from 0.01707 to 0.01687, saving model to model\\SAE_bottleneck_18_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0157 - val_loss: 0.0169\n",
      "Epoch 16/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0168\n",
      "Epoch 16: val_loss improved from 0.01687 to 0.01677, saving model to model\\SAE_bottleneck_18_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0155 - val_loss: 0.0168\n",
      "Epoch 17/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0153\n",
      "Epoch 17: val_loss improved from 0.01677 to 0.01665, saving model to model\\SAE_bottleneck_18_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0152 - val_loss: 0.0167\n",
      "Epoch 18/40\n",
      "11/26 [===========>..................] - ETA: 0s - loss: 0.0148\n",
      "Epoch 18: val_loss improved from 0.01665 to 0.01643, saving model to model\\SAE_bottleneck_18_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0151 - val_loss: 0.0164\n",
      "Epoch 19/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0148\n",
      "Epoch 19: val_loss improved from 0.01643 to 0.01608, saving model to model\\SAE_bottleneck_18_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0147 - val_loss: 0.0161\n",
      "Epoch 20/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0136\n",
      "Epoch 20: val_loss improved from 0.01608 to 0.01589, saving model to model\\SAE_bottleneck_18_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0144 - val_loss: 0.0159\n",
      "Epoch 21/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0150\n",
      "Epoch 21: val_loss improved from 0.01589 to 0.01583, saving model to model\\SAE_bottleneck_18_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0141 - val_loss: 0.0158\n",
      "Epoch 22/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0151\n",
      "Epoch 22: val_loss improved from 0.01583 to 0.01568, saving model to model\\SAE_bottleneck_18_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0140 - val_loss: 0.0157\n",
      "Epoch 23/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0150\n",
      "Epoch 23: val_loss improved from 0.01568 to 0.01565, saving model to model\\SAE_bottleneck_18_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0138 - val_loss: 0.0157\n",
      "Epoch 24/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0141\n",
      "Epoch 24: val_loss did not improve from 0.01565\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0137 - val_loss: 0.0157\n",
      "Epoch 25/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0131\n",
      "Epoch 25: val_loss improved from 0.01565 to 0.01562, saving model to model\\SAE_bottleneck_18_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0136 - val_loss: 0.0156\n",
      "Epoch 26/40\n",
      "13/26 [==============>...............] - ETA: 0s - loss: 0.0135\n",
      "Epoch 26: val_loss did not improve from 0.01562\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0135 - val_loss: 0.0157\n",
      "Epoch 27/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0121\n",
      "Epoch 27: val_loss did not improve from 0.01562\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0135 - val_loss: 0.0157\n",
      "Epoch 28/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0124\n",
      "Epoch 28: val_loss improved from 0.01562 to 0.01555, saving model to model\\SAE_bottleneck_18_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0134 - val_loss: 0.0156\n",
      "Epoch 29/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0146\n",
      "Epoch 29: val_loss did not improve from 0.01555\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0133 - val_loss: 0.0156\n",
      "Epoch 30/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0109\n",
      "Epoch 30: val_loss improved from 0.01555 to 0.01554, saving model to model\\SAE_bottleneck_18_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0132 - val_loss: 0.0155\n",
      "Epoch 31/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0126\n",
      "Epoch 31: val_loss improved from 0.01554 to 0.01551, saving model to model\\SAE_bottleneck_18_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0131 - val_loss: 0.0155\n",
      "Epoch 32/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0108\n",
      "Epoch 32: val_loss improved from 0.01551 to 0.01545, saving model to model\\SAE_bottleneck_18_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0131 - val_loss: 0.0155\n",
      "Epoch 33/40\n",
      "13/26 [==============>...............] - ETA: 0s - loss: 0.0126\n",
      "Epoch 33: val_loss did not improve from 0.01545\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0130 - val_loss: 0.0155\n",
      "Epoch 34/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0108\n",
      "Epoch 34: val_loss improved from 0.01545 to 0.01540, saving model to model\\SAE_bottleneck_18_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0129 - val_loss: 0.0154\n",
      "Epoch 35/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0129\n",
      "Epoch 35: val_loss did not improve from 0.01540\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0128 - val_loss: 0.0154\n",
      "Epoch 36/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0137\n",
      "Epoch 36: val_loss did not improve from 0.01540\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0127 - val_loss: 0.0154\n",
      "Epoch 37/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0127\n",
      "Epoch 37: val_loss did not improve from 0.01540\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0126 - val_loss: 0.0154\n",
      "Epoch 38/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0117\n",
      "Epoch 38: val_loss improved from 0.01540 to 0.01538, saving model to model\\SAE_bottleneck_18_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0125 - val_loss: 0.0154\n",
      "Epoch 39/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0100\n",
      "Epoch 39: val_loss improved from 0.01538 to 0.01537, saving model to model\\SAE_bottleneck_18_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0125 - val_loss: 0.0154\n",
      "Epoch 40/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0139\n",
      "Epoch 40: val_loss improved from 0.01537 to 0.01520, saving model to model\\SAE_bottleneck_18_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0124 - val_loss: 0.0152\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "LogisticRegression - Mean CV Score: 0.5827692307692308\n",
      "LogisticRegression - Mean Confusion Matrix:\n",
      "[[7.5 5.1]\n",
      " [5.7 7.6]]\n",
      "SVM - Mean CV Score: 0.5950769230769231\n",
      "SVM - Mean Confusion Matrix:\n",
      "[[8.3 4.3]\n",
      " [6.2 7.1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest - Mean CV Score: 0.6138461538461539\n",
      "RandomForest - Mean Confusion Matrix:\n",
      "[[7.7 4.9]\n",
      " [5.1 8.2]]\n",
      "KNN - Mean CV Score: 0.5986153846153845\n",
      "KNN - Mean Confusion Matrix:\n",
      "[[7.8 4.8]\n",
      " [5.6 7.7]]\n",
      "GradientBoosting - Mean CV Score: 0.578923076923077\n",
      "GradientBoosting - Mean Confusion Matrix:\n",
      "[[7.3 5.3]\n",
      " [5.6 7.7]]\n",
      "AdaBoost - Mean CV Score: 0.5941538461538463\n",
      "AdaBoost - Mean Confusion Matrix:\n",
      "[[7.4 5.2]\n",
      " [5.3 8. ]]\n",
      "NaiveBayes - Mean CV Score: 0.5132307692307692\n",
      "NaiveBayes - Mean Confusion Matrix:\n",
      "[[11.6  1. ]\n",
      " [11.6  1.7]]\n",
      "DecisionTree - Mean CV Score: 0.6055384615384616\n",
      "DecisionTree - Mean Confusion Matrix:\n",
      "[[7.7 4.9]\n",
      " [5.3 8. ]]\n",
      "ExtraTrees - Mean CV Score: 0.6176923076923078\n",
      "ExtraTrees - Mean Confusion Matrix:\n",
      "[[7.9 4.7]\n",
      " [5.2 8.1]]\n",
      "XGBoost - Mean CV Score: 0.6218461538461538\n",
      "XGBoost - Mean Confusion Matrix:\n",
      "[[6.9 5.7]\n",
      " [4.1 9.2]]\n",
      "Size: bottleneck_18, Best classifier: XGBoost, CV Score: 0.6218461538461538\n",
      "Epoch 1/40\n",
      " 1/26 [>.............................] - ETA: 24s - loss: 0.0465\n",
      "Epoch 1: val_loss improved from inf to 0.02784, saving model to model\\SAE_bottleneck_22_best_model.keras\n",
      "26/26 [==============================] - 1s 11ms/step - loss: 0.0370 - val_loss: 0.0278\n",
      "Epoch 2/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0233\n",
      "Epoch 2: val_loss improved from 0.02784 to 0.02432, saving model to model\\SAE_bottleneck_22_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0242 - val_loss: 0.0243\n",
      "Epoch 3/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0181\n",
      "Epoch 3: val_loss improved from 0.02432 to 0.02372, saving model to model\\SAE_bottleneck_22_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0228 - val_loss: 0.0237\n",
      "Epoch 4/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0241\n",
      "Epoch 4: val_loss improved from 0.02372 to 0.02245, saving model to model\\SAE_bottleneck_22_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0222 - val_loss: 0.0224\n",
      "Epoch 5/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0266\n",
      "Epoch 5: val_loss improved from 0.02245 to 0.02033, saving model to model\\SAE_bottleneck_22_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0203 - val_loss: 0.0203\n",
      "Epoch 6/40\n",
      "13/26 [==============>...............] - ETA: 0s - loss: 0.0195\n",
      "Epoch 6: val_loss improved from 0.02033 to 0.01937, saving model to model\\SAE_bottleneck_22_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0190 - val_loss: 0.0194\n",
      "Epoch 7/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0185\n",
      "Epoch 7: val_loss improved from 0.01937 to 0.01900, saving model to model\\SAE_bottleneck_22_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0184 - val_loss: 0.0190\n",
      "Epoch 8/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0179\n",
      "Epoch 8: val_loss improved from 0.01900 to 0.01825, saving model to model\\SAE_bottleneck_22_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0179 - val_loss: 0.0183\n",
      "Epoch 9/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0170\n",
      "Epoch 9: val_loss improved from 0.01825 to 0.01786, saving model to model\\SAE_bottleneck_22_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0172 - val_loss: 0.0179\n",
      "Epoch 10/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0135\n",
      "Epoch 10: val_loss improved from 0.01786 to 0.01757, saving model to model\\SAE_bottleneck_22_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0168 - val_loss: 0.0176\n",
      "Epoch 11/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0174\n",
      "Epoch 11: val_loss improved from 0.01757 to 0.01751, saving model to model\\SAE_bottleneck_22_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0166 - val_loss: 0.0175\n",
      "Epoch 12/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0156\n",
      "Epoch 12: val_loss improved from 0.01751 to 0.01708, saving model to model\\SAE_bottleneck_22_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0162 - val_loss: 0.0171\n",
      "Epoch 13/40\n",
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0158\n",
      "Epoch 13: val_loss improved from 0.01708 to 0.01680, saving model to model\\SAE_bottleneck_22_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0158 - val_loss: 0.0168\n",
      "Epoch 14/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0156\n",
      "Epoch 14: val_loss improved from 0.01680 to 0.01664, saving model to model\\SAE_bottleneck_22_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0155 - val_loss: 0.0166\n",
      "Epoch 15/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0168\n",
      "Epoch 15: val_loss improved from 0.01664 to 0.01657, saving model to model\\SAE_bottleneck_22_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0152 - val_loss: 0.0166\n",
      "Epoch 16/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0148\n",
      "Epoch 16: val_loss improved from 0.01657 to 0.01644, saving model to model\\SAE_bottleneck_22_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0150 - val_loss: 0.0164\n",
      "Epoch 17/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0125\n",
      "Epoch 17: val_loss improved from 0.01644 to 0.01620, saving model to model\\SAE_bottleneck_22_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0148 - val_loss: 0.0162\n",
      "Epoch 18/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0156\n",
      "Epoch 18: val_loss improved from 0.01620 to 0.01614, saving model to model\\SAE_bottleneck_22_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0146 - val_loss: 0.0161\n",
      "Epoch 19/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0136\n",
      "Epoch 19: val_loss improved from 0.01614 to 0.01599, saving model to model\\SAE_bottleneck_22_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0145 - val_loss: 0.0160\n",
      "Epoch 20/40\n",
      "16/26 [=================>............] - ETA: 0s - loss: 0.0144\n",
      "Epoch 20: val_loss improved from 0.01599 to 0.01593, saving model to model\\SAE_bottleneck_22_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0143 - val_loss: 0.0159\n",
      "Epoch 21/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0127\n",
      "Epoch 21: val_loss improved from 0.01593 to 0.01579, saving model to model\\SAE_bottleneck_22_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0142 - val_loss: 0.0158\n",
      "Epoch 22/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0121\n",
      "Epoch 22: val_loss did not improve from 0.01579\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0140 - val_loss: 0.0158\n",
      "Epoch 23/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0131\n",
      "Epoch 23: val_loss improved from 0.01579 to 0.01577, saving model to model\\SAE_bottleneck_22_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0139 - val_loss: 0.0158\n",
      "Epoch 24/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0124\n",
      "Epoch 24: val_loss improved from 0.01577 to 0.01574, saving model to model\\SAE_bottleneck_22_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0137 - val_loss: 0.0157\n",
      "Epoch 25/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0121\n",
      "Epoch 25: val_loss improved from 0.01574 to 0.01565, saving model to model\\SAE_bottleneck_22_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0136 - val_loss: 0.0157\n",
      "Epoch 26/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0155\n",
      "Epoch 26: val_loss improved from 0.01565 to 0.01557, saving model to model\\SAE_bottleneck_22_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0135 - val_loss: 0.0156\n",
      "Epoch 27/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0167\n",
      "Epoch 27: val_loss improved from 0.01557 to 0.01547, saving model to model\\SAE_bottleneck_22_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0133 - val_loss: 0.0155\n",
      "Epoch 28/40\n",
      "10/26 [==========>...................] - ETA: 0s - loss: 0.0128\n",
      "Epoch 28: val_loss improved from 0.01547 to 0.01543, saving model to model\\SAE_bottleneck_22_best_model.keras\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0132 - val_loss: 0.0154\n",
      "Epoch 29/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0108\n",
      "Epoch 29: val_loss did not improve from 0.01543\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0130 - val_loss: 0.0154\n",
      "Epoch 30/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0126\n",
      "Epoch 30: val_loss improved from 0.01543 to 0.01536, saving model to model\\SAE_bottleneck_22_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0129 - val_loss: 0.0154\n",
      "Epoch 31/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0107\n",
      "Epoch 31: val_loss improved from 0.01536 to 0.01535, saving model to model\\SAE_bottleneck_22_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0128 - val_loss: 0.0154\n",
      "Epoch 32/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0134\n",
      "Epoch 32: val_loss did not improve from 0.01535\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0127 - val_loss: 0.0154\n",
      "Epoch 33/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0134\n",
      "Epoch 33: val_loss improved from 0.01535 to 0.01534, saving model to model\\SAE_bottleneck_22_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0126 - val_loss: 0.0153\n",
      "Epoch 34/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0139\n",
      "Epoch 34: val_loss improved from 0.01534 to 0.01527, saving model to model\\SAE_bottleneck_22_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0124 - val_loss: 0.0153\n",
      "Epoch 35/40\n",
      "19/26 [====================>.........] - ETA: 0s - loss: 0.0124\n",
      "Epoch 35: val_loss improved from 0.01527 to 0.01522, saving model to model\\SAE_bottleneck_22_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0124 - val_loss: 0.0152\n",
      "Epoch 36/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0099\n",
      "Epoch 36: val_loss improved from 0.01522 to 0.01519, saving model to model\\SAE_bottleneck_22_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0123 - val_loss: 0.0152\n",
      "Epoch 37/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0103\n",
      "Epoch 37: val_loss improved from 0.01519 to 0.01516, saving model to model\\SAE_bottleneck_22_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0123 - val_loss: 0.0152\n",
      "Epoch 38/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0125\n",
      "Epoch 38: val_loss improved from 0.01516 to 0.01512, saving model to model\\SAE_bottleneck_22_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0121 - val_loss: 0.0151\n",
      "Epoch 39/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0132\n",
      "Epoch 39: val_loss did not improve from 0.01512\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0120 - val_loss: 0.0152\n",
      "Epoch 40/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0123\n",
      "Epoch 40: val_loss improved from 0.01512 to 0.01505, saving model to model\\SAE_bottleneck_22_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0119 - val_loss: 0.0150\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "LogisticRegression - Mean CV Score: 0.5713846153846154\n",
      "LogisticRegression - Mean Confusion Matrix:\n",
      "[[6.8 5.8]\n",
      " [5.3 8. ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM - Mean CV Score: 0.5716923076923076\n",
      "SVM - Mean Confusion Matrix:\n",
      "[[7.1 5.5]\n",
      " [5.6 7.7]]\n",
      "RandomForest - Mean CV Score: 0.6060000000000001\n",
      "RandomForest - Mean Confusion Matrix:\n",
      "[[7.5 5.1]\n",
      " [5.1 8.2]]\n",
      "KNN - Mean CV Score: 0.6018461538461539\n",
      "KNN - Mean Confusion Matrix:\n",
      "[[8.  4.6]\n",
      " [5.7 7.6]]\n",
      "GradientBoosting - Mean CV Score: 0.6138461538461538\n",
      "GradientBoosting - Mean Confusion Matrix:\n",
      "[[7.7 4.9]\n",
      " [5.1 8.2]]\n",
      "AdaBoost - Mean CV Score: 0.5250769230769231\n",
      "AdaBoost - Mean Confusion Matrix:\n",
      "[[6.9 5.7]\n",
      " [6.6 6.7]]\n",
      "NaiveBayes - Mean CV Score: 0.567076923076923\n",
      "NaiveBayes - Mean Confusion Matrix:\n",
      "[[10.6  2. ]\n",
      " [ 9.2  4.1]]\n",
      "DecisionTree - Mean CV Score: 0.5366153846153845\n",
      "DecisionTree - Mean Confusion Matrix:\n",
      "[[7.  5.6]\n",
      " [6.4 6.9]]\n",
      "ExtraTrees - Mean CV Score: 0.6136923076923078\n",
      "ExtraTrees - Mean Confusion Matrix:\n",
      "[[7.7 4.9]\n",
      " [5.1 8.2]]\n",
      "XGBoost - Mean CV Score: 0.61\n",
      "XGBoost - Mean Confusion Matrix:\n",
      "[[7.2 5.4]\n",
      " [4.7 8.6]]\n",
      "Size: bottleneck_22, Best classifier: GradientBoosting, CV Score: 0.6138461538461538\n",
      "Epoch 1/40\n",
      " 1/26 [>.............................] - ETA: 24s - loss: 0.0472\n",
      "Epoch 1: val_loss improved from inf to 0.02705, saving model to model\\SAE_bottleneck_26_best_model.keras\n",
      "26/26 [==============================] - 1s 11ms/step - loss: 0.0366 - val_loss: 0.0270\n",
      "Epoch 2/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0254\n",
      "Epoch 2: val_loss improved from 0.02705 to 0.02444, saving model to model\\SAE_bottleneck_26_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0239 - val_loss: 0.0244\n",
      "Epoch 3/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0178\n",
      "Epoch 3: val_loss improved from 0.02444 to 0.02347, saving model to model\\SAE_bottleneck_26_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0227 - val_loss: 0.0235\n",
      "Epoch 4/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0186\n",
      "Epoch 4: val_loss improved from 0.02347 to 0.02147, saving model to model\\SAE_bottleneck_26_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0214 - val_loss: 0.0215\n",
      "Epoch 5/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0197\n",
      "Epoch 5: val_loss improved from 0.02147 to 0.02054, saving model to model\\SAE_bottleneck_26_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0197 - val_loss: 0.0205\n",
      "Epoch 6/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0175\n",
      "Epoch 6: val_loss improved from 0.02054 to 0.01979, saving model to model\\SAE_bottleneck_26_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0189 - val_loss: 0.0198\n",
      "Epoch 7/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0164\n",
      "Epoch 7: val_loss improved from 0.01979 to 0.01930, saving model to model\\SAE_bottleneck_26_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0185 - val_loss: 0.0193\n",
      "Epoch 8/40\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0179\n",
      "Epoch 8: val_loss improved from 0.01930 to 0.01862, saving model to model\\SAE_bottleneck_26_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0179 - val_loss: 0.0186\n",
      "Epoch 9/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0187\n",
      "Epoch 9: val_loss improved from 0.01862 to 0.01804, saving model to model\\SAE_bottleneck_26_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0172 - val_loss: 0.0180\n",
      "Epoch 10/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0169\n",
      "Epoch 10: val_loss improved from 0.01804 to 0.01784, saving model to model\\SAE_bottleneck_26_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0168 - val_loss: 0.0178\n",
      "Epoch 11/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0153\n",
      "Epoch 11: val_loss improved from 0.01784 to 0.01762, saving model to model\\SAE_bottleneck_26_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0165 - val_loss: 0.0176\n",
      "Epoch 12/40\n",
      "20/26 [======================>.......] - ETA: 0s - loss: 0.0161\n",
      "Epoch 12: val_loss improved from 0.01762 to 0.01754, saving model to model\\SAE_bottleneck_26_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0163 - val_loss: 0.0175\n",
      "Epoch 13/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0140\n",
      "Epoch 13: val_loss improved from 0.01754 to 0.01744, saving model to model\\SAE_bottleneck_26_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0162 - val_loss: 0.0174\n",
      "Epoch 14/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0149\n",
      "Epoch 14: val_loss improved from 0.01744 to 0.01729, saving model to model\\SAE_bottleneck_26_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0161 - val_loss: 0.0173\n",
      "Epoch 15/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0157\n",
      "Epoch 15: val_loss did not improve from 0.01729\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0159 - val_loss: 0.0173\n",
      "Epoch 16/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0136\n",
      "Epoch 16: val_loss improved from 0.01729 to 0.01688, saving model to model\\SAE_bottleneck_26_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0157 - val_loss: 0.0169\n",
      "Epoch 17/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0151\n",
      "Epoch 17: val_loss did not improve from 0.01688\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0155 - val_loss: 0.0171\n",
      "Epoch 18/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0153\n",
      "Epoch 18: val_loss improved from 0.01688 to 0.01656, saving model to model\\SAE_bottleneck_26_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0152 - val_loss: 0.0166\n",
      "Epoch 19/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0155\n",
      "Epoch 19: val_loss improved from 0.01656 to 0.01648, saving model to model\\SAE_bottleneck_26_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0150 - val_loss: 0.0165\n",
      "Epoch 20/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0147\n",
      "Epoch 20: val_loss improved from 0.01648 to 0.01622, saving model to model\\SAE_bottleneck_26_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0148 - val_loss: 0.0162\n",
      "Epoch 21/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0174\n",
      "Epoch 21: val_loss improved from 0.01622 to 0.01619, saving model to model\\SAE_bottleneck_26_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0147 - val_loss: 0.0162\n",
      "Epoch 22/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0124\n",
      "Epoch 22: val_loss improved from 0.01619 to 0.01611, saving model to model\\SAE_bottleneck_26_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0145 - val_loss: 0.0161\n",
      "Epoch 23/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0162\n",
      "Epoch 23: val_loss improved from 0.01611 to 0.01600, saving model to model\\SAE_bottleneck_26_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0145 - val_loss: 0.0160\n",
      "Epoch 24/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0112\n",
      "Epoch 24: val_loss did not improve from 0.01600\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0143 - val_loss: 0.0160\n",
      "Epoch 25/40\n",
      "18/26 [===================>..........] - ETA: 0s - loss: 0.0140\n",
      "Epoch 25: val_loss improved from 0.01600 to 0.01570, saving model to model\\SAE_bottleneck_26_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0142 - val_loss: 0.0157\n",
      "Epoch 26/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0124\n",
      "Epoch 26: val_loss did not improve from 0.01570\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0140 - val_loss: 0.0157\n",
      "Epoch 27/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0112\n",
      "Epoch 27: val_loss improved from 0.01570 to 0.01560, saving model to model\\SAE_bottleneck_26_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0139 - val_loss: 0.0156\n",
      "Epoch 28/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0130\n",
      "Epoch 28: val_loss improved from 0.01560 to 0.01548, saving model to model\\SAE_bottleneck_26_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0137 - val_loss: 0.0155\n",
      "Epoch 29/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0181\n",
      "Epoch 29: val_loss improved from 0.01548 to 0.01530, saving model to model\\SAE_bottleneck_26_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0135 - val_loss: 0.0153\n",
      "Epoch 30/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0124\n",
      "Epoch 30: val_loss improved from 0.01530 to 0.01526, saving model to model\\SAE_bottleneck_26_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0133 - val_loss: 0.0153\n",
      "Epoch 31/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0138\n",
      "Epoch 31: val_loss improved from 0.01526 to 0.01525, saving model to model\\SAE_bottleneck_26_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0132 - val_loss: 0.0153\n",
      "Epoch 32/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0122\n",
      "Epoch 32: val_loss improved from 0.01525 to 0.01515, saving model to model\\SAE_bottleneck_26_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0130 - val_loss: 0.0151\n",
      "Epoch 33/40\n",
      "15/26 [================>.............] - ETA: 0s - loss: 0.0122\n",
      "Epoch 33: val_loss improved from 0.01515 to 0.01505, saving model to model\\SAE_bottleneck_26_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0129 - val_loss: 0.0151\n",
      "Epoch 34/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0130\n",
      "Epoch 34: val_loss did not improve from 0.01505\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0128 - val_loss: 0.0151\n",
      "Epoch 35/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0127\n",
      "Epoch 35: val_loss did not improve from 0.01505\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0127 - val_loss: 0.0152\n",
      "Epoch 36/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0139\n",
      "Epoch 36: val_loss improved from 0.01505 to 0.01505, saving model to model\\SAE_bottleneck_26_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0127 - val_loss: 0.0151\n",
      "Epoch 37/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0109\n",
      "Epoch 37: val_loss did not improve from 0.01505\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0126 - val_loss: 0.0151\n",
      "Epoch 38/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0153\n",
      "Epoch 38: val_loss improved from 0.01505 to 0.01498, saving model to model\\SAE_bottleneck_26_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0125 - val_loss: 0.0150\n",
      "Epoch 39/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0114\n",
      "Epoch 39: val_loss did not improve from 0.01498\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0125 - val_loss: 0.0150\n",
      "Epoch 40/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0105\n",
      "Epoch 40: val_loss did not improve from 0.01498\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0124 - val_loss: 0.0151\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "LogisticRegression - Mean CV Score: 0.6023076923076923\n",
      "LogisticRegression - Mean Confusion Matrix:\n",
      "[[7.8 4.8]\n",
      " [5.5 7.8]]\n",
      "SVM - Mean CV Score: 0.5601538461538461\n",
      "SVM - Mean Confusion Matrix:\n",
      "[[6.3 6.3]\n",
      " [5.1 8.2]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest - Mean CV Score: 0.6293846153846154\n",
      "RandomForest - Mean Confusion Matrix:\n",
      "[[7.6 5. ]\n",
      " [4.6 8.7]]\n",
      "KNN - Mean CV Score: 0.5750769230769229\n",
      "KNN - Mean Confusion Matrix:\n",
      "[[8.3 4.3]\n",
      " [6.7 6.6]]\n",
      "GradientBoosting - Mean CV Score: 0.5983076923076924\n",
      "GradientBoosting - Mean Confusion Matrix:\n",
      "[[7.8 4.8]\n",
      " [5.6 7.7]]\n",
      "AdaBoost - Mean CV Score: 0.5598461538461539\n",
      "AdaBoost - Mean Confusion Matrix:\n",
      "[[7.7 4.9]\n",
      " [6.5 6.8]]\n",
      "NaiveBayes - Mean CV Score: 0.556\n",
      "NaiveBayes - Mean Confusion Matrix:\n",
      "[[10.9  1.7]\n",
      " [ 9.8  3.5]]\n",
      "DecisionTree - Mean CV Score: 0.6060000000000001\n",
      "DecisionTree - Mean Confusion Matrix:\n",
      "[[7.8 4.8]\n",
      " [5.4 7.9]]\n",
      "ExtraTrees - Mean CV Score: 0.5866153846153846\n",
      "ExtraTrees - Mean Confusion Matrix:\n",
      "[[7.7 4.9]\n",
      " [5.8 7.5]]\n",
      "XGBoost - Mean CV Score: 0.5830769230769229\n",
      "XGBoost - Mean Confusion Matrix:\n",
      "[[7.2 5.4]\n",
      " [5.4 7.9]]\n",
      "Size: bottleneck_26, Best classifier: RandomForest, CV Score: 0.6293846153846154\n",
      "Epoch 1/40\n",
      " 1/26 [>.............................] - ETA: 24s - loss: 0.0450\n",
      "Epoch 1: val_loss improved from inf to 0.02661, saving model to model\\SAE_bottleneck_30_best_model.keras\n",
      "26/26 [==============================] - 1s 11ms/step - loss: 0.0355 - val_loss: 0.0266\n",
      "Epoch 2/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0258\n",
      "Epoch 2: val_loss improved from 0.02661 to 0.02391, saving model to model\\SAE_bottleneck_30_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0235 - val_loss: 0.0239\n",
      "Epoch 3/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0179\n",
      "Epoch 3: val_loss improved from 0.02391 to 0.02333, saving model to model\\SAE_bottleneck_30_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0226 - val_loss: 0.0233\n",
      "Epoch 4/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0204\n",
      "Epoch 4: val_loss improved from 0.02333 to 0.02194, saving model to model\\SAE_bottleneck_30_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0217 - val_loss: 0.0219\n",
      "Epoch 5/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0197\n",
      "Epoch 5: val_loss improved from 0.02194 to 0.02033, saving model to model\\SAE_bottleneck_30_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0200 - val_loss: 0.0203\n",
      "Epoch 6/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0174\n",
      "Epoch 6: val_loss improved from 0.02033 to 0.01966, saving model to model\\SAE_bottleneck_30_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0190 - val_loss: 0.0197\n",
      "Epoch 7/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0187\n",
      "Epoch 7: val_loss improved from 0.01966 to 0.01916, saving model to model\\SAE_bottleneck_30_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0186 - val_loss: 0.0192\n",
      "Epoch 8/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0184\n",
      "Epoch 8: val_loss improved from 0.01916 to 0.01862, saving model to model\\SAE_bottleneck_30_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0182 - val_loss: 0.0186\n",
      "Epoch 9/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0161\n",
      "Epoch 9: val_loss improved from 0.01862 to 0.01817, saving model to model\\SAE_bottleneck_30_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0175 - val_loss: 0.0182\n",
      "Epoch 10/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0165\n",
      "Epoch 10: val_loss improved from 0.01817 to 0.01781, saving model to model\\SAE_bottleneck_30_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0171 - val_loss: 0.0178\n",
      "Epoch 11/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0147\n",
      "Epoch 11: val_loss improved from 0.01781 to 0.01780, saving model to model\\SAE_bottleneck_30_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0168 - val_loss: 0.0178\n",
      "Epoch 12/40\n",
      "15/26 [================>.............] - ETA: 0s - loss: 0.0161\n",
      "Epoch 12: val_loss improved from 0.01780 to 0.01756, saving model to model\\SAE_bottleneck_30_best_model.keras\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0166 - val_loss: 0.0176\n",
      "Epoch 13/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0165\n",
      "Epoch 13: val_loss improved from 0.01756 to 0.01743, saving model to model\\SAE_bottleneck_30_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0164 - val_loss: 0.0174\n",
      "Epoch 14/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0157\n",
      "Epoch 14: val_loss improved from 0.01743 to 0.01734, saving model to model\\SAE_bottleneck_30_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0163 - val_loss: 0.0173\n",
      "Epoch 15/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0171\n",
      "Epoch 15: val_loss improved from 0.01734 to 0.01716, saving model to model\\SAE_bottleneck_30_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0162 - val_loss: 0.0172\n",
      "Epoch 16/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0137\n",
      "Epoch 16: val_loss improved from 0.01716 to 0.01713, saving model to model\\SAE_bottleneck_30_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0160 - val_loss: 0.0171\n",
      "Epoch 17/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0154\n",
      "Epoch 17: val_loss improved from 0.01713 to 0.01695, saving model to model\\SAE_bottleneck_30_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0159 - val_loss: 0.0169\n",
      "Epoch 18/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0159\n",
      "Epoch 18: val_loss improved from 0.01695 to 0.01678, saving model to model\\SAE_bottleneck_30_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0156 - val_loss: 0.0168\n",
      "Epoch 19/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0154\n",
      "Epoch 19: val_loss improved from 0.01678 to 0.01656, saving model to model\\SAE_bottleneck_30_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0153 - val_loss: 0.0166\n",
      "Epoch 20/40\n",
      "12/26 [============>.................] - ETA: 0s - loss: 0.0152\n",
      "Epoch 20: val_loss improved from 0.01656 to 0.01630, saving model to model\\SAE_bottleneck_30_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0150 - val_loss: 0.0163\n",
      "Epoch 21/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0155\n",
      "Epoch 21: val_loss improved from 0.01630 to 0.01609, saving model to model\\SAE_bottleneck_30_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0147 - val_loss: 0.0161\n",
      "Epoch 22/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0136\n",
      "Epoch 22: val_loss improved from 0.01609 to 0.01583, saving model to model\\SAE_bottleneck_30_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0144 - val_loss: 0.0158\n",
      "Epoch 23/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0115\n",
      "Epoch 23: val_loss improved from 0.01583 to 0.01559, saving model to model\\SAE_bottleneck_30_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0141 - val_loss: 0.0156\n",
      "Epoch 24/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0148\n",
      "Epoch 24: val_loss improved from 0.01559 to 0.01551, saving model to model\\SAE_bottleneck_30_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0139 - val_loss: 0.0155\n",
      "Epoch 25/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0137\n",
      "Epoch 25: val_loss improved from 0.01551 to 0.01544, saving model to model\\SAE_bottleneck_30_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0137 - val_loss: 0.0154\n",
      "Epoch 26/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0142\n",
      "Epoch 26: val_loss improved from 0.01544 to 0.01535, saving model to model\\SAE_bottleneck_30_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0136 - val_loss: 0.0153\n",
      "Epoch 27/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0122\n",
      "Epoch 27: val_loss improved from 0.01535 to 0.01533, saving model to model\\SAE_bottleneck_30_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0135 - val_loss: 0.0153\n",
      "Epoch 28/40\n",
      "14/26 [===============>..............] - ETA: 0s - loss: 0.0133\n",
      "Epoch 28: val_loss improved from 0.01533 to 0.01513, saving model to model\\SAE_bottleneck_30_best_model.keras\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0134 - val_loss: 0.0151\n",
      "Epoch 29/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0124\n",
      "Epoch 29: val_loss improved from 0.01513 to 0.01502, saving model to model\\SAE_bottleneck_30_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0133 - val_loss: 0.0150\n",
      "Epoch 30/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0116\n",
      "Epoch 30: val_loss did not improve from 0.01502\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0133 - val_loss: 0.0151\n",
      "Epoch 31/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0145\n",
      "Epoch 31: val_loss did not improve from 0.01502\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0132 - val_loss: 0.0151\n",
      "Epoch 32/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0110\n",
      "Epoch 32: val_loss improved from 0.01502 to 0.01499, saving model to model\\SAE_bottleneck_30_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0131 - val_loss: 0.0150\n",
      "Epoch 33/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0114\n",
      "Epoch 33: val_loss improved from 0.01499 to 0.01495, saving model to model\\SAE_bottleneck_30_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0130 - val_loss: 0.0149\n",
      "Epoch 34/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0153\n",
      "Epoch 34: val_loss improved from 0.01495 to 0.01493, saving model to model\\SAE_bottleneck_30_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0130 - val_loss: 0.0149\n",
      "Epoch 35/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0131\n",
      "Epoch 35: val_loss did not improve from 0.01493\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0129 - val_loss: 0.0150\n",
      "Epoch 36/40\n",
      "11/26 [===========>..................] - ETA: 0s - loss: 0.0128\n",
      "Epoch 36: val_loss improved from 0.01493 to 0.01492, saving model to model\\SAE_bottleneck_30_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0129 - val_loss: 0.0149\n",
      "Epoch 37/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0112\n",
      "Epoch 37: val_loss improved from 0.01492 to 0.01490, saving model to model\\SAE_bottleneck_30_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0128 - val_loss: 0.0149\n",
      "Epoch 38/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0110\n",
      "Epoch 38: val_loss improved from 0.01490 to 0.01488, saving model to model\\SAE_bottleneck_30_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0128 - val_loss: 0.0149\n",
      "Epoch 39/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0123\n",
      "Epoch 39: val_loss improved from 0.01488 to 0.01477, saving model to model\\SAE_bottleneck_30_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0127 - val_loss: 0.0148\n",
      "Epoch 40/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0135\n",
      "Epoch 40: val_loss improved from 0.01477 to 0.01476, saving model to model\\SAE_bottleneck_30_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0126 - val_loss: 0.0148\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "LogisticRegression - Mean CV Score: 0.5904615384615385\n",
      "LogisticRegression - Mean Confusion Matrix:\n",
      "[[7.4 5.2]\n",
      " [5.4 7.9]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM - Mean CV Score: 0.5984615384615385\n",
      "SVM - Mean Confusion Matrix:\n",
      "[[7.9 4.7]\n",
      " [5.7 7.6]]\n",
      "RandomForest - Mean CV Score: 0.6450769230769231\n",
      "RandomForest - Mean Confusion Matrix:\n",
      "[[7.5 5.1]\n",
      " [4.1 9.2]]\n",
      "KNN - Mean CV Score: 0.6101538461538462\n",
      "KNN - Mean Confusion Matrix:\n",
      "[[8.4 4.2]\n",
      " [5.9 7.4]]\n",
      "GradientBoosting - Mean CV Score: 0.6447692307692308\n",
      "GradientBoosting - Mean Confusion Matrix:\n",
      "[[7.9 4.7]\n",
      " [4.5 8.8]]\n",
      "AdaBoost - Mean CV Score: 0.6176923076923077\n",
      "AdaBoost - Mean Confusion Matrix:\n",
      "[[7.3 5.3]\n",
      " [4.6 8.7]]\n",
      "NaiveBayes - Mean CV Score: 0.5635384615384614\n",
      "NaiveBayes - Mean Confusion Matrix:\n",
      "[[9.6 3. ]\n",
      " [8.3 5. ]]\n",
      "DecisionTree - Mean CV Score: 0.5366153846153846\n",
      "DecisionTree - Mean Confusion Matrix:\n",
      "[[6.1 6.5]\n",
      " [5.5 7.8]]\n",
      "ExtraTrees - Mean CV Score: 0.6295384615384616\n",
      "ExtraTrees - Mean Confusion Matrix:\n",
      "[[7.7 4.9]\n",
      " [4.7 8.6]]\n",
      "XGBoost - Mean CV Score: 0.6255384615384615\n",
      "XGBoost - Mean Confusion Matrix:\n",
      "[[7.2 5.4]\n",
      " [4.3 9. ]]\n",
      "Size: bottleneck_30, Best classifier: RandomForest, CV Score: 0.6450769230769231\n",
      "Epoch 1/40\n",
      " 1/26 [>.............................] - ETA: 24s - loss: 0.0501\n",
      "Epoch 1: val_loss improved from inf to 0.02795, saving model to model\\SAE_bottleneck_34_best_model.keras\n",
      "26/26 [==============================] - 1s 10ms/step - loss: 0.0381 - val_loss: 0.0279\n",
      "Epoch 2/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0234\n",
      "Epoch 2: val_loss improved from 0.02795 to 0.02454, saving model to model\\SAE_bottleneck_34_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0241 - val_loss: 0.0245\n",
      "Epoch 3/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0223\n",
      "Epoch 3: val_loss improved from 0.02454 to 0.02397, saving model to model\\SAE_bottleneck_34_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0229 - val_loss: 0.0240\n",
      "Epoch 4/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0202\n",
      "Epoch 4: val_loss improved from 0.02397 to 0.02356, saving model to model\\SAE_bottleneck_34_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0225 - val_loss: 0.0236\n",
      "Epoch 5/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0240\n",
      "Epoch 5: val_loss improved from 0.02356 to 0.02258, saving model to model\\SAE_bottleneck_34_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0220 - val_loss: 0.0226\n",
      "Epoch 6/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0331\n",
      "Epoch 6: val_loss improved from 0.02258 to 0.02094, saving model to model\\SAE_bottleneck_34_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0207 - val_loss: 0.0209\n",
      "Epoch 7/40\n",
      "14/26 [===============>..............] - ETA: 0s - loss: 0.0187\n",
      "Epoch 7: val_loss improved from 0.02094 to 0.02011, saving model to model\\SAE_bottleneck_34_best_model.keras\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0193 - val_loss: 0.0201\n",
      "Epoch 8/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0177\n",
      "Epoch 8: val_loss improved from 0.02011 to 0.01981, saving model to model\\SAE_bottleneck_34_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0189 - val_loss: 0.0198\n",
      "Epoch 9/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0188\n",
      "Epoch 9: val_loss improved from 0.01981 to 0.01963, saving model to model\\SAE_bottleneck_34_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0187 - val_loss: 0.0196\n",
      "Epoch 10/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0172\n",
      "Epoch 10: val_loss improved from 0.01963 to 0.01943, saving model to model\\SAE_bottleneck_34_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0186 - val_loss: 0.0194\n",
      "Epoch 11/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0182\n",
      "Epoch 11: val_loss improved from 0.01943 to 0.01930, saving model to model\\SAE_bottleneck_34_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0185 - val_loss: 0.0193\n",
      "Epoch 12/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0162\n",
      "Epoch 12: val_loss improved from 0.01930 to 0.01910, saving model to model\\SAE_bottleneck_34_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0183 - val_loss: 0.0191\n",
      "Epoch 13/40\n",
      "14/26 [===============>..............] - ETA: 0s - loss: 0.0177\n",
      "Epoch 13: val_loss improved from 0.01910 to 0.01867, saving model to model\\SAE_bottleneck_34_best_model.keras\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0180 - val_loss: 0.0187\n",
      "Epoch 14/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0205\n",
      "Epoch 14: val_loss improved from 0.01867 to 0.01810, saving model to model\\SAE_bottleneck_34_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0174 - val_loss: 0.0181\n",
      "Epoch 15/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0220\n",
      "Epoch 15: val_loss improved from 0.01810 to 0.01778, saving model to model\\SAE_bottleneck_34_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0168 - val_loss: 0.0178\n",
      "Epoch 16/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0242\n",
      "Epoch 16: val_loss improved from 0.01778 to 0.01757, saving model to model\\SAE_bottleneck_34_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0165 - val_loss: 0.0176\n",
      "Epoch 17/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0163\n",
      "Epoch 17: val_loss improved from 0.01757 to 0.01755, saving model to model\\SAE_bottleneck_34_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0162 - val_loss: 0.0175\n",
      "Epoch 18/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0158\n",
      "Epoch 18: val_loss improved from 0.01755 to 0.01735, saving model to model\\SAE_bottleneck_34_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0161 - val_loss: 0.0174\n",
      "Epoch 19/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0141\n",
      "Epoch 19: val_loss improved from 0.01735 to 0.01713, saving model to model\\SAE_bottleneck_34_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0158 - val_loss: 0.0171\n",
      "Epoch 20/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0153\n",
      "Epoch 20: val_loss improved from 0.01713 to 0.01703, saving model to model\\SAE_bottleneck_34_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0156 - val_loss: 0.0170\n",
      "Epoch 21/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0150\n",
      "Epoch 21: val_loss improved from 0.01703 to 0.01685, saving model to model\\SAE_bottleneck_34_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0154 - val_loss: 0.0168\n",
      "Epoch 22/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0153\n",
      "Epoch 22: val_loss improved from 0.01685 to 0.01682, saving model to model\\SAE_bottleneck_34_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0152 - val_loss: 0.0168\n",
      "Epoch 23/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0152\n",
      "Epoch 23: val_loss improved from 0.01682 to 0.01669, saving model to model\\SAE_bottleneck_34_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0149 - val_loss: 0.0167\n",
      "Epoch 24/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0153\n",
      "Epoch 24: val_loss improved from 0.01669 to 0.01654, saving model to model\\SAE_bottleneck_34_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0147 - val_loss: 0.0165\n",
      "Epoch 25/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0161\n",
      "Epoch 25: val_loss improved from 0.01654 to 0.01647, saving model to model\\SAE_bottleneck_34_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0146 - val_loss: 0.0165\n",
      "Epoch 26/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0145\n",
      "Epoch 26: val_loss improved from 0.01647 to 0.01620, saving model to model\\SAE_bottleneck_34_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0143 - val_loss: 0.0162\n",
      "Epoch 27/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0160\n",
      "Epoch 27: val_loss improved from 0.01620 to 0.01619, saving model to model\\SAE_bottleneck_34_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0141 - val_loss: 0.0162\n",
      "Epoch 28/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0124\n",
      "Epoch 28: val_loss improved from 0.01619 to 0.01591, saving model to model\\SAE_bottleneck_34_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0139 - val_loss: 0.0159\n",
      "Epoch 29/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0127\n",
      "Epoch 29: val_loss improved from 0.01591 to 0.01583, saving model to model\\SAE_bottleneck_34_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0137 - val_loss: 0.0158\n",
      "Epoch 30/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0135\n",
      "Epoch 30: val_loss improved from 0.01583 to 0.01575, saving model to model\\SAE_bottleneck_34_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0135 - val_loss: 0.0157\n",
      "Epoch 31/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0168\n",
      "Epoch 31: val_loss improved from 0.01575 to 0.01552, saving model to model\\SAE_bottleneck_34_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0133 - val_loss: 0.0155\n",
      "Epoch 32/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0124\n",
      "Epoch 32: val_loss improved from 0.01552 to 0.01545, saving model to model\\SAE_bottleneck_34_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0132 - val_loss: 0.0155\n",
      "Epoch 33/40\n",
      "16/26 [=================>............] - ETA: 0s - loss: 0.0129\n",
      "Epoch 33: val_loss did not improve from 0.01545\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0131 - val_loss: 0.0156\n",
      "Epoch 34/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0139\n",
      "Epoch 34: val_loss improved from 0.01545 to 0.01535, saving model to model\\SAE_bottleneck_34_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0130 - val_loss: 0.0154\n",
      "Epoch 35/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0136\n",
      "Epoch 35: val_loss improved from 0.01535 to 0.01530, saving model to model\\SAE_bottleneck_34_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0128 - val_loss: 0.0153\n",
      "Epoch 36/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0120\n",
      "Epoch 36: val_loss improved from 0.01530 to 0.01526, saving model to model\\SAE_bottleneck_34_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0127 - val_loss: 0.0153\n",
      "Epoch 37/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0134\n",
      "Epoch 37: val_loss did not improve from 0.01526\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0127 - val_loss: 0.0153\n",
      "Epoch 38/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0159\n",
      "Epoch 38: val_loss improved from 0.01526 to 0.01522, saving model to model\\SAE_bottleneck_34_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0127 - val_loss: 0.0152\n",
      "Epoch 39/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0101\n",
      "Epoch 39: val_loss improved from 0.01522 to 0.01510, saving model to model\\SAE_bottleneck_34_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0125 - val_loss: 0.0151\n",
      "Epoch 40/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0104\n",
      "Epoch 40: val_loss did not improve from 0.01510\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0125 - val_loss: 0.0152\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "LogisticRegression - Mean CV Score: 0.556\n",
      "LogisticRegression - Mean Confusion Matrix:\n",
      "[[7.3 5.3]\n",
      " [6.2 7.1]]\n",
      "SVM - Mean CV Score: 0.5750769230769232\n",
      "SVM - Mean Confusion Matrix:\n",
      "[[6.8 5.8]\n",
      " [5.2 8.1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest - Mean CV Score: 0.5750769230769229\n",
      "RandomForest - Mean Confusion Matrix:\n",
      "[[7.1 5.5]\n",
      " [5.5 7.8]]\n",
      "KNN - Mean CV Score: 0.591076923076923\n",
      "KNN - Mean Confusion Matrix:\n",
      "[[8.4 4.2]\n",
      " [6.4 6.9]]\n",
      "GradientBoosting - Mean CV Score: 0.552153846153846\n",
      "GradientBoosting - Mean Confusion Matrix:\n",
      "[[6.7 5.9]\n",
      " [5.7 7.6]]\n",
      "AdaBoost - Mean CV Score: 0.514\n",
      "AdaBoost - Mean Confusion Matrix:\n",
      "[[6.3 6.3]\n",
      " [6.3 7. ]]\n",
      "NaiveBayes - Mean CV Score: 0.5792307692307692\n",
      "NaiveBayes - Mean Confusion Matrix:\n",
      "[[8.7 3.9]\n",
      " [7.  6.3]]\n",
      "DecisionTree - Mean CV Score: 0.548\n",
      "DecisionTree - Mean Confusion Matrix:\n",
      "[[6.5 6.1]\n",
      " [5.6 7.7]]\n",
      "ExtraTrees - Mean CV Score: 0.5827692307692306\n",
      "ExtraTrees - Mean Confusion Matrix:\n",
      "[[7.5 5.1]\n",
      " [5.7 7.6]]\n",
      "XGBoost - Mean CV Score: 0.5404615384615384\n",
      "XGBoost - Mean Confusion Matrix:\n",
      "[[6.5 6.1]\n",
      " [5.8 7.5]]\n",
      "Size: bottleneck_34, Best classifier: KNN, CV Score: 0.591076923076923\n",
      "Epoch 1/40\n",
      " 1/26 [>.............................] - ETA: 24s - loss: 0.0507\n",
      "Epoch 1: val_loss improved from inf to 0.02675, saving model to model\\SAE_bottleneck_38_best_model.keras\n",
      "26/26 [==============================] - 1s 11ms/step - loss: 0.0362 - val_loss: 0.0268\n",
      "Epoch 2/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0279\n",
      "Epoch 2: val_loss improved from 0.02675 to 0.02377, saving model to model\\SAE_bottleneck_38_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0234 - val_loss: 0.0238\n",
      "Epoch 3/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0194\n",
      "Epoch 3: val_loss improved from 0.02377 to 0.02183, saving model to model\\SAE_bottleneck_38_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0216 - val_loss: 0.0218\n",
      "Epoch 4/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0234\n",
      "Epoch 4: val_loss improved from 0.02183 to 0.02039, saving model to model\\SAE_bottleneck_38_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0201 - val_loss: 0.0204\n",
      "Epoch 5/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0136\n",
      "Epoch 5: val_loss improved from 0.02039 to 0.01978, saving model to model\\SAE_bottleneck_38_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0191 - val_loss: 0.0198\n",
      "Epoch 6/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0167\n",
      "Epoch 6: val_loss improved from 0.01978 to 0.01953, saving model to model\\SAE_bottleneck_38_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0188 - val_loss: 0.0195\n",
      "Epoch 7/40\n",
      "17/26 [==================>...........] - ETA: 0s - loss: 0.0185\n",
      "Epoch 7: val_loss improved from 0.01953 to 0.01922, saving model to model\\SAE_bottleneck_38_best_model.keras\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0185 - val_loss: 0.0192\n",
      "Epoch 8/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0149\n",
      "Epoch 8: val_loss improved from 0.01922 to 0.01885, saving model to model\\SAE_bottleneck_38_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0181 - val_loss: 0.0188\n",
      "Epoch 9/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0176\n",
      "Epoch 9: val_loss improved from 0.01885 to 0.01824, saving model to model\\SAE_bottleneck_38_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0176 - val_loss: 0.0182\n",
      "Epoch 10/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0156\n",
      "Epoch 10: val_loss improved from 0.01824 to 0.01799, saving model to model\\SAE_bottleneck_38_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0170 - val_loss: 0.0180\n",
      "Epoch 11/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0152\n",
      "Epoch 11: val_loss improved from 0.01799 to 0.01787, saving model to model\\SAE_bottleneck_38_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0167 - val_loss: 0.0179\n",
      "Epoch 12/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0178\n",
      "Epoch 12: val_loss improved from 0.01787 to 0.01769, saving model to model\\SAE_bottleneck_38_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0166 - val_loss: 0.0177\n",
      "Epoch 13/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0176\n",
      "Epoch 13: val_loss improved from 0.01769 to 0.01746, saving model to model\\SAE_bottleneck_38_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0163 - val_loss: 0.0175\n",
      "Epoch 14/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0154\n",
      "Epoch 14: val_loss did not improve from 0.01746\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0162 - val_loss: 0.0175\n",
      "Epoch 15/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0140\n",
      "Epoch 15: val_loss improved from 0.01746 to 0.01722, saving model to model\\SAE_bottleneck_38_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0160 - val_loss: 0.0172\n",
      "Epoch 16/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0143\n",
      "Epoch 16: val_loss improved from 0.01722 to 0.01705, saving model to model\\SAE_bottleneck_38_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0159 - val_loss: 0.0170\n",
      "Epoch 17/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0159\n",
      "Epoch 17: val_loss improved from 0.01705 to 0.01691, saving model to model\\SAE_bottleneck_38_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0156 - val_loss: 0.0169\n",
      "Epoch 18/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0145\n",
      "Epoch 18: val_loss improved from 0.01691 to 0.01677, saving model to model\\SAE_bottleneck_38_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0154 - val_loss: 0.0168\n",
      "Epoch 19/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0172\n",
      "Epoch 19: val_loss improved from 0.01677 to 0.01676, saving model to model\\SAE_bottleneck_38_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0152 - val_loss: 0.0168\n",
      "Epoch 20/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0160\n",
      "Epoch 20: val_loss improved from 0.01676 to 0.01649, saving model to model\\SAE_bottleneck_38_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0150 - val_loss: 0.0165\n",
      "Epoch 21/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0136\n",
      "Epoch 21: val_loss improved from 0.01649 to 0.01636, saving model to model\\SAE_bottleneck_38_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0148 - val_loss: 0.0164\n",
      "Epoch 22/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0127\n",
      "Epoch 22: val_loss did not improve from 0.01636\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0146 - val_loss: 0.0164\n",
      "Epoch 23/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0144\n",
      "Epoch 23: val_loss improved from 0.01636 to 0.01625, saving model to model\\SAE_bottleneck_38_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0145 - val_loss: 0.0163\n",
      "Epoch 24/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0151\n",
      "Epoch 24: val_loss improved from 0.01625 to 0.01617, saving model to model\\SAE_bottleneck_38_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0144 - val_loss: 0.0162\n",
      "Epoch 25/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0125\n",
      "Epoch 25: val_loss improved from 0.01617 to 0.01593, saving model to model\\SAE_bottleneck_38_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0142 - val_loss: 0.0159\n",
      "Epoch 26/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0136\n",
      "Epoch 26: val_loss improved from 0.01593 to 0.01589, saving model to model\\SAE_bottleneck_38_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0141 - val_loss: 0.0159\n",
      "Epoch 27/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0141\n",
      "Epoch 27: val_loss improved from 0.01589 to 0.01573, saving model to model\\SAE_bottleneck_38_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0139 - val_loss: 0.0157\n",
      "Epoch 28/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0125\n",
      "Epoch 28: val_loss improved from 0.01573 to 0.01553, saving model to model\\SAE_bottleneck_38_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0137 - val_loss: 0.0155\n",
      "Epoch 29/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0117\n",
      "Epoch 29: val_loss did not improve from 0.01553\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0136 - val_loss: 0.0156\n",
      "Epoch 30/40\n",
      "15/26 [================>.............] - ETA: 0s - loss: 0.0136\n",
      "Epoch 30: val_loss improved from 0.01553 to 0.01548, saving model to model\\SAE_bottleneck_38_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0135 - val_loss: 0.0155\n",
      "Epoch 31/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0144\n",
      "Epoch 31: val_loss improved from 0.01548 to 0.01536, saving model to model\\SAE_bottleneck_38_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0133 - val_loss: 0.0154\n",
      "Epoch 32/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0131\n",
      "Epoch 32: val_loss improved from 0.01536 to 0.01520, saving model to model\\SAE_bottleneck_38_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0132 - val_loss: 0.0152\n",
      "Epoch 33/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0126\n",
      "Epoch 33: val_loss improved from 0.01520 to 0.01509, saving model to model\\SAE_bottleneck_38_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0130 - val_loss: 0.0151\n",
      "Epoch 34/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0131\n",
      "Epoch 34: val_loss improved from 0.01509 to 0.01504, saving model to model\\SAE_bottleneck_38_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0128 - val_loss: 0.0150\n",
      "Epoch 35/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0120\n",
      "Epoch 35: val_loss improved from 0.01504 to 0.01478, saving model to model\\SAE_bottleneck_38_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0126 - val_loss: 0.0148\n",
      "Epoch 36/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0094\n",
      "Epoch 36: val_loss did not improve from 0.01478\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0124 - val_loss: 0.0149\n",
      "Epoch 37/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0125\n",
      "Epoch 37: val_loss did not improve from 0.01478\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0123 - val_loss: 0.0148\n",
      "Epoch 38/40\n",
      "14/26 [===============>..............] - ETA: 0s - loss: 0.0123\n",
      "Epoch 38: val_loss improved from 0.01478 to 0.01461, saving model to model\\SAE_bottleneck_38_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0122 - val_loss: 0.0146\n",
      "Epoch 39/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0110\n",
      "Epoch 39: val_loss improved from 0.01461 to 0.01452, saving model to model\\SAE_bottleneck_38_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0121 - val_loss: 0.0145\n",
      "Epoch 40/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0111\n",
      "Epoch 40: val_loss did not improve from 0.01452\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0120 - val_loss: 0.0147\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "LogisticRegression - Mean CV Score: 0.5747692307692309\n",
      "LogisticRegression - Mean Confusion Matrix:\n",
      "[[7.2 5.4]\n",
      " [5.6 7.7]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM - Mean CV Score: 0.556\n",
      "SVM - Mean Confusion Matrix:\n",
      "[[7.  5.6]\n",
      " [5.9 7.4]]\n",
      "RandomForest - Mean CV Score: 0.6406153846153846\n",
      "RandomForest - Mean Confusion Matrix:\n",
      "[[7.7 4.9]\n",
      " [4.4 8.9]]\n",
      "KNN - Mean CV Score: 0.5984615384615383\n",
      "KNN - Mean Confusion Matrix:\n",
      "[[7.8 4.8]\n",
      " [5.6 7.7]]\n",
      "GradientBoosting - Mean CV Score: 0.5673846153846153\n",
      "GradientBoosting - Mean Confusion Matrix:\n",
      "[[6.5 6.1]\n",
      " [5.1 8.2]]\n",
      "AdaBoost - Mean CV Score: 0.5713846153846154\n",
      "AdaBoost - Mean Confusion Matrix:\n",
      "[[6.6 6. ]\n",
      " [5.1 8.2]]\n",
      "NaiveBayes - Mean CV Score: 0.5595384615384615\n",
      "NaiveBayes - Mean Confusion Matrix:\n",
      "[[9.7 2.9]\n",
      " [8.5 4.8]]\n",
      "DecisionTree - Mean CV Score: 0.5095384615384615\n",
      "DecisionTree - Mean Confusion Matrix:\n",
      "[[6.2 6.4]\n",
      " [6.3 7. ]]\n",
      "ExtraTrees - Mean CV Score: 0.6290769230769231\n",
      "ExtraTrees - Mean Confusion Matrix:\n",
      "[[7.9 4.7]\n",
      " [4.9 8.4]]\n",
      "XGBoost - Mean CV Score: 0.6290769230769231\n",
      "XGBoost - Mean Confusion Matrix:\n",
      "[[7.6 5. ]\n",
      " [4.6 8.7]]\n",
      "Size: bottleneck_38, Best classifier: RandomForest, CV Score: 0.6406153846153846\n",
      "Epoch 1/40\n",
      " 1/26 [>.............................] - ETA: 23s - loss: 0.0466\n",
      "Epoch 1: val_loss improved from inf to 0.02696, saving model to model\\SAE_bottleneck_42_best_model.keras\n",
      "26/26 [==============================] - 1s 11ms/step - loss: 0.0373 - val_loss: 0.0270\n",
      "Epoch 2/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0239\n",
      "Epoch 2: val_loss improved from 0.02696 to 0.02426, saving model to model\\SAE_bottleneck_42_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0238 - val_loss: 0.0243\n",
      "Epoch 3/40\n",
      "21/26 [=======================>......] - ETA: 0s - loss: 0.0232\n",
      "Epoch 3: val_loss improved from 0.02426 to 0.02335, saving model to model\\SAE_bottleneck_42_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0226 - val_loss: 0.0233\n",
      "Epoch 4/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0299\n",
      "Epoch 4: val_loss improved from 0.02335 to 0.02154, saving model to model\\SAE_bottleneck_42_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0216 - val_loss: 0.0215\n",
      "Epoch 5/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0182\n",
      "Epoch 5: val_loss improved from 0.02154 to 0.01994, saving model to model\\SAE_bottleneck_42_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0198 - val_loss: 0.0199\n",
      "Epoch 6/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0220\n",
      "Epoch 6: val_loss improved from 0.01994 to 0.01930, saving model to model\\SAE_bottleneck_42_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0188 - val_loss: 0.0193\n",
      "Epoch 7/40\n",
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0185\n",
      "Epoch 7: val_loss improved from 0.01930 to 0.01899, saving model to model\\SAE_bottleneck_42_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0185 - val_loss: 0.0190\n",
      "Epoch 8/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0190\n",
      "Epoch 8: val_loss improved from 0.01899 to 0.01854, saving model to model\\SAE_bottleneck_42_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0181 - val_loss: 0.0185\n",
      "Epoch 9/40\n",
      "15/26 [================>.............] - ETA: 0s - loss: 0.0175\n",
      "Epoch 9: val_loss improved from 0.01854 to 0.01820, saving model to model\\SAE_bottleneck_42_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0175 - val_loss: 0.0182\n",
      "Epoch 10/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0147\n",
      "Epoch 10: val_loss improved from 0.01820 to 0.01790, saving model to model\\SAE_bottleneck_42_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0170 - val_loss: 0.0179\n",
      "Epoch 11/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0146\n",
      "Epoch 11: val_loss improved from 0.01790 to 0.01761, saving model to model\\SAE_bottleneck_42_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0166 - val_loss: 0.0176\n",
      "Epoch 12/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0158\n",
      "Epoch 12: val_loss improved from 0.01761 to 0.01758, saving model to model\\SAE_bottleneck_42_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0163 - val_loss: 0.0176\n",
      "Epoch 13/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0142\n",
      "Epoch 13: val_loss improved from 0.01758 to 0.01737, saving model to model\\SAE_bottleneck_42_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0162 - val_loss: 0.0174\n",
      "Epoch 14/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0165\n",
      "Epoch 14: val_loss improved from 0.01737 to 0.01710, saving model to model\\SAE_bottleneck_42_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0159 - val_loss: 0.0171\n",
      "Epoch 15/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0196\n",
      "Epoch 15: val_loss improved from 0.01710 to 0.01682, saving model to model\\SAE_bottleneck_42_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0155 - val_loss: 0.0168\n",
      "Epoch 16/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0139\n",
      "Epoch 16: val_loss improved from 0.01682 to 0.01660, saving model to model\\SAE_bottleneck_42_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0152 - val_loss: 0.0166\n",
      "Epoch 17/40\n",
      "13/26 [==============>...............] - ETA: 0s - loss: 0.0148\n",
      "Epoch 17: val_loss improved from 0.01660 to 0.01626, saving model to model\\SAE_bottleneck_42_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0148 - val_loss: 0.0163\n",
      "Epoch 18/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0138\n",
      "Epoch 18: val_loss improved from 0.01626 to 0.01608, saving model to model\\SAE_bottleneck_42_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0144 - val_loss: 0.0161\n",
      "Epoch 19/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0144\n",
      "Epoch 19: val_loss improved from 0.01608 to 0.01592, saving model to model\\SAE_bottleneck_42_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0141 - val_loss: 0.0159\n",
      "Epoch 20/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0147\n",
      "Epoch 20: val_loss did not improve from 0.01592\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0140 - val_loss: 0.0160\n",
      "Epoch 21/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0165\n",
      "Epoch 21: val_loss improved from 0.01592 to 0.01592, saving model to model\\SAE_bottleneck_42_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0139 - val_loss: 0.0159\n",
      "Epoch 22/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0176\n",
      "Epoch 22: val_loss improved from 0.01592 to 0.01576, saving model to model\\SAE_bottleneck_42_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0138 - val_loss: 0.0158\n",
      "Epoch 23/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0119\n",
      "Epoch 23: val_loss improved from 0.01576 to 0.01570, saving model to model\\SAE_bottleneck_42_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0136 - val_loss: 0.0157\n",
      "Epoch 24/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0118\n",
      "Epoch 24: val_loss improved from 0.01570 to 0.01570, saving model to model\\SAE_bottleneck_42_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0135 - val_loss: 0.0157\n",
      "Epoch 25/40\n",
      "13/26 [==============>...............] - ETA: 0s - loss: 0.0135\n",
      "Epoch 25: val_loss did not improve from 0.01570\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0134 - val_loss: 0.0157\n",
      "Epoch 26/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0121\n",
      "Epoch 26: val_loss improved from 0.01570 to 0.01568, saving model to model\\SAE_bottleneck_42_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0134 - val_loss: 0.0157\n",
      "Epoch 27/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0158\n",
      "Epoch 27: val_loss improved from 0.01568 to 0.01563, saving model to model\\SAE_bottleneck_42_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0133 - val_loss: 0.0156\n",
      "Epoch 28/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0141\n",
      "Epoch 28: val_loss improved from 0.01563 to 0.01559, saving model to model\\SAE_bottleneck_42_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0132 - val_loss: 0.0156\n",
      "Epoch 29/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0122\n",
      "Epoch 29: val_loss improved from 0.01559 to 0.01553, saving model to model\\SAE_bottleneck_42_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0132 - val_loss: 0.0155\n",
      "Epoch 30/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0125\n",
      "Epoch 30: val_loss did not improve from 0.01553\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0131 - val_loss: 0.0156\n",
      "Epoch 31/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0122\n",
      "Epoch 31: val_loss improved from 0.01553 to 0.01549, saving model to model\\SAE_bottleneck_42_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0130 - val_loss: 0.0155\n",
      "Epoch 32/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0137\n",
      "Epoch 32: val_loss improved from 0.01549 to 0.01545, saving model to model\\SAE_bottleneck_42_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0129 - val_loss: 0.0155\n",
      "Epoch 33/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0118\n",
      "Epoch 33: val_loss improved from 0.01545 to 0.01534, saving model to model\\SAE_bottleneck_42_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0128 - val_loss: 0.0153\n",
      "Epoch 34/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0164\n",
      "Epoch 34: val_loss did not improve from 0.01534\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0128 - val_loss: 0.0154\n",
      "Epoch 35/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0125\n",
      "Epoch 35: val_loss did not improve from 0.01534\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0127 - val_loss: 0.0154\n",
      "Epoch 36/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0119\n",
      "Epoch 36: val_loss improved from 0.01534 to 0.01534, saving model to model\\SAE_bottleneck_42_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0126 - val_loss: 0.0153\n",
      "Epoch 37/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0170\n",
      "Epoch 37: val_loss did not improve from 0.01534\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0126 - val_loss: 0.0154\n",
      "Epoch 38/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0123\n",
      "Epoch 38: val_loss improved from 0.01534 to 0.01521, saving model to model\\SAE_bottleneck_42_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0125 - val_loss: 0.0152\n",
      "Epoch 39/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0114\n",
      "Epoch 39: val_loss improved from 0.01521 to 0.01518, saving model to model\\SAE_bottleneck_42_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0124 - val_loss: 0.0152\n",
      "Epoch 40/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0123\n",
      "Epoch 40: val_loss improved from 0.01518 to 0.01515, saving model to model\\SAE_bottleneck_42_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0123 - val_loss: 0.0152\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "LogisticRegression - Mean CV Score: 0.5826153846153848\n",
      "LogisticRegression - Mean Confusion Matrix:\n",
      "[[7.1 5.5]\n",
      " [5.3 8. ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM - Mean CV Score: 0.5830769230769229\n",
      "SVM - Mean Confusion Matrix:\n",
      "[[7.  5.6]\n",
      " [5.2 8.1]]\n",
      "RandomForest - Mean CV Score: 0.5947692307692307\n",
      "RandomForest - Mean Confusion Matrix:\n",
      "[[6.8 5.8]\n",
      " [4.7 8.6]]\n",
      "KNN - Mean CV Score: 0.5601538461538461\n",
      "KNN - Mean Confusion Matrix:\n",
      "[[7.9 4.7]\n",
      " [6.7 6.6]]\n",
      "GradientBoosting - Mean CV Score: 0.6295384615384616\n",
      "GradientBoosting - Mean Confusion Matrix:\n",
      "[[7.5 5.1]\n",
      " [4.5 8.8]]\n",
      "AdaBoost - Mean CV Score: 0.5832307692307692\n",
      "AdaBoost - Mean Confusion Matrix:\n",
      "[[7.3 5.3]\n",
      " [5.5 7.8]]\n",
      "NaiveBayes - Mean CV Score: 0.5755384615384616\n",
      "NaiveBayes - Mean Confusion Matrix:\n",
      "[[8.2 4.4]\n",
      " [6.6 6.7]]\n",
      "DecisionTree - Mean CV Score: 0.5253846153846153\n",
      "DecisionTree - Mean Confusion Matrix:\n",
      "[[6.3 6.3]\n",
      " [6.  7.3]]\n",
      "ExtraTrees - Mean CV Score: 0.5866153846153844\n",
      "ExtraTrees - Mean Confusion Matrix:\n",
      "[[7.3 5.3]\n",
      " [5.4 7.9]]\n",
      "XGBoost - Mean CV Score: 0.5793846153846153\n",
      "XGBoost - Mean Confusion Matrix:\n",
      "[[7.1 5.5]\n",
      " [5.4 7.9]]\n",
      "Size: bottleneck_42, Best classifier: GradientBoosting, CV Score: 0.6295384615384616\n",
      "Epoch 1/40\n",
      " 1/26 [>.............................] - ETA: 24s - loss: 0.0437\n",
      "Epoch 1: val_loss improved from inf to 0.02711, saving model to model\\SAE_bottleneck_46_best_model.keras\n",
      "26/26 [==============================] - 1s 11ms/step - loss: 0.0370 - val_loss: 0.0271\n",
      "Epoch 2/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0208\n",
      "Epoch 2: val_loss improved from 0.02711 to 0.02440, saving model to model\\SAE_bottleneck_46_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0238 - val_loss: 0.0244\n",
      "Epoch 3/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0211\n",
      "Epoch 3: val_loss improved from 0.02440 to 0.02371, saving model to model\\SAE_bottleneck_46_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0227 - val_loss: 0.0237\n",
      "Epoch 4/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0239\n",
      "Epoch 4: val_loss improved from 0.02371 to 0.02311, saving model to model\\SAE_bottleneck_46_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0224 - val_loss: 0.0231\n",
      "Epoch 5/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0206\n",
      "Epoch 5: val_loss improved from 0.02311 to 0.02115, saving model to model\\SAE_bottleneck_46_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0213 - val_loss: 0.0212\n",
      "Epoch 6/40\n",
      "12/26 [============>.................] - ETA: 0s - loss: 0.0204\n",
      "Epoch 6: val_loss improved from 0.02115 to 0.02009, saving model to model\\SAE_bottleneck_46_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0196 - val_loss: 0.0201\n",
      "Epoch 7/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0171\n",
      "Epoch 7: val_loss improved from 0.02009 to 0.01963, saving model to model\\SAE_bottleneck_46_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0190 - val_loss: 0.0196\n",
      "Epoch 8/40\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0188\n",
      "Epoch 8: val_loss improved from 0.01963 to 0.01954, saving model to model\\SAE_bottleneck_46_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0188 - val_loss: 0.0195\n",
      "Epoch 9/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0175\n",
      "Epoch 9: val_loss improved from 0.01954 to 0.01937, saving model to model\\SAE_bottleneck_46_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0187 - val_loss: 0.0194\n",
      "Epoch 10/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0150\n",
      "Epoch 10: val_loss improved from 0.01937 to 0.01921, saving model to model\\SAE_bottleneck_46_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0185 - val_loss: 0.0192\n",
      "Epoch 11/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0155\n",
      "Epoch 11: val_loss improved from 0.01921 to 0.01902, saving model to model\\SAE_bottleneck_46_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0184 - val_loss: 0.0190\n",
      "Epoch 12/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0200\n",
      "Epoch 12: val_loss improved from 0.01902 to 0.01866, saving model to model\\SAE_bottleneck_46_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0180 - val_loss: 0.0187\n",
      "Epoch 13/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0159\n",
      "Epoch 13: val_loss improved from 0.01866 to 0.01815, saving model to model\\SAE_bottleneck_46_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0174 - val_loss: 0.0182\n",
      "Epoch 14/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0163\n",
      "Epoch 14: val_loss improved from 0.01815 to 0.01786, saving model to model\\SAE_bottleneck_46_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0168 - val_loss: 0.0179\n",
      "Epoch 15/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0140\n",
      "Epoch 15: val_loss improved from 0.01786 to 0.01765, saving model to model\\SAE_bottleneck_46_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0165 - val_loss: 0.0177\n",
      "Epoch 16/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0158\n",
      "Epoch 16: val_loss improved from 0.01765 to 0.01743, saving model to model\\SAE_bottleneck_46_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0163 - val_loss: 0.0174\n",
      "Epoch 17/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0147\n",
      "Epoch 17: val_loss improved from 0.01743 to 0.01724, saving model to model\\SAE_bottleneck_46_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0161 - val_loss: 0.0172\n",
      "Epoch 18/40\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0157\n",
      "Epoch 18: val_loss improved from 0.01724 to 0.01701, saving model to model\\SAE_bottleneck_46_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0157 - val_loss: 0.0170\n",
      "Epoch 19/40\n",
      "14/26 [===============>..............] - ETA: 0s - loss: 0.0152\n",
      "Epoch 19: val_loss improved from 0.01701 to 0.01672, saving model to model\\SAE_bottleneck_46_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0153 - val_loss: 0.0167\n",
      "Epoch 20/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0174\n",
      "Epoch 20: val_loss improved from 0.01672 to 0.01657, saving model to model\\SAE_bottleneck_46_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0150 - val_loss: 0.0166\n",
      "Epoch 21/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0141\n",
      "Epoch 21: val_loss improved from 0.01657 to 0.01647, saving model to model\\SAE_bottleneck_46_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0147 - val_loss: 0.0165\n",
      "Epoch 22/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0130\n",
      "Epoch 22: val_loss improved from 0.01647 to 0.01614, saving model to model\\SAE_bottleneck_46_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0146 - val_loss: 0.0161\n",
      "Epoch 23/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0127\n",
      "Epoch 23: val_loss improved from 0.01614 to 0.01591, saving model to model\\SAE_bottleneck_46_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0143 - val_loss: 0.0159\n",
      "Epoch 24/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0141\n",
      "Epoch 24: val_loss did not improve from 0.01591\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0141 - val_loss: 0.0159\n",
      "Epoch 25/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0141\n",
      "Epoch 25: val_loss improved from 0.01591 to 0.01583, saving model to model\\SAE_bottleneck_46_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0140 - val_loss: 0.0158\n",
      "Epoch 26/40\n",
      "13/26 [==============>...............] - ETA: 0s - loss: 0.0132\n",
      "Epoch 26: val_loss improved from 0.01583 to 0.01570, saving model to model\\SAE_bottleneck_46_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0138 - val_loss: 0.0157\n",
      "Epoch 27/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0137\n",
      "Epoch 27: val_loss improved from 0.01570 to 0.01555, saving model to model\\SAE_bottleneck_46_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0136 - val_loss: 0.0155\n",
      "Epoch 28/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0141\n",
      "Epoch 28: val_loss did not improve from 0.01555\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0134 - val_loss: 0.0156\n",
      "Epoch 29/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0101\n",
      "Epoch 29: val_loss improved from 0.01555 to 0.01543, saving model to model\\SAE_bottleneck_46_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0133 - val_loss: 0.0154\n",
      "Epoch 30/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0114\n",
      "Epoch 30: val_loss improved from 0.01543 to 0.01537, saving model to model\\SAE_bottleneck_46_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0131 - val_loss: 0.0154\n",
      "Epoch 31/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0117\n",
      "Epoch 31: val_loss improved from 0.01537 to 0.01531, saving model to model\\SAE_bottleneck_46_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0130 - val_loss: 0.0153\n",
      "Epoch 32/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0134\n",
      "Epoch 32: val_loss improved from 0.01531 to 0.01527, saving model to model\\SAE_bottleneck_46_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0129 - val_loss: 0.0153\n",
      "Epoch 33/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0107\n",
      "Epoch 33: val_loss improved from 0.01527 to 0.01524, saving model to model\\SAE_bottleneck_46_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0128 - val_loss: 0.0152\n",
      "Epoch 34/40\n",
      "12/26 [============>.................] - ETA: 0s - loss: 0.0124\n",
      "Epoch 34: val_loss improved from 0.01524 to 0.01518, saving model to model\\SAE_bottleneck_46_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0126 - val_loss: 0.0152\n",
      "Epoch 35/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0121\n",
      "Epoch 35: val_loss did not improve from 0.01518\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0125 - val_loss: 0.0152\n",
      "Epoch 36/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0134\n",
      "Epoch 36: val_loss improved from 0.01518 to 0.01509, saving model to model\\SAE_bottleneck_46_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0124 - val_loss: 0.0151\n",
      "Epoch 37/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0105\n",
      "Epoch 37: val_loss improved from 0.01509 to 0.01507, saving model to model\\SAE_bottleneck_46_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0124 - val_loss: 0.0151\n",
      "Epoch 38/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0106\n",
      "Epoch 38: val_loss did not improve from 0.01507\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0123 - val_loss: 0.0151\n",
      "Epoch 39/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0142\n",
      "Epoch 39: val_loss did not improve from 0.01507\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0123 - val_loss: 0.0152\n",
      "Epoch 40/40\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.0126\n",
      "Epoch 40: val_loss improved from 0.01507 to 0.01507, saving model to model\\SAE_bottleneck_46_best_model.keras\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0122 - val_loss: 0.0151\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "LogisticRegression - Mean CV Score: 0.5944615384615386\n",
      "LogisticRegression - Mean Confusion Matrix:\n",
      "[[7.1 5.5]\n",
      " [5.  8.3]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM - Mean CV Score: 0.6023076923076922\n",
      "SVM - Mean Confusion Matrix:\n",
      "[[7.  5.6]\n",
      " [4.7 8.6]]\n",
      "RandomForest - Mean CV Score: 0.6332307692307693\n",
      "RandomForest - Mean Confusion Matrix:\n",
      "[[7.8 4.8]\n",
      " [4.7 8.6]]\n",
      "KNN - Mean CV Score: 0.6104615384615384\n",
      "KNN - Mean Confusion Matrix:\n",
      "[[8.7 3.9]\n",
      " [6.2 7.1]]\n",
      "GradientBoosting - Mean CV Score: 0.6063076923076923\n",
      "GradientBoosting - Mean Confusion Matrix:\n",
      "[[7.7 4.9]\n",
      " [5.3 8. ]]\n",
      "AdaBoost - Mean CV Score: 0.5716923076923076\n",
      "AdaBoost - Mean Confusion Matrix:\n",
      "[[7.6 5. ]\n",
      " [6.1 7.2]]\n",
      "NaiveBayes - Mean CV Score: 0.5247692307692308\n",
      "NaiveBayes - Mean Confusion Matrix:\n",
      "[[11.2  1.4]\n",
      " [10.9  2.4]]\n",
      "DecisionTree - Mean CV Score: 0.548\n",
      "DecisionTree - Mean Confusion Matrix:\n",
      "[[6.3 6.3]\n",
      " [5.4 7.9]]\n",
      "ExtraTrees - Mean CV Score: 0.6255384615384615\n",
      "ExtraTrees - Mean Confusion Matrix:\n",
      "[[8.  4.6]\n",
      " [5.1 8.2]]\n",
      "XGBoost - Mean CV Score: 0.586923076923077\n",
      "XGBoost - Mean Confusion Matrix:\n",
      "[[7.5 5.1]\n",
      " [5.6 7.7]]\n",
      "Size: bottleneck_46, Best classifier: RandomForest, CV Score: 0.6332307692307693\n"
     ]
    }
   ],
   "source": [
    "SAEresults = dispatcher(SAE,\"SAE\",6,48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0385 \n",
      "Epoch 1: val_loss improved from inf to 0.02814, saving model to model\\DSAE_bottleneck_6_best_model.keras\n",
      "26/26 [==============================] - 2s 13ms/step - loss: 0.0372 - val_loss: 0.0281\n",
      "Epoch 2/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0253\n",
      "Epoch 2: val_loss improved from 0.02814 to 0.02524, saving model to model\\DSAE_bottleneck_6_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0251 - val_loss: 0.0252\n",
      "Epoch 3/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0238\n",
      "Epoch 3: val_loss improved from 0.02524 to 0.02436, saving model to model\\DSAE_bottleneck_6_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0236 - val_loss: 0.0244\n",
      "Epoch 4/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0233\n",
      "Epoch 4: val_loss improved from 0.02436 to 0.02406, saving model to model\\DSAE_bottleneck_6_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0231 - val_loss: 0.0241\n",
      "Epoch 5/40\n",
      "21/26 [=======================>......] - ETA: 0s - loss: 0.0228\n",
      "Epoch 5: val_loss improved from 0.02406 to 0.02393, saving model to model\\DSAE_bottleneck_6_best_model.keras\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0228 - val_loss: 0.0239\n",
      "Epoch 6/40\n",
      "19/26 [====================>.........] - ETA: 0s - loss: 0.0231\n",
      "Epoch 6: val_loss improved from 0.02393 to 0.02327, saving model to model\\DSAE_bottleneck_6_best_model.keras\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 0.0226 - val_loss: 0.0233\n",
      "Epoch 7/40\n",
      "20/26 [======================>.......] - ETA: 0s - loss: 0.0214\n",
      "Epoch 7: val_loss improved from 0.02327 to 0.02146, saving model to model\\DSAE_bottleneck_6_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0215 - val_loss: 0.0215\n",
      "Epoch 8/40\n",
      "21/26 [=======================>......] - ETA: 0s - loss: 0.0203\n",
      "Epoch 8: val_loss improved from 0.02146 to 0.02106, saving model to model\\DSAE_bottleneck_6_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0201 - val_loss: 0.0211\n",
      "Epoch 9/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0197\n",
      "Epoch 9: val_loss improved from 0.02106 to 0.02087, saving model to model\\DSAE_bottleneck_6_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0199 - val_loss: 0.0209\n",
      "Epoch 10/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0195\n",
      "Epoch 10: val_loss improved from 0.02087 to 0.02049, saving model to model\\DSAE_bottleneck_6_best_model.keras\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 0.0196 - val_loss: 0.0205\n",
      "Epoch 11/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0193\n",
      "Epoch 11: val_loss improved from 0.02049 to 0.02040, saving model to model\\DSAE_bottleneck_6_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0194 - val_loss: 0.0204\n",
      "Epoch 12/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0195\n",
      "Epoch 12: val_loss did not improve from 0.02040\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0193 - val_loss: 0.0205\n",
      "Epoch 13/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0191\n",
      "Epoch 13: val_loss improved from 0.02040 to 0.02035, saving model to model\\DSAE_bottleneck_6_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0192 - val_loss: 0.0203\n",
      "Epoch 14/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0185\n",
      "Epoch 14: val_loss improved from 0.02035 to 0.02033, saving model to model\\DSAE_bottleneck_6_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0191 - val_loss: 0.0203\n",
      "Epoch 15/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0193\n",
      "Epoch 15: val_loss did not improve from 0.02033\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0191 - val_loss: 0.0204\n",
      "Epoch 16/40\n",
      "21/26 [=======================>......] - ETA: 0s - loss: 0.0191\n",
      "Epoch 16: val_loss improved from 0.02033 to 0.02029, saving model to model\\DSAE_bottleneck_6_best_model.keras\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 0.0190 - val_loss: 0.0203\n",
      "Epoch 17/40\n",
      "21/26 [=======================>......] - ETA: 0s - loss: 0.0189\n",
      "Epoch 17: val_loss improved from 0.02029 to 0.02025, saving model to model\\DSAE_bottleneck_6_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0190 - val_loss: 0.0202\n",
      "Epoch 18/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0191\n",
      "Epoch 18: val_loss improved from 0.02025 to 0.02017, saving model to model\\DSAE_bottleneck_6_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0190 - val_loss: 0.0202\n",
      "Epoch 19/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0189\n",
      "Epoch 19: val_loss did not improve from 0.02017\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0189 - val_loss: 0.0202\n",
      "Epoch 20/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0192\n",
      "Epoch 20: val_loss did not improve from 0.02017\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0189 - val_loss: 0.0208\n",
      "Epoch 21/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0193\n",
      "Epoch 21: val_loss did not improve from 0.02017\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0190 - val_loss: 0.0203\n",
      "Epoch 22/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0185\n",
      "Epoch 22: val_loss improved from 0.02017 to 0.02017, saving model to model\\DSAE_bottleneck_6_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0188 - val_loss: 0.0202\n",
      "Epoch 23/40\n",
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0189\n",
      "Epoch 23: val_loss did not improve from 0.02017\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0187 - val_loss: 0.0203\n",
      "Epoch 24/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0191\n",
      "Epoch 24: val_loss improved from 0.02017 to 0.02016, saving model to model\\DSAE_bottleneck_6_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0188 - val_loss: 0.0202\n",
      "Epoch 25/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0189\n",
      "Epoch 25: val_loss did not improve from 0.02016\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0187 - val_loss: 0.0202\n",
      "Epoch 26/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0188\n",
      "Epoch 26: val_loss improved from 0.02016 to 0.02015, saving model to model\\DSAE_bottleneck_6_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0187 - val_loss: 0.0202\n",
      "Epoch 27/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0190\n",
      "Epoch 27: val_loss did not improve from 0.02015\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0187 - val_loss: 0.0203\n",
      "Epoch 28/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0191\n",
      "Epoch 28: val_loss did not improve from 0.02015\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0187 - val_loss: 0.0202\n",
      "Epoch 29/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0190\n",
      "Epoch 29: val_loss did not improve from 0.02015\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0187 - val_loss: 0.0203\n",
      "Epoch 30/40\n",
      "13/26 [==============>...............] - ETA: 0s - loss: 0.0188\n",
      "Epoch 30: val_loss did not improve from 0.02015\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0186 - val_loss: 0.0202\n",
      "Epoch 31/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0188\n",
      "Epoch 31: val_loss improved from 0.02015 to 0.02015, saving model to model\\DSAE_bottleneck_6_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0186 - val_loss: 0.0201\n",
      "Epoch 32/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0182\n",
      "Epoch 32: val_loss did not improve from 0.02015\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0186 - val_loss: 0.0201\n",
      "Epoch 33/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0190\n",
      "Epoch 33: val_loss did not improve from 0.02015\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0187 - val_loss: 0.0203\n",
      "Epoch 34/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0184\n",
      "Epoch 34: val_loss did not improve from 0.02015\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0186 - val_loss: 0.0202\n",
      "Epoch 35/40\n",
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0185\n",
      "Epoch 35: val_loss did not improve from 0.02015\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0185 - val_loss: 0.0203\n",
      "Epoch 36/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0189\n",
      "Epoch 36: val_loss did not improve from 0.02015\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0186 - val_loss: 0.0202\n",
      "Epoch 37/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0190\n",
      "Epoch 37: val_loss did not improve from 0.02015\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0186 - val_loss: 0.0206\n",
      "Epoch 38/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0186\n",
      "Epoch 38: val_loss did not improve from 0.02015\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0186 - val_loss: 0.0203\n",
      "Epoch 39/40\n",
      "21/26 [=======================>......] - ETA: 0s - loss: 0.0183\n",
      "Epoch 39: val_loss did not improve from 0.02015\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0185 - val_loss: 0.0202\n",
      "Epoch 40/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0186\n",
      "Epoch 40: val_loss did not improve from 0.02015\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0185 - val_loss: 0.0203\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "LogisticRegression - Mean CV Score: 0.4367692307692307\n",
      "LogisticRegression - Mean Confusion Matrix:\n",
      "[[ 1.2 11.4]\n",
      " [ 3.2 10.1]]\n",
      "SVM - Mean CV Score: 0.5640000000000001\n",
      "SVM - Mean Confusion Matrix:\n",
      "[[7.1 5.5]\n",
      " [5.8 7.5]]\n",
      "RandomForest - Mean CV Score: 0.5138461538461538\n",
      "RandomForest - Mean Confusion Matrix:\n",
      "[[7.1 5.5]\n",
      " [7.1 6.2]]\n",
      "KNN - Mean CV Score: 0.49046153846153845\n",
      "KNN - Mean Confusion Matrix:\n",
      "[[6.1 6.5]\n",
      " [6.7 6.6]]\n",
      "GradientBoosting - Mean CV Score: 0.529076923076923\n",
      "GradientBoosting - Mean Confusion Matrix:\n",
      "[[6.4 6.2]\n",
      " [6.  7.3]]\n",
      "AdaBoost - Mean CV Score: 0.47092307692307694\n",
      "AdaBoost - Mean Confusion Matrix:\n",
      "[[5.3 7.3]\n",
      " [6.4 6.9]]\n",
      "NaiveBayes - Mean CV Score: 0.5212307692307692\n",
      "NaiveBayes - Mean Confusion Matrix:\n",
      "[[8.4 4.2]\n",
      " [8.2 5.1]]\n",
      "DecisionTree - Mean CV Score: 0.49076923076923074\n",
      "DecisionTree - Mean Confusion Matrix:\n",
      "[[6.5 6.1]\n",
      " [7.1 6.2]]\n",
      "ExtraTrees - Mean CV Score: 0.5175384615384615\n",
      "ExtraTrees - Mean Confusion Matrix:\n",
      "[[6.8 5.8]\n",
      " [6.7 6.6]]\n",
      "XGBoost - Mean CV Score: 0.5407692307692307\n",
      "XGBoost - Mean Confusion Matrix:\n",
      "[[6.5 6.1]\n",
      " [5.8 7.5]]\n",
      "Size: bottleneck_6, Best classifier: SVM, CV Score: 0.5640000000000001\n",
      "Epoch 1/40\n",
      "14/26 [===============>..............] - ETA: 0s - loss: 0.0466 \n",
      "Epoch 1: val_loss improved from inf to 0.03309, saving model to model\\DSAE_bottleneck_10_best_model.keras\n",
      "26/26 [==============================] - 2s 15ms/step - loss: 0.0436 - val_loss: 0.0331\n",
      "Epoch 2/40\n",
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0257\n",
      "Epoch 2: val_loss improved from 0.03309 to 0.02489, saving model to model\\DSAE_bottleneck_10_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0254 - val_loss: 0.0249\n",
      "Epoch 3/40\n",
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0235\n",
      "Epoch 3: val_loss improved from 0.02489 to 0.02469, saving model to model\\DSAE_bottleneck_10_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0234 - val_loss: 0.0247\n",
      "Epoch 4/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0234\n",
      "Epoch 4: val_loss improved from 0.02469 to 0.02469, saving model to model\\DSAE_bottleneck_10_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0233 - val_loss: 0.0247\n",
      "Epoch 5/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0236\n",
      "Epoch 5: val_loss did not improve from 0.02469\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0233 - val_loss: 0.0248\n",
      "Epoch 6/40\n",
      "17/26 [==================>...........] - ETA: 0s - loss: 0.0224\n",
      "Epoch 6: val_loss did not improve from 0.02469\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0233 - val_loss: 0.0247\n",
      "Epoch 7/40\n",
      "17/26 [==================>...........] - ETA: 0s - loss: 0.0239\n",
      "Epoch 7: val_loss did not improve from 0.02469\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0233 - val_loss: 0.0247\n",
      "Epoch 8/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0235\n",
      "Epoch 8: val_loss improved from 0.02469 to 0.02467, saving model to model\\DSAE_bottleneck_10_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0233 - val_loss: 0.0247\n",
      "Epoch 9/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0235\n",
      "Epoch 9: val_loss did not improve from 0.02467\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0232 - val_loss: 0.0247\n",
      "Epoch 10/40\n",
      "19/26 [====================>.........] - ETA: 0s - loss: 0.0232\n",
      "Epoch 10: val_loss did not improve from 0.02467\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0233 - val_loss: 0.0247\n",
      "Epoch 11/40\n",
      "20/26 [======================>.......] - ETA: 0s - loss: 0.0236\n",
      "Epoch 11: val_loss did not improve from 0.02467\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0233 - val_loss: 0.0249\n",
      "Epoch 12/40\n",
      "13/26 [==============>...............] - ETA: 0s - loss: 0.0239\n",
      "Epoch 12: val_loss did not improve from 0.02467\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0233 - val_loss: 0.0247\n",
      "Epoch 13/40\n",
      "21/26 [=======================>......] - ETA: 0s - loss: 0.0232\n",
      "Epoch 13: val_loss did not improve from 0.02467\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0233 - val_loss: 0.0247\n",
      "Epoch 14/40\n",
      "21/26 [=======================>......] - ETA: 0s - loss: 0.0234\n",
      "Epoch 14: val_loss did not improve from 0.02467\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0233 - val_loss: 0.0247\n",
      "Epoch 15/40\n",
      "21/26 [=======================>......] - ETA: 0s - loss: 0.0231\n",
      "Epoch 15: val_loss did not improve from 0.02467\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0233 - val_loss: 0.0249\n",
      "Epoch 16/40\n",
      "20/26 [======================>.......] - ETA: 0s - loss: 0.0232\n",
      "Epoch 16: val_loss did not improve from 0.02467\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0233 - val_loss: 0.0248\n",
      "Epoch 17/40\n",
      "20/26 [======================>.......] - ETA: 0s - loss: 0.0238\n",
      "Epoch 17: val_loss did not improve from 0.02467\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0232 - val_loss: 0.0247\n",
      "Epoch 18/40\n",
      "17/26 [==================>...........] - ETA: 0s - loss: 0.0222\n",
      "Epoch 18: val_loss did not improve from 0.02467\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0233 - val_loss: 0.0248\n",
      "Epoch 19/40\n",
      "19/26 [====================>.........] - ETA: 0s - loss: 0.0226\n",
      "Epoch 19: val_loss did not improve from 0.02467\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0233 - val_loss: 0.0247\n",
      "Epoch 20/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0238\n",
      "Epoch 20: val_loss did not improve from 0.02467\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0232 - val_loss: 0.0248\n",
      "Epoch 21/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0227\n",
      "Epoch 21: val_loss did not improve from 0.02467\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0232 - val_loss: 0.0248\n",
      "Epoch 22/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0234\n",
      "Epoch 22: val_loss did not improve from 0.02467\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0232 - val_loss: 0.0248\n",
      "Epoch 23/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0227\n",
      "Epoch 23: val_loss did not improve from 0.02467\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0232 - val_loss: 0.0247\n",
      "Epoch 24/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0235\n",
      "Epoch 24: val_loss did not improve from 0.02467\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0232 - val_loss: 0.0247\n",
      "Epoch 25/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0234\n",
      "Epoch 25: val_loss did not improve from 0.02467\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0232 - val_loss: 0.0247\n",
      "Epoch 26/40\n",
      "21/26 [=======================>......] - ETA: 0s - loss: 0.0234\n",
      "Epoch 26: val_loss did not improve from 0.02467\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0232 - val_loss: 0.0247\n",
      "Epoch 27/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0225\n",
      "Epoch 27: val_loss did not improve from 0.02467\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0233 - val_loss: 0.0247\n",
      "Epoch 28/40\n",
      "21/26 [=======================>......] - ETA: 0s - loss: 0.0228\n",
      "Epoch 28: val_loss did not improve from 0.02467\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0233 - val_loss: 0.0248\n",
      "Epoch 29/40\n",
      "13/26 [==============>...............] - ETA: 0s - loss: 0.0231\n",
      "Epoch 29: val_loss did not improve from 0.02467\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0232 - val_loss: 0.0247\n",
      "Epoch 30/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0227\n",
      "Epoch 30: val_loss did not improve from 0.02467\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0232 - val_loss: 0.0247\n",
      "Epoch 31/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0235\n",
      "Epoch 31: val_loss did not improve from 0.02467\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0232 - val_loss: 0.0250\n",
      "Epoch 32/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0231\n",
      "Epoch 32: val_loss did not improve from 0.02467\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0233 - val_loss: 0.0248\n",
      "Epoch 33/40\n",
      "21/26 [=======================>......] - ETA: 0s - loss: 0.0230\n",
      "Epoch 33: val_loss did not improve from 0.02467\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0233 - val_loss: 0.0247\n",
      "Epoch 34/40\n",
      "20/26 [======================>.......] - ETA: 0s - loss: 0.0231\n",
      "Epoch 34: val_loss did not improve from 0.02467\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0232 - val_loss: 0.0247\n",
      "Epoch 35/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0235\n",
      "Epoch 35: val_loss did not improve from 0.02467\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0232 - val_loss: 0.0248\n",
      "Epoch 36/40\n",
      "21/26 [=======================>......] - ETA: 0s - loss: 0.0233\n",
      "Epoch 36: val_loss did not improve from 0.02467\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0232 - val_loss: 0.0248\n",
      "Epoch 37/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0230\n",
      "Epoch 37: val_loss did not improve from 0.02467\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0232 - val_loss: 0.0247\n",
      "Epoch 38/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0235\n",
      "Epoch 38: val_loss did not improve from 0.02467\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0232 - val_loss: 0.0248\n",
      "Epoch 39/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0234\n",
      "Epoch 39: val_loss did not improve from 0.02467\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0232 - val_loss: 0.0247\n",
      "Epoch 40/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0237\n",
      "Epoch 40: val_loss did not improve from 0.02467\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0232 - val_loss: 0.0248\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "LogisticRegression - Mean CV Score: 0.47523076923076923\n",
      "LogisticRegression - Mean Confusion Matrix:\n",
      "[[ 0.8 11.8]\n",
      " [ 1.8 11.5]]\n",
      "SVM - Mean CV Score: 0.47523076923076923\n",
      "SVM - Mean Confusion Matrix:\n",
      "[[ 0.8 11.8]\n",
      " [ 1.8 11.5]]\n",
      "RandomForest - Mean CV Score: 0.4712307692307693\n",
      "RandomForest - Mean Confusion Matrix:\n",
      "[[ 0.8 11.8]\n",
      " [ 1.9 11.4]]\n",
      "KNN - Mean CV Score: 0.4978461538461539\n",
      "KNN - Mean Confusion Matrix:\n",
      "[[10.4  2.2]\n",
      " [10.8  2.5]]\n",
      "GradientBoosting - Mean CV Score: 0.47523076923076923\n",
      "GradientBoosting - Mean Confusion Matrix:\n",
      "[[ 0.8 11.8]\n",
      " [ 1.8 11.5]]\n",
      "AdaBoost - Mean CV Score: 0.47523076923076923\n",
      "AdaBoost - Mean Confusion Matrix:\n",
      "[[ 0.8 11.8]\n",
      " [ 1.8 11.5]]\n",
      "NaiveBayes - Mean CV Score: 0.5213846153846153\n",
      "NaiveBayes - Mean Confusion Matrix:\n",
      "[[ 1.4 11.2]\n",
      " [ 1.2 12.1]]\n",
      "DecisionTree - Mean CV Score: 0.47523076923076923\n",
      "DecisionTree - Mean Confusion Matrix:\n",
      "[[ 0.8 11.8]\n",
      " [ 1.8 11.5]]\n",
      "ExtraTrees - Mean CV Score: 0.47523076923076923\n",
      "ExtraTrees - Mean Confusion Matrix:\n",
      "[[ 0.8 11.8]\n",
      " [ 1.8 11.5]]\n",
      "XGBoost - Mean CV Score: 0.4598461538461539\n",
      "XGBoost - Mean Confusion Matrix:\n",
      "[[ 1.7 10.9]\n",
      " [ 3.1 10.2]]\n",
      "Size: bottleneck_10, Best classifier: NaiveBayes, CV Score: 0.5213846153846153\n",
      "Epoch 1/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0391 \n",
      "Epoch 1: val_loss improved from inf to 0.02740, saving model to model\\DSAE_bottleneck_14_best_model.keras\n",
      "26/26 [==============================] - 1s 12ms/step - loss: 0.0377 - val_loss: 0.0274\n",
      "Epoch 2/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0249\n",
      "Epoch 2: val_loss improved from 0.02740 to 0.02537, saving model to model\\DSAE_bottleneck_14_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0249 - val_loss: 0.0254\n",
      "Epoch 3/40\n",
      "20/26 [======================>.......] - ETA: 0s - loss: 0.0236\n",
      "Epoch 3: val_loss improved from 0.02537 to 0.02457, saving model to model\\DSAE_bottleneck_14_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0236 - val_loss: 0.0246\n",
      "Epoch 4/40\n",
      "17/26 [==================>...........] - ETA: 0s - loss: 0.0240\n",
      "Epoch 4: val_loss improved from 0.02457 to 0.02431, saving model to model\\DSAE_bottleneck_14_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0232 - val_loss: 0.0243\n",
      "Epoch 5/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0229\n",
      "Epoch 5: val_loss improved from 0.02431 to 0.02393, saving model to model\\DSAE_bottleneck_14_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0229 - val_loss: 0.0239\n",
      "Epoch 6/40\n",
      "13/26 [==============>...............] - ETA: 0s - loss: 0.0242\n",
      "Epoch 6: val_loss improved from 0.02393 to 0.02387, saving model to model\\DSAE_bottleneck_14_best_model.keras\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0228 - val_loss: 0.0239\n",
      "Epoch 7/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0226\n",
      "Epoch 7: val_loss improved from 0.02387 to 0.02382, saving model to model\\DSAE_bottleneck_14_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0227 - val_loss: 0.0238\n",
      "Epoch 8/40\n",
      "21/26 [=======================>......] - ETA: 0s - loss: 0.0221\n",
      "Epoch 8: val_loss improved from 0.02382 to 0.02354, saving model to model\\DSAE_bottleneck_14_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0226 - val_loss: 0.0235\n",
      "Epoch 9/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0221\n",
      "Epoch 9: val_loss improved from 0.02354 to 0.02197, saving model to model\\DSAE_bottleneck_14_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0220 - val_loss: 0.0220\n",
      "Epoch 10/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0201\n",
      "Epoch 10: val_loss improved from 0.02197 to 0.02083, saving model to model\\DSAE_bottleneck_14_best_model.keras\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0202 - val_loss: 0.0208\n",
      "Epoch 11/40\n",
      "18/26 [===================>..........] - ETA: 0s - loss: 0.0198\n",
      "Epoch 11: val_loss improved from 0.02083 to 0.02058, saving model to model\\DSAE_bottleneck_14_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0196 - val_loss: 0.0206\n",
      "Epoch 12/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0194\n",
      "Epoch 12: val_loss improved from 0.02058 to 0.02044, saving model to model\\DSAE_bottleneck_14_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0194 - val_loss: 0.0204\n",
      "Epoch 13/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0195\n",
      "Epoch 13: val_loss improved from 0.02044 to 0.02034, saving model to model\\DSAE_bottleneck_14_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0192 - val_loss: 0.0203\n",
      "Epoch 14/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0193\n",
      "Epoch 14: val_loss improved from 0.02034 to 0.02033, saving model to model\\DSAE_bottleneck_14_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0192 - val_loss: 0.0203\n",
      "Epoch 15/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0190\n",
      "Epoch 15: val_loss did not improve from 0.02033\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0192 - val_loss: 0.0203\n",
      "Epoch 16/40\n",
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0189\n",
      "Epoch 16: val_loss did not improve from 0.02033\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0190 - val_loss: 0.0204\n",
      "Epoch 17/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0184\n",
      "Epoch 17: val_loss improved from 0.02033 to 0.02024, saving model to model\\DSAE_bottleneck_14_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0190 - val_loss: 0.0202\n",
      "Epoch 18/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0189\n",
      "Epoch 18: val_loss did not improve from 0.02024\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0189 - val_loss: 0.0204\n",
      "Epoch 19/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0190\n",
      "Epoch 19: val_loss improved from 0.02024 to 0.02021, saving model to model\\DSAE_bottleneck_14_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0189 - val_loss: 0.0202\n",
      "Epoch 20/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0185\n",
      "Epoch 20: val_loss did not improve from 0.02021\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0189 - val_loss: 0.0204\n",
      "Epoch 21/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0185\n",
      "Epoch 21: val_loss did not improve from 0.02021\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0188 - val_loss: 0.0202\n",
      "Epoch 22/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0188\n",
      "Epoch 22: val_loss did not improve from 0.02021\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0188 - val_loss: 0.0203\n",
      "Epoch 23/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0186\n",
      "Epoch 23: val_loss did not improve from 0.02021\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0188 - val_loss: 0.0203\n",
      "Epoch 24/40\n",
      "21/26 [=======================>......] - ETA: 0s - loss: 0.0187\n",
      "Epoch 24: val_loss did not improve from 0.02021\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0188 - val_loss: 0.0203\n",
      "Epoch 25/40\n",
      "20/26 [======================>.......] - ETA: 0s - loss: 0.0188\n",
      "Epoch 25: val_loss did not improve from 0.02021\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0187 - val_loss: 0.0204\n",
      "Epoch 26/40\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0187\n",
      "Epoch 26: val_loss did not improve from 0.02021\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0187 - val_loss: 0.0202\n",
      "Epoch 27/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0185\n",
      "Epoch 27: val_loss did not improve from 0.02021\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0187 - val_loss: 0.0203\n",
      "Epoch 28/40\n",
      "21/26 [=======================>......] - ETA: 0s - loss: 0.0186\n",
      "Epoch 28: val_loss did not improve from 0.02021\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0187 - val_loss: 0.0204\n",
      "Epoch 29/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0188\n",
      "Epoch 29: val_loss did not improve from 0.02021\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0187 - val_loss: 0.0203\n",
      "Epoch 30/40\n",
      "19/26 [====================>.........] - ETA: 0s - loss: 0.0187\n",
      "Epoch 30: val_loss did not improve from 0.02021\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0187 - val_loss: 0.0203\n",
      "Epoch 31/40\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0188\n",
      "Epoch 31: val_loss did not improve from 0.02021\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0188 - val_loss: 0.0204\n",
      "Epoch 32/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0186\n",
      "Epoch 32: val_loss did not improve from 0.02021\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0187 - val_loss: 0.0204\n",
      "Epoch 33/40\n",
      "21/26 [=======================>......] - ETA: 0s - loss: 0.0190\n",
      "Epoch 33: val_loss did not improve from 0.02021\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0186 - val_loss: 0.0204\n",
      "Epoch 34/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0185\n",
      "Epoch 34: val_loss did not improve from 0.02021\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0186 - val_loss: 0.0203\n",
      "Epoch 35/40\n",
      "21/26 [=======================>......] - ETA: 0s - loss: 0.0188\n",
      "Epoch 35: val_loss did not improve from 0.02021\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0186 - val_loss: 0.0204\n",
      "Epoch 36/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0185\n",
      "Epoch 36: val_loss did not improve from 0.02021\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0186 - val_loss: 0.0204\n",
      "Epoch 37/40\n",
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0185\n",
      "Epoch 37: val_loss did not improve from 0.02021\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0185 - val_loss: 0.0203\n",
      "Epoch 38/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0179\n",
      "Epoch 38: val_loss did not improve from 0.02021\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0185 - val_loss: 0.0203\n",
      "Epoch 39/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0187\n",
      "Epoch 39: val_loss did not improve from 0.02021\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0186 - val_loss: 0.0204\n",
      "Epoch 40/40\n",
      "21/26 [=======================>......] - ETA: 0s - loss: 0.0185\n",
      "Epoch 40: val_loss did not improve from 0.02021\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0186 - val_loss: 0.0205\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "LogisticRegression - Mean CV Score: 0.47923076923076924\n",
      "LogisticRegression - Mean Confusion Matrix:\n",
      "[[ 2.6 10. ]\n",
      " [ 3.5  9.8]]\n",
      "SVM - Mean CV Score: 0.5715384615384616\n",
      "SVM - Mean Confusion Matrix:\n",
      "[[8.3 4.3]\n",
      " [6.8 6.5]]\n",
      "RandomForest - Mean CV Score: 0.5590769230769231\n",
      "RandomForest - Mean Confusion Matrix:\n",
      "[[7.1 5.5]\n",
      " [5.9 7.4]]\n",
      "KNN - Mean CV Score: 0.5126153846153847\n",
      "KNN - Mean Confusion Matrix:\n",
      "[[5.5 7.1]\n",
      " [5.5 7.8]]\n",
      "GradientBoosting - Mean CV Score: 0.5132307692307693\n",
      "GradientBoosting - Mean Confusion Matrix:\n",
      "[[6.5 6.1]\n",
      " [6.5 6.8]]\n",
      "AdaBoost - Mean CV Score: 0.5095384615384615\n",
      "AdaBoost - Mean Confusion Matrix:\n",
      "[[5.8 6.8]\n",
      " [5.9 7.4]]\n",
      "NaiveBayes - Mean CV Score: 0.5481538461538461\n",
      "NaiveBayes - Mean Confusion Matrix:\n",
      "[[9.4 3.2]\n",
      " [8.5 4.8]]\n",
      "DecisionTree - Mean CV Score: 0.5669230769230771\n",
      "DecisionTree - Mean Confusion Matrix:\n",
      "[[7.2 5.4]\n",
      " [5.8 7.5]]\n",
      "ExtraTrees - Mean CV Score: 0.5590769230769231\n",
      "ExtraTrees - Mean Confusion Matrix:\n",
      "[[7.  5.6]\n",
      " [5.8 7.5]]\n",
      "XGBoost - Mean CV Score: 0.5555384615384615\n",
      "XGBoost - Mean Confusion Matrix:\n",
      "[[6.7 5.9]\n",
      " [5.6 7.7]]\n",
      "Size: bottleneck_14, Best classifier: SVM, CV Score: 0.5715384615384616\n",
      "Epoch 1/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0415 \n",
      "Epoch 1: val_loss improved from inf to 0.02989, saving model to model\\DSAE_bottleneck_18_best_model.keras\n",
      "26/26 [==============================] - 2s 13ms/step - loss: 0.0401 - val_loss: 0.0299\n",
      "Epoch 2/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0251\n",
      "Epoch 2: val_loss improved from 0.02989 to 0.02526, saving model to model\\DSAE_bottleneck_18_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0249 - val_loss: 0.0253\n",
      "Epoch 3/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0242\n",
      "Epoch 3: val_loss improved from 0.02526 to 0.02454, saving model to model\\DSAE_bottleneck_18_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0236 - val_loss: 0.0245\n",
      "Epoch 4/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0228\n",
      "Epoch 4: val_loss improved from 0.02454 to 0.02405, saving model to model\\DSAE_bottleneck_18_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0231 - val_loss: 0.0241\n",
      "Epoch 5/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0231\n",
      "Epoch 5: val_loss improved from 0.02405 to 0.02383, saving model to model\\DSAE_bottleneck_18_best_model.keras\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0228 - val_loss: 0.0238\n",
      "Epoch 6/40\n",
      "21/26 [=======================>......] - ETA: 0s - loss: 0.0226\n",
      "Epoch 6: val_loss improved from 0.02383 to 0.02348, saving model to model\\DSAE_bottleneck_18_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0226 - val_loss: 0.0235\n",
      "Epoch 7/40\n",
      "19/26 [====================>.........] - ETA: 0s - loss: 0.0217\n",
      "Epoch 7: val_loss improved from 0.02348 to 0.02179, saving model to model\\DSAE_bottleneck_18_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0218 - val_loss: 0.0218\n",
      "Epoch 8/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0203\n",
      "Epoch 8: val_loss improved from 0.02179 to 0.02077, saving model to model\\DSAE_bottleneck_18_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0203 - val_loss: 0.0208\n",
      "Epoch 9/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0200\n",
      "Epoch 9: val_loss improved from 0.02077 to 0.02048, saving model to model\\DSAE_bottleneck_18_best_model.keras\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 0.0197 - val_loss: 0.0205\n",
      "Epoch 10/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0194\n",
      "Epoch 10: val_loss improved from 0.02048 to 0.02047, saving model to model\\DSAE_bottleneck_18_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0194 - val_loss: 0.0205\n",
      "Epoch 11/40\n",
      "20/26 [======================>.......] - ETA: 0s - loss: 0.0192\n",
      "Epoch 11: val_loss improved from 0.02047 to 0.02041, saving model to model\\DSAE_bottleneck_18_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0193 - val_loss: 0.0204\n",
      "Epoch 12/40\n",
      "20/26 [======================>.......] - ETA: 0s - loss: 0.0191\n",
      "Epoch 12: val_loss improved from 0.02041 to 0.02035, saving model to model\\DSAE_bottleneck_18_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0193 - val_loss: 0.0204\n",
      "Epoch 13/40\n",
      "21/26 [=======================>......] - ETA: 0s - loss: 0.0186\n",
      "Epoch 13: val_loss improved from 0.02035 to 0.02034, saving model to model\\DSAE_bottleneck_18_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0192 - val_loss: 0.0203\n",
      "Epoch 14/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0190\n",
      "Epoch 14: val_loss improved from 0.02034 to 0.02028, saving model to model\\DSAE_bottleneck_18_best_model.keras\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 0.0191 - val_loss: 0.0203\n",
      "Epoch 15/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0186\n",
      "Epoch 15: val_loss improved from 0.02028 to 0.02023, saving model to model\\DSAE_bottleneck_18_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0191 - val_loss: 0.0202\n",
      "Epoch 16/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0191\n",
      "Epoch 16: val_loss did not improve from 0.02023\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0190 - val_loss: 0.0203\n",
      "Epoch 17/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0187\n",
      "Epoch 17: val_loss did not improve from 0.02023\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0190 - val_loss: 0.0202\n",
      "Epoch 18/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0189\n",
      "Epoch 18: val_loss did not improve from 0.02023\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0189 - val_loss: 0.0205\n",
      "Epoch 19/40\n",
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0191\n",
      "Epoch 19: val_loss did not improve from 0.02023\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0189 - val_loss: 0.0202\n",
      "Epoch 20/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0189\n",
      "Epoch 20: val_loss improved from 0.02023 to 0.02022, saving model to model\\DSAE_bottleneck_18_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0188 - val_loss: 0.0202\n",
      "Epoch 21/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0189\n",
      "Epoch 21: val_loss did not improve from 0.02022\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0188 - val_loss: 0.0203\n",
      "Epoch 22/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0188\n",
      "Epoch 22: val_loss did not improve from 0.02022\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0188 - val_loss: 0.0203\n",
      "Epoch 23/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0191\n",
      "Epoch 23: val_loss did not improve from 0.02022\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0189 - val_loss: 0.0203\n",
      "Epoch 24/40\n",
      "21/26 [=======================>......] - ETA: 0s - loss: 0.0184\n",
      "Epoch 24: val_loss did not improve from 0.02022\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0188 - val_loss: 0.0204\n",
      "Epoch 25/40\n",
      "21/26 [=======================>......] - ETA: 0s - loss: 0.0189\n",
      "Epoch 25: val_loss did not improve from 0.02022\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0187 - val_loss: 0.0203\n",
      "Epoch 26/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0187\n",
      "Epoch 26: val_loss improved from 0.02022 to 0.02022, saving model to model\\DSAE_bottleneck_18_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0188 - val_loss: 0.0202\n",
      "Epoch 27/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0185\n",
      "Epoch 27: val_loss did not improve from 0.02022\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0187 - val_loss: 0.0203\n",
      "Epoch 28/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0186\n",
      "Epoch 28: val_loss did not improve from 0.02022\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0187 - val_loss: 0.0202\n",
      "Epoch 29/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0186\n",
      "Epoch 29: val_loss did not improve from 0.02022\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0186 - val_loss: 0.0203\n",
      "Epoch 30/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0185\n",
      "Epoch 30: val_loss did not improve from 0.02022\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0186 - val_loss: 0.0203\n",
      "Epoch 31/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0187\n",
      "Epoch 31: val_loss did not improve from 0.02022\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0186 - val_loss: 0.0204\n",
      "Epoch 32/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0185\n",
      "Epoch 32: val_loss did not improve from 0.02022\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0186 - val_loss: 0.0203\n",
      "Epoch 33/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0188\n",
      "Epoch 33: val_loss improved from 0.02022 to 0.02021, saving model to model\\DSAE_bottleneck_18_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0186 - val_loss: 0.0202\n",
      "Epoch 34/40\n",
      "11/26 [===========>..................] - ETA: 0s - loss: 0.0179\n",
      "Epoch 34: val_loss did not improve from 0.02021\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0186 - val_loss: 0.0203\n",
      "Epoch 35/40\n",
      "18/26 [===================>..........] - ETA: 0s - loss: 0.0183\n",
      "Epoch 35: val_loss did not improve from 0.02021\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0186 - val_loss: 0.0203\n",
      "Epoch 36/40\n",
      "20/26 [======================>.......] - ETA: 0s - loss: 0.0179\n",
      "Epoch 36: val_loss did not improve from 0.02021\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0185 - val_loss: 0.0202\n",
      "Epoch 37/40\n",
      "21/26 [=======================>......] - ETA: 0s - loss: 0.0188\n",
      "Epoch 37: val_loss did not improve from 0.02021\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0186 - val_loss: 0.0202\n",
      "Epoch 38/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0184\n",
      "Epoch 38: val_loss did not improve from 0.02021\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0185 - val_loss: 0.0203\n",
      "Epoch 39/40\n",
      "21/26 [=======================>......] - ETA: 0s - loss: 0.0183\n",
      "Epoch 39: val_loss did not improve from 0.02021\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0185 - val_loss: 0.0203\n",
      "Epoch 40/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0186\n",
      "Epoch 40: val_loss did not improve from 0.02021\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0185 - val_loss: 0.0203\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "LogisticRegression - Mean CV Score: 0.46369230769230774\n",
      "LogisticRegression - Mean Confusion Matrix:\n",
      "[[ 1.1 11.5]\n",
      " [ 2.4 10.9]]\n",
      "SVM - Mean CV Score: 0.5292307692307692\n",
      "SVM - Mean Confusion Matrix:\n",
      "[[6.7 5.9]\n",
      " [6.3 7. ]]\n",
      "RandomForest - Mean CV Score: 0.4750769230769231\n",
      "RandomForest - Mean Confusion Matrix:\n",
      "[[5.3 7.3]\n",
      " [6.3 7. ]]\n",
      "KNN - Mean CV Score: 0.46753846153846157\n",
      "KNN - Mean Confusion Matrix:\n",
      "[[6.6 6. ]\n",
      " [7.8 5.5]]\n",
      "GradientBoosting - Mean CV Score: 0.48307692307692307\n",
      "GradientBoosting - Mean Confusion Matrix:\n",
      "[[6.4 6.2]\n",
      " [7.2 6.1]]\n",
      "AdaBoost - Mean CV Score: 0.5058461538461538\n",
      "AdaBoost - Mean Confusion Matrix:\n",
      "[[6.3 6.3]\n",
      " [6.5 6.8]]\n",
      "NaiveBayes - Mean CV Score: 0.506\n",
      "NaiveBayes - Mean Confusion Matrix:\n",
      "[[8.6 4. ]\n",
      " [8.8 4.5]]\n",
      "DecisionTree - Mean CV Score: 0.49846153846153846\n",
      "DecisionTree - Mean Confusion Matrix:\n",
      "[[5.9 6.7]\n",
      " [6.3 7. ]]\n",
      "ExtraTrees - Mean CV Score: 0.49046153846153845\n",
      "ExtraTrees - Mean Confusion Matrix:\n",
      "[[5.5 7.1]\n",
      " [6.1 7.2]]\n",
      "XGBoost - Mean CV Score: 0.5023076923076923\n",
      "XGBoost - Mean Confusion Matrix:\n",
      "[[6.1 6.5]\n",
      " [6.4 6.9]]\n",
      "Size: bottleneck_18, Best classifier: SVM, CV Score: 0.5292307692307692\n",
      "Epoch 1/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0405 \n",
      "Epoch 1: val_loss improved from inf to 0.02652, saving model to model\\DSAE_bottleneck_22_best_model.keras\n",
      "26/26 [==============================] - 2s 13ms/step - loss: 0.0386 - val_loss: 0.0265\n",
      "Epoch 2/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0246\n",
      "Epoch 2: val_loss improved from 0.02652 to 0.02505, saving model to model\\DSAE_bottleneck_22_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0246 - val_loss: 0.0250\n",
      "Epoch 3/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0235\n",
      "Epoch 3: val_loss improved from 0.02505 to 0.02428, saving model to model\\DSAE_bottleneck_22_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0235 - val_loss: 0.0243\n",
      "Epoch 4/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0233\n",
      "Epoch 4: val_loss improved from 0.02428 to 0.02409, saving model to model\\DSAE_bottleneck_22_best_model.keras\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0232 - val_loss: 0.0241\n",
      "Epoch 5/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0230\n",
      "Epoch 5: val_loss improved from 0.02409 to 0.02387, saving model to model\\DSAE_bottleneck_22_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0229 - val_loss: 0.0239\n",
      "Epoch 6/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0225\n",
      "Epoch 6: val_loss improved from 0.02387 to 0.02382, saving model to model\\DSAE_bottleneck_22_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0227 - val_loss: 0.0238\n",
      "Epoch 7/40\n",
      "18/26 [===================>..........] - ETA: 0s - loss: 0.0220\n",
      "Epoch 7: val_loss improved from 0.02382 to 0.02294, saving model to model\\DSAE_bottleneck_22_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0224 - val_loss: 0.0229\n",
      "Epoch 8/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0210\n",
      "Epoch 8: val_loss improved from 0.02294 to 0.02102, saving model to model\\DSAE_bottleneck_22_best_model.keras\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0209 - val_loss: 0.0210\n",
      "Epoch 9/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0195\n",
      "Epoch 9: val_loss improved from 0.02102 to 0.02060, saving model to model\\DSAE_bottleneck_22_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0198 - val_loss: 0.0206\n",
      "Epoch 10/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0191\n",
      "Epoch 10: val_loss improved from 0.02060 to 0.02056, saving model to model\\DSAE_bottleneck_22_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0195 - val_loss: 0.0206\n",
      "Epoch 11/40\n",
      "21/26 [=======================>......] - ETA: 0s - loss: 0.0192\n",
      "Epoch 11: val_loss improved from 0.02056 to 0.02054, saving model to model\\DSAE_bottleneck_22_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0193 - val_loss: 0.0205\n",
      "Epoch 12/40\n",
      "21/26 [=======================>......] - ETA: 0s - loss: 0.0188\n",
      "Epoch 12: val_loss improved from 0.02054 to 0.02050, saving model to model\\DSAE_bottleneck_22_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0193 - val_loss: 0.0205\n",
      "Epoch 13/40\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0192\n",
      "Epoch 13: val_loss improved from 0.02050 to 0.02027, saving model to model\\DSAE_bottleneck_22_best_model.keras\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 0.0192 - val_loss: 0.0203\n",
      "Epoch 14/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0190\n",
      "Epoch 14: val_loss did not improve from 0.02027\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0191 - val_loss: 0.0203\n",
      "Epoch 15/40\n",
      "21/26 [=======================>......] - ETA: 0s - loss: 0.0186\n",
      "Epoch 15: val_loss improved from 0.02027 to 0.02022, saving model to model\\DSAE_bottleneck_22_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0190 - val_loss: 0.0202\n",
      "Epoch 16/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0191\n",
      "Epoch 16: val_loss did not improve from 0.02022\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0189 - val_loss: 0.0204\n",
      "Epoch 17/40\n",
      "21/26 [=======================>......] - ETA: 0s - loss: 0.0192\n",
      "Epoch 17: val_loss did not improve from 0.02022\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0189 - val_loss: 0.0203\n",
      "Epoch 18/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0188\n",
      "Epoch 18: val_loss improved from 0.02022 to 0.02005, saving model to model\\DSAE_bottleneck_22_best_model.keras\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 0.0189 - val_loss: 0.0200\n",
      "Epoch 19/40\n",
      "20/26 [======================>.......] - ETA: 0s - loss: 0.0188\n",
      "Epoch 19: val_loss did not improve from 0.02005\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0188 - val_loss: 0.0202\n",
      "Epoch 20/40\n",
      "21/26 [=======================>......] - ETA: 0s - loss: 0.0189\n",
      "Epoch 20: val_loss did not improve from 0.02005\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0187 - val_loss: 0.0201\n",
      "Epoch 21/40\n",
      "18/26 [===================>..........] - ETA: 0s - loss: 0.0189\n",
      "Epoch 21: val_loss did not improve from 0.02005\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0187 - val_loss: 0.0201\n",
      "Epoch 22/40\n",
      "14/26 [===============>..............] - ETA: 0s - loss: 0.0177\n",
      "Epoch 22: val_loss improved from 0.02005 to 0.01991, saving model to model\\DSAE_bottleneck_22_best_model.keras\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0186 - val_loss: 0.0199\n",
      "Epoch 23/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0190\n",
      "Epoch 23: val_loss improved from 0.01991 to 0.01984, saving model to model\\DSAE_bottleneck_22_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0185 - val_loss: 0.0198\n",
      "Epoch 24/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0183\n",
      "Epoch 24: val_loss improved from 0.01984 to 0.01977, saving model to model\\DSAE_bottleneck_22_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0185 - val_loss: 0.0198\n",
      "Epoch 25/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0185\n",
      "Epoch 25: val_loss did not improve from 0.01977\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0183 - val_loss: 0.0199\n",
      "Epoch 26/40\n",
      "21/26 [=======================>......] - ETA: 0s - loss: 0.0185\n",
      "Epoch 26: val_loss improved from 0.01977 to 0.01959, saving model to model\\DSAE_bottleneck_22_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0182 - val_loss: 0.0196\n",
      "Epoch 27/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0179\n",
      "Epoch 27: val_loss improved from 0.01959 to 0.01934, saving model to model\\DSAE_bottleneck_22_best_model.keras\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0179 - val_loss: 0.0193\n",
      "Epoch 28/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0176\n",
      "Epoch 28: val_loss did not improve from 0.01934\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0177 - val_loss: 0.0195\n",
      "Epoch 29/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0172\n",
      "Epoch 29: val_loss improved from 0.01934 to 0.01913, saving model to model\\DSAE_bottleneck_22_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0175 - val_loss: 0.0191\n",
      "Epoch 30/40\n",
      "21/26 [=======================>......] - ETA: 0s - loss: 0.0174\n",
      "Epoch 30: val_loss improved from 0.01913 to 0.01903, saving model to model\\DSAE_bottleneck_22_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0174 - val_loss: 0.0190\n",
      "Epoch 31/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0172\n",
      "Epoch 31: val_loss improved from 0.01903 to 0.01874, saving model to model\\DSAE_bottleneck_22_best_model.keras\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 0.0171 - val_loss: 0.0187\n",
      "Epoch 32/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0173\n",
      "Epoch 32: val_loss improved from 0.01874 to 0.01855, saving model to model\\DSAE_bottleneck_22_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0170 - val_loss: 0.0185\n",
      "Epoch 33/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0170\n",
      "Epoch 33: val_loss did not improve from 0.01855\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0169 - val_loss: 0.0188\n",
      "Epoch 34/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0169\n",
      "Epoch 34: val_loss improved from 0.01855 to 0.01846, saving model to model\\DSAE_bottleneck_22_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0169 - val_loss: 0.0185\n",
      "Epoch 35/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0169\n",
      "Epoch 35: val_loss improved from 0.01846 to 0.01843, saving model to model\\DSAE_bottleneck_22_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0168 - val_loss: 0.0184\n",
      "Epoch 36/40\n",
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0168\n",
      "Epoch 36: val_loss did not improve from 0.01843\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0167 - val_loss: 0.0184\n",
      "Epoch 37/40\n",
      "21/26 [=======================>......] - ETA: 0s - loss: 0.0171\n",
      "Epoch 37: val_loss improved from 0.01843 to 0.01839, saving model to model\\DSAE_bottleneck_22_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0167 - val_loss: 0.0184\n",
      "Epoch 38/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0165\n",
      "Epoch 38: val_loss did not improve from 0.01839\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0166 - val_loss: 0.0185\n",
      "Epoch 39/40\n",
      "20/26 [======================>.......] - ETA: 0s - loss: 0.0167\n",
      "Epoch 39: val_loss did not improve from 0.01839\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0166 - val_loss: 0.0186\n",
      "Epoch 40/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0165\n",
      "Epoch 40: val_loss improved from 0.01839 to 0.01836, saving model to model\\DSAE_bottleneck_22_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0167 - val_loss: 0.0184\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "LogisticRegression - Mean CV Score: 0.43646153846153846\n",
      "LogisticRegression - Mean Confusion Matrix:\n",
      "[[3.1 9.5]\n",
      " [5.1 8.2]]\n",
      "SVM - Mean CV Score: 0.5792307692307691\n",
      "SVM - Mean Confusion Matrix:\n",
      "[[7.7 4.9]\n",
      " [6.  7.3]]\n",
      "RandomForest - Mean CV Score: 0.5173846153846154\n",
      "RandomForest - Mean Confusion Matrix:\n",
      "[[6.3 6.3]\n",
      " [6.2 7.1]]\n",
      "KNN - Mean CV Score: 0.564\n",
      "KNN - Mean Confusion Matrix:\n",
      "[[7.1 5.5]\n",
      " [5.8 7.5]]\n",
      "GradientBoosting - Mean CV Score: 0.5672307692307692\n",
      "GradientBoosting - Mean Confusion Matrix:\n",
      "[[6.9 5.7]\n",
      " [5.5 7.8]]\n",
      "AdaBoost - Mean CV Score: 0.5598461538461539\n",
      "AdaBoost - Mean Confusion Matrix:\n",
      "[[7.3 5.3]\n",
      " [6.1 7.2]]\n",
      "NaiveBayes - Mean CV Score: 0.5130769230769232\n",
      "NaiveBayes - Mean Confusion Matrix:\n",
      "[[10.3  2.3]\n",
      " [10.3  3. ]]\n",
      "DecisionTree - Mean CV Score: 0.5292307692307692\n",
      "DecisionTree - Mean Confusion Matrix:\n",
      "[[6.5 6.1]\n",
      " [6.1 7.2]]\n",
      "ExtraTrees - Mean CV Score: 0.5016923076923077\n",
      "ExtraTrees - Mean Confusion Matrix:\n",
      "[[6.4 6.2]\n",
      " [6.7 6.6]]\n",
      "XGBoost - Mean CV Score: 0.5290769230769232\n",
      "XGBoost - Mean Confusion Matrix:\n",
      "[[6.5 6.1]\n",
      " [6.1 7.2]]\n",
      "Size: bottleneck_22, Best classifier: SVM, CV Score: 0.5792307692307691\n",
      "Epoch 1/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0386 \n",
      "Epoch 1: val_loss improved from inf to 0.02747, saving model to model\\DSAE_bottleneck_26_best_model.keras\n",
      "26/26 [==============================] - 1s 12ms/step - loss: 0.0378 - val_loss: 0.0275\n",
      "Epoch 2/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0247\n",
      "Epoch 2: val_loss improved from 0.02747 to 0.02538, saving model to model\\DSAE_bottleneck_26_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0247 - val_loss: 0.0254\n",
      "Epoch 3/40\n",
      "21/26 [=======================>......] - ETA: 0s - loss: 0.0232\n",
      "Epoch 3: val_loss improved from 0.02538 to 0.02427, saving model to model\\DSAE_bottleneck_26_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0235 - val_loss: 0.0243\n",
      "Epoch 4/40\n",
      "17/26 [==================>...........] - ETA: 0s - loss: 0.0228\n",
      "Epoch 4: val_loss improved from 0.02427 to 0.02414, saving model to model\\DSAE_bottleneck_26_best_model.keras\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 0.0231 - val_loss: 0.0241\n",
      "Epoch 5/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0233\n",
      "Epoch 5: val_loss improved from 0.02414 to 0.02391, saving model to model\\DSAE_bottleneck_26_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0229 - val_loss: 0.0239\n",
      "Epoch 6/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0230\n",
      "Epoch 6: val_loss improved from 0.02391 to 0.02360, saving model to model\\DSAE_bottleneck_26_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0227 - val_loss: 0.0236\n",
      "Epoch 7/40\n",
      "20/26 [======================>.......] - ETA: 0s - loss: 0.0226\n",
      "Epoch 7: val_loss improved from 0.02360 to 0.02310, saving model to model\\DSAE_bottleneck_26_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0224 - val_loss: 0.0231\n",
      "Epoch 8/40\n",
      "21/26 [=======================>......] - ETA: 0s - loss: 0.0213\n",
      "Epoch 8: val_loss improved from 0.02310 to 0.02108, saving model to model\\DSAE_bottleneck_26_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0212 - val_loss: 0.0211\n",
      "Epoch 9/40\n",
      "12/26 [============>.................] - ETA: 0s - loss: 0.0197\n",
      "Epoch 9: val_loss improved from 0.02108 to 0.02059, saving model to model\\DSAE_bottleneck_26_best_model.keras\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0197 - val_loss: 0.0206\n",
      "Epoch 10/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0194\n",
      "Epoch 10: val_loss improved from 0.02059 to 0.02036, saving model to model\\DSAE_bottleneck_26_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0194 - val_loss: 0.0204\n",
      "Epoch 11/40\n",
      "21/26 [=======================>......] - ETA: 0s - loss: 0.0194\n",
      "Epoch 11: val_loss improved from 0.02036 to 0.02034, saving model to model\\DSAE_bottleneck_26_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0192 - val_loss: 0.0203\n",
      "Epoch 12/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0194\n",
      "Epoch 12: val_loss improved from 0.02034 to 0.02026, saving model to model\\DSAE_bottleneck_26_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0191 - val_loss: 0.0203\n",
      "Epoch 13/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0193\n",
      "Epoch 13: val_loss improved from 0.02026 to 0.02013, saving model to model\\DSAE_bottleneck_26_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0190 - val_loss: 0.0201\n",
      "Epoch 14/40\n",
      "11/26 [===========>..................] - ETA: 0s - loss: 0.0181\n",
      "Epoch 14: val_loss did not improve from 0.02013\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0190 - val_loss: 0.0202\n",
      "Epoch 15/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0189\n",
      "Epoch 15: val_loss improved from 0.02013 to 0.02004, saving model to model\\DSAE_bottleneck_26_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0188 - val_loss: 0.0200\n",
      "Epoch 16/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0187\n",
      "Epoch 16: val_loss improved from 0.02004 to 0.02001, saving model to model\\DSAE_bottleneck_26_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0187 - val_loss: 0.0200\n",
      "Epoch 17/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0183\n",
      "Epoch 17: val_loss did not improve from 0.02001\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0186 - val_loss: 0.0201\n",
      "Epoch 18/40\n",
      "21/26 [=======================>......] - ETA: 0s - loss: 0.0184\n",
      "Epoch 18: val_loss improved from 0.02001 to 0.02000, saving model to model\\DSAE_bottleneck_26_best_model.keras\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0186 - val_loss: 0.0200\n",
      "Epoch 19/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0180\n",
      "Epoch 19: val_loss improved from 0.02000 to 0.01993, saving model to model\\DSAE_bottleneck_26_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0185 - val_loss: 0.0199\n",
      "Epoch 20/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0187\n",
      "Epoch 20: val_loss did not improve from 0.01993\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0185 - val_loss: 0.0200\n",
      "Epoch 21/40\n",
      "21/26 [=======================>......] - ETA: 0s - loss: 0.0184\n",
      "Epoch 21: val_loss did not improve from 0.01993\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0185 - val_loss: 0.0199\n",
      "Epoch 22/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0184\n",
      "Epoch 22: val_loss improved from 0.01993 to 0.01978, saving model to model\\DSAE_bottleneck_26_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0184 - val_loss: 0.0198\n",
      "Epoch 23/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0183\n",
      "Epoch 23: val_loss improved from 0.01978 to 0.01976, saving model to model\\DSAE_bottleneck_26_best_model.keras\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 0.0183 - val_loss: 0.0198\n",
      "Epoch 24/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0182\n",
      "Epoch 24: val_loss improved from 0.01976 to 0.01968, saving model to model\\DSAE_bottleneck_26_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0183 - val_loss: 0.0197\n",
      "Epoch 25/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0182\n",
      "Epoch 25: val_loss improved from 0.01968 to 0.01951, saving model to model\\DSAE_bottleneck_26_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0183 - val_loss: 0.0195\n",
      "Epoch 26/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0181\n",
      "Epoch 26: val_loss did not improve from 0.01951\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0182 - val_loss: 0.0195\n",
      "Epoch 27/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0182\n",
      "Epoch 27: val_loss did not improve from 0.01951\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0181 - val_loss: 0.0196\n",
      "Epoch 28/40\n",
      "17/26 [==================>...........] - ETA: 0s - loss: 0.0184\n",
      "Epoch 28: val_loss improved from 0.01951 to 0.01939, saving model to model\\DSAE_bottleneck_26_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0182 - val_loss: 0.0194\n",
      "Epoch 29/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0178\n",
      "Epoch 29: val_loss improved from 0.01939 to 0.01890, saving model to model\\DSAE_bottleneck_26_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0179 - val_loss: 0.0189\n",
      "Epoch 30/40\n",
      "20/26 [======================>.......] - ETA: 0s - loss: 0.0174\n",
      "Epoch 30: val_loss improved from 0.01890 to 0.01870, saving model to model\\DSAE_bottleneck_26_best_model.keras\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0175 - val_loss: 0.0187\n",
      "Epoch 31/40\n",
      "19/26 [====================>.........] - ETA: 0s - loss: 0.0176\n",
      "Epoch 31: val_loss improved from 0.01870 to 0.01863, saving model to model\\DSAE_bottleneck_26_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0173 - val_loss: 0.0186\n",
      "Epoch 32/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0170\n",
      "Epoch 32: val_loss improved from 0.01863 to 0.01852, saving model to model\\DSAE_bottleneck_26_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0172 - val_loss: 0.0185\n",
      "Epoch 33/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0170\n",
      "Epoch 33: val_loss did not improve from 0.01852\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0171 - val_loss: 0.0187\n",
      "Epoch 34/40\n",
      "20/26 [======================>.......] - ETA: 0s - loss: 0.0172\n",
      "Epoch 34: val_loss improved from 0.01852 to 0.01850, saving model to model\\DSAE_bottleneck_26_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0169 - val_loss: 0.0185\n",
      "Epoch 35/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0169\n",
      "Epoch 35: val_loss did not improve from 0.01850\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0168 - val_loss: 0.0185\n",
      "Epoch 36/40\n",
      "21/26 [=======================>......] - ETA: 0s - loss: 0.0163\n",
      "Epoch 36: val_loss improved from 0.01850 to 0.01835, saving model to model\\DSAE_bottleneck_26_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0168 - val_loss: 0.0183\n",
      "Epoch 37/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0164\n",
      "Epoch 37: val_loss did not improve from 0.01835\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0166 - val_loss: 0.0188\n",
      "Epoch 38/40\n",
      "20/26 [======================>.......] - ETA: 0s - loss: 0.0167\n",
      "Epoch 38: val_loss did not improve from 0.01835\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0165 - val_loss: 0.0186\n",
      "Epoch 39/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0163\n",
      "Epoch 39: val_loss did not improve from 0.01835\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0164 - val_loss: 0.0184\n",
      "Epoch 40/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0163\n",
      "Epoch 40: val_loss did not improve from 0.01835\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0164 - val_loss: 0.0186\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "LogisticRegression - Mean CV Score: 0.4481538461538461\n",
      "LogisticRegression - Mean Confusion Matrix:\n",
      "[[3.1 9.5]\n",
      " [4.8 8.5]]\n",
      "SVM - Mean CV Score: 0.5907692307692306\n",
      "SVM - Mean Confusion Matrix:\n",
      "[[7.3 5.3]\n",
      " [5.3 8. ]]\n",
      "RandomForest - Mean CV Score: 0.5058461538461538\n",
      "RandomForest - Mean Confusion Matrix:\n",
      "[[6.2 6.4]\n",
      " [6.4 6.9]]\n",
      "KNN - Mean CV Score: 0.5361538461538462\n",
      "KNN - Mean Confusion Matrix:\n",
      "[[6.7 5.9]\n",
      " [6.1 7.2]]\n",
      "GradientBoosting - Mean CV Score: 0.524923076923077\n",
      "GradientBoosting - Mean Confusion Matrix:\n",
      "[[6.7 5.9]\n",
      " [6.4 6.9]]\n",
      "AdaBoost - Mean CV Score: 0.5209230769230769\n",
      "AdaBoost - Mean Confusion Matrix:\n",
      "[[6.4 6.2]\n",
      " [6.2 7.1]]\n",
      "NaiveBayes - Mean CV Score: 0.5636923076923077\n",
      "NaiveBayes - Mean Confusion Matrix:\n",
      "[[6.8 5.8]\n",
      " [5.5 7.8]]\n",
      "DecisionTree - Mean CV Score: 0.5401538461538461\n",
      "DecisionTree - Mean Confusion Matrix:\n",
      "[[7.2 5.4]\n",
      " [6.5 6.8]]\n",
      "ExtraTrees - Mean CV Score: 0.5364615384615385\n",
      "ExtraTrees - Mean Confusion Matrix:\n",
      "[[6.9 5.7]\n",
      " [6.3 7. ]]\n",
      "XGBoost - Mean CV Score: 0.5478461538461539\n",
      "XGBoost - Mean Confusion Matrix:\n",
      "[[6.7 5.9]\n",
      " [5.8 7.5]]\n",
      "Size: bottleneck_26, Best classifier: SVM, CV Score: 0.5907692307692306\n",
      "Epoch 1/40\n",
      "18/26 [===================>..........] - ETA: 0s - loss: 0.0416 \n",
      "Epoch 1: val_loss improved from inf to 0.02685, saving model to model\\DSAE_bottleneck_30_best_model.keras\n",
      "26/26 [==============================] - 1s 13ms/step - loss: 0.0374 - val_loss: 0.0268\n",
      "Epoch 2/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0246\n",
      "Epoch 2: val_loss improved from 0.02685 to 0.02494, saving model to model\\DSAE_bottleneck_30_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0245 - val_loss: 0.0249\n",
      "Epoch 3/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0236\n",
      "Epoch 3: val_loss improved from 0.02494 to 0.02429, saving model to model\\DSAE_bottleneck_30_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0233 - val_loss: 0.0243\n",
      "Epoch 4/40\n",
      "18/26 [===================>..........] - ETA: 0s - loss: 0.0218\n",
      "Epoch 4: val_loss improved from 0.02429 to 0.02396, saving model to model\\DSAE_bottleneck_30_best_model.keras\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 0.0230 - val_loss: 0.0240\n",
      "Epoch 5/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0227\n",
      "Epoch 5: val_loss improved from 0.02396 to 0.02395, saving model to model\\DSAE_bottleneck_30_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0229 - val_loss: 0.0239\n",
      "Epoch 6/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0223\n",
      "Epoch 6: val_loss did not improve from 0.02395\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0228 - val_loss: 0.0240\n",
      "Epoch 7/40\n",
      "21/26 [=======================>......] - ETA: 0s - loss: 0.0221\n",
      "Epoch 7: val_loss improved from 0.02395 to 0.02359, saving model to model\\DSAE_bottleneck_30_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0226 - val_loss: 0.0236\n",
      "Epoch 8/40\n",
      "21/26 [=======================>......] - ETA: 0s - loss: 0.0219\n",
      "Epoch 8: val_loss improved from 0.02359 to 0.02257, saving model to model\\DSAE_bottleneck_30_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0222 - val_loss: 0.0226\n",
      "Epoch 9/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0208\n",
      "Epoch 9: val_loss improved from 0.02257 to 0.02094, saving model to model\\DSAE_bottleneck_30_best_model.keras\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0205 - val_loss: 0.0209\n",
      "Epoch 10/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0199\n",
      "Epoch 10: val_loss improved from 0.02094 to 0.02056, saving model to model\\DSAE_bottleneck_30_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0197 - val_loss: 0.0206\n",
      "Epoch 11/40\n",
      "21/26 [=======================>......] - ETA: 0s - loss: 0.0191\n",
      "Epoch 11: val_loss improved from 0.02056 to 0.02049, saving model to model\\DSAE_bottleneck_30_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0194 - val_loss: 0.0205\n",
      "Epoch 12/40\n",
      "21/26 [=======================>......] - ETA: 0s - loss: 0.0192\n",
      "Epoch 12: val_loss did not improve from 0.02049\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0193 - val_loss: 0.0208\n",
      "Epoch 13/40\n",
      "21/26 [=======================>......] - ETA: 0s - loss: 0.0193\n",
      "Epoch 13: val_loss improved from 0.02049 to 0.02027, saving model to model\\DSAE_bottleneck_30_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0193 - val_loss: 0.0203\n",
      "Epoch 14/40\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0191\n",
      "Epoch 14: val_loss did not improve from 0.02027\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0191 - val_loss: 0.0203\n",
      "Epoch 15/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0189\n",
      "Epoch 15: val_loss improved from 0.02027 to 0.02015, saving model to model\\DSAE_bottleneck_30_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0191 - val_loss: 0.0202\n",
      "Epoch 16/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0191\n",
      "Epoch 16: val_loss did not improve from 0.02015\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0190 - val_loss: 0.0202\n",
      "Epoch 17/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0189\n",
      "Epoch 17: val_loss did not improve from 0.02015\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0190 - val_loss: 0.0202\n",
      "Epoch 18/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0187\n",
      "Epoch 18: val_loss did not improve from 0.02015\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0189 - val_loss: 0.0202\n",
      "Epoch 19/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0189\n",
      "Epoch 19: val_loss improved from 0.02015 to 0.02014, saving model to model\\DSAE_bottleneck_30_best_model.keras\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 0.0188 - val_loss: 0.0201\n",
      "Epoch 20/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0186\n",
      "Epoch 20: val_loss did not improve from 0.02014\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0189 - val_loss: 0.0203\n",
      "Epoch 21/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0188\n",
      "Epoch 21: val_loss did not improve from 0.02014\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0188 - val_loss: 0.0202\n",
      "Epoch 22/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0185\n",
      "Epoch 22: val_loss did not improve from 0.02014\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0187 - val_loss: 0.0202\n",
      "Epoch 23/40\n",
      "12/26 [============>.................] - ETA: 0s - loss: 0.0195\n",
      "Epoch 23: val_loss did not improve from 0.02014\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0187 - val_loss: 0.0202\n",
      "Epoch 24/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0189\n",
      "Epoch 24: val_loss did not improve from 0.02014\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0187 - val_loss: 0.0202\n",
      "Epoch 25/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0188\n",
      "Epoch 25: val_loss did not improve from 0.02014\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0187 - val_loss: 0.0202\n",
      "Epoch 26/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0188\n",
      "Epoch 26: val_loss did not improve from 0.02014\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0186 - val_loss: 0.0202\n",
      "Epoch 27/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0187\n",
      "Epoch 27: val_loss improved from 0.02014 to 0.02010, saving model to model\\DSAE_bottleneck_30_best_model.keras\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0186 - val_loss: 0.0201\n",
      "Epoch 28/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0185\n",
      "Epoch 28: val_loss improved from 0.02010 to 0.02008, saving model to model\\DSAE_bottleneck_30_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0187 - val_loss: 0.0201\n",
      "Epoch 29/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0183\n",
      "Epoch 29: val_loss did not improve from 0.02008\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0186 - val_loss: 0.0202\n",
      "Epoch 30/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0187\n",
      "Epoch 30: val_loss did not improve from 0.02008\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0186 - val_loss: 0.0201\n",
      "Epoch 31/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0185\n",
      "Epoch 31: val_loss did not improve from 0.02008\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0186 - val_loss: 0.0201\n",
      "Epoch 32/40\n",
      "16/26 [=================>............] - ETA: 0s - loss: 0.0181\n",
      "Epoch 32: val_loss did not improve from 0.02008\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0186 - val_loss: 0.0203\n",
      "Epoch 33/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0187\n",
      "Epoch 33: val_loss did not improve from 0.02008\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0185 - val_loss: 0.0201\n",
      "Epoch 34/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0184\n",
      "Epoch 34: val_loss did not improve from 0.02008\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0185 - val_loss: 0.0202\n",
      "Epoch 35/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0182\n",
      "Epoch 35: val_loss did not improve from 0.02008\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0185 - val_loss: 0.0202\n",
      "Epoch 36/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0188\n",
      "Epoch 36: val_loss improved from 0.02008 to 0.02005, saving model to model\\DSAE_bottleneck_30_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0185 - val_loss: 0.0201\n",
      "Epoch 37/40\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0185\n",
      "Epoch 37: val_loss did not improve from 0.02005\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0185 - val_loss: 0.0201\n",
      "Epoch 38/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0182\n",
      "Epoch 38: val_loss did not improve from 0.02005\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0185 - val_loss: 0.0201\n",
      "Epoch 39/40\n",
      "21/26 [=======================>......] - ETA: 0s - loss: 0.0187\n",
      "Epoch 39: val_loss did not improve from 0.02005\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0185 - val_loss: 0.0201\n",
      "Epoch 40/40\n",
      "21/26 [=======================>......] - ETA: 0s - loss: 0.0187\n",
      "Epoch 40: val_loss improved from 0.02005 to 0.02001, saving model to model\\DSAE_bottleneck_30_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0185 - val_loss: 0.0200\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "LogisticRegression - Mean CV Score: 0.4713846153846154\n",
      "LogisticRegression - Mean Confusion Matrix:\n",
      "[[ 1.1 11.5]\n",
      " [ 2.2 11.1]]\n",
      "SVM - Mean CV Score: 0.5486153846153846\n",
      "SVM - Mean Confusion Matrix:\n",
      "[[7.  5.6]\n",
      " [6.1 7.2]]\n",
      "RandomForest - Mean CV Score: 0.5367692307692307\n",
      "RandomForest - Mean Confusion Matrix:\n",
      "[[6.9 5.7]\n",
      " [6.3 7. ]]\n",
      "KNN - Mean CV Score: 0.48246153846153855\n",
      "KNN - Mean Confusion Matrix:\n",
      "[[6.  6.6]\n",
      " [6.8 6.5]]\n",
      "GradientBoosting - Mean CV Score: 0.5483076923076924\n",
      "GradientBoosting - Mean Confusion Matrix:\n",
      "[[7.  5.6]\n",
      " [6.1 7.2]]\n",
      "AdaBoost - Mean CV Score: 0.5209230769230769\n",
      "AdaBoost - Mean Confusion Matrix:\n",
      "[[6.8 5.8]\n",
      " [6.6 6.7]]\n",
      "NaiveBayes - Mean CV Score: 0.5249230769230768\n",
      "NaiveBayes - Mean Confusion Matrix:\n",
      "[[9.4 3.2]\n",
      " [9.1 4.2]]\n",
      "DecisionTree - Mean CV Score: 0.49830769230769223\n",
      "DecisionTree - Mean Confusion Matrix:\n",
      "[[6.6 6. ]\n",
      " [7.  6.3]]\n",
      "ExtraTrees - Mean CV Score: 0.5444615384615386\n",
      "ExtraTrees - Mean Confusion Matrix:\n",
      "[[7.1 5.5]\n",
      " [6.3 7. ]]\n",
      "XGBoost - Mean CV Score: 0.4901538461538462\n",
      "XGBoost - Mean Confusion Matrix:\n",
      "[[5.8 6.8]\n",
      " [6.4 6.9]]\n",
      "Size: bottleneck_30, Best classifier: SVM, CV Score: 0.5486153846153846\n",
      "Epoch 1/40\n",
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0380 \n",
      "Epoch 1: val_loss improved from inf to 0.02636, saving model to model\\DSAE_bottleneck_34_best_model.keras\n",
      "26/26 [==============================] - 1s 12ms/step - loss: 0.0376 - val_loss: 0.0264\n",
      "Epoch 2/40\n",
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0244\n",
      "Epoch 2: val_loss improved from 0.02636 to 0.02509, saving model to model\\DSAE_bottleneck_34_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0245 - val_loss: 0.0251\n",
      "Epoch 3/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0231\n",
      "Epoch 3: val_loss improved from 0.02509 to 0.02447, saving model to model\\DSAE_bottleneck_34_best_model.keras\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 0.0234 - val_loss: 0.0245\n",
      "Epoch 4/40\n",
      "18/26 [===================>..........] - ETA: 0s - loss: 0.0233\n",
      "Epoch 4: val_loss improved from 0.02447 to 0.02397, saving model to model\\DSAE_bottleneck_34_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0230 - val_loss: 0.0240\n",
      "Epoch 5/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0232\n",
      "Epoch 5: val_loss improved from 0.02397 to 0.02395, saving model to model\\DSAE_bottleneck_34_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0228 - val_loss: 0.0239\n",
      "Epoch 6/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0229\n",
      "Epoch 6: val_loss improved from 0.02395 to 0.02393, saving model to model\\DSAE_bottleneck_34_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0228 - val_loss: 0.0239\n",
      "Epoch 7/40\n",
      "21/26 [=======================>......] - ETA: 0s - loss: 0.0229\n",
      "Epoch 7: val_loss improved from 0.02393 to 0.02370, saving model to model\\DSAE_bottleneck_34_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0227 - val_loss: 0.0237\n",
      "Epoch 8/40\n",
      "21/26 [=======================>......] - ETA: 0s - loss: 0.0227\n",
      "Epoch 8: val_loss improved from 0.02370 to 0.02342, saving model to model\\DSAE_bottleneck_34_best_model.keras\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 0.0226 - val_loss: 0.0234\n",
      "Epoch 9/40\n",
      "21/26 [=======================>......] - ETA: 0s - loss: 0.0219\n",
      "Epoch 9: val_loss improved from 0.02342 to 0.02225, saving model to model\\DSAE_bottleneck_34_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0219 - val_loss: 0.0223\n",
      "Epoch 10/40\n",
      "21/26 [=======================>......] - ETA: 0s - loss: 0.0209\n",
      "Epoch 10: val_loss improved from 0.02225 to 0.02106, saving model to model\\DSAE_bottleneck_34_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0204 - val_loss: 0.0211\n",
      "Epoch 11/40\n",
      "19/26 [====================>.........] - ETA: 0s - loss: 0.0199\n",
      "Epoch 11: val_loss improved from 0.02106 to 0.02061, saving model to model\\DSAE_bottleneck_34_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0196 - val_loss: 0.0206\n",
      "Epoch 12/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0193\n",
      "Epoch 12: val_loss improved from 0.02061 to 0.02055, saving model to model\\DSAE_bottleneck_34_best_model.keras\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 0.0194 - val_loss: 0.0205\n",
      "Epoch 13/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0200\n",
      "Epoch 13: val_loss improved from 0.02055 to 0.02054, saving model to model\\DSAE_bottleneck_34_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0193 - val_loss: 0.0205\n",
      "Epoch 14/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0192\n",
      "Epoch 14: val_loss improved from 0.02054 to 0.02044, saving model to model\\DSAE_bottleneck_34_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0193 - val_loss: 0.0204\n",
      "Epoch 15/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0192\n",
      "Epoch 15: val_loss did not improve from 0.02044\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0191 - val_loss: 0.0207\n",
      "Epoch 16/40\n",
      "17/26 [==================>...........] - ETA: 0s - loss: 0.0190\n",
      "Epoch 16: val_loss improved from 0.02044 to 0.02035, saving model to model\\DSAE_bottleneck_34_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0191 - val_loss: 0.0204\n",
      "Epoch 17/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0190\n",
      "Epoch 17: val_loss did not improve from 0.02035\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0190 - val_loss: 0.0204\n",
      "Epoch 18/40\n",
      "21/26 [=======================>......] - ETA: 0s - loss: 0.0182\n",
      "Epoch 18: val_loss improved from 0.02035 to 0.02032, saving model to model\\DSAE_bottleneck_34_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0189 - val_loss: 0.0203\n",
      "Epoch 19/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0189\n",
      "Epoch 19: val_loss improved from 0.02032 to 0.02027, saving model to model\\DSAE_bottleneck_34_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0189 - val_loss: 0.0203\n",
      "Epoch 20/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0190\n",
      "Epoch 20: val_loss did not improve from 0.02027\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0189 - val_loss: 0.0204\n",
      "Epoch 21/40\n",
      "21/26 [=======================>......] - ETA: 0s - loss: 0.0186\n",
      "Epoch 21: val_loss did not improve from 0.02027\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0189 - val_loss: 0.0205\n",
      "Epoch 22/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0187\n",
      "Epoch 22: val_loss did not improve from 0.02027\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0188 - val_loss: 0.0204\n",
      "Epoch 23/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0190\n",
      "Epoch 23: val_loss did not improve from 0.02027\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0188 - val_loss: 0.0204\n",
      "Epoch 24/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0183\n",
      "Epoch 24: val_loss did not improve from 0.02027\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0188 - val_loss: 0.0204\n",
      "Epoch 25/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0189\n",
      "Epoch 25: val_loss did not improve from 0.02027\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0188 - val_loss: 0.0204\n",
      "Epoch 26/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0189\n",
      "Epoch 26: val_loss did not improve from 0.02027\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0188 - val_loss: 0.0204\n",
      "Epoch 27/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0189\n",
      "Epoch 27: val_loss did not improve from 0.02027\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0187 - val_loss: 0.0204\n",
      "Epoch 28/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0186\n",
      "Epoch 28: val_loss did not improve from 0.02027\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0187 - val_loss: 0.0204\n",
      "Epoch 29/40\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0187\n",
      "Epoch 29: val_loss did not improve from 0.02027\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0187 - val_loss: 0.0206\n",
      "Epoch 30/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0187\n",
      "Epoch 30: val_loss did not improve from 0.02027\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0187 - val_loss: 0.0204\n",
      "Epoch 31/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0187\n",
      "Epoch 31: val_loss did not improve from 0.02027\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0187 - val_loss: 0.0206\n",
      "Epoch 32/40\n",
      "21/26 [=======================>......] - ETA: 0s - loss: 0.0184\n",
      "Epoch 32: val_loss did not improve from 0.02027\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0187 - val_loss: 0.0205\n",
      "Epoch 33/40\n",
      "14/26 [===============>..............] - ETA: 0s - loss: 0.0190\n",
      "Epoch 33: val_loss did not improve from 0.02027\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0187 - val_loss: 0.0204\n",
      "Epoch 34/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0186\n",
      "Epoch 34: val_loss did not improve from 0.02027\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0186 - val_loss: 0.0203\n",
      "Epoch 35/40\n",
      "21/26 [=======================>......] - ETA: 0s - loss: 0.0184\n",
      "Epoch 35: val_loss did not improve from 0.02027\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0186 - val_loss: 0.0205\n",
      "Epoch 36/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0189\n",
      "Epoch 36: val_loss did not improve from 0.02027\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0186 - val_loss: 0.0205\n",
      "Epoch 37/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0183\n",
      "Epoch 37: val_loss did not improve from 0.02027\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0186 - val_loss: 0.0204\n",
      "Epoch 38/40\n",
      "17/26 [==================>...........] - ETA: 0s - loss: 0.0177\n",
      "Epoch 38: val_loss did not improve from 0.02027\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0186 - val_loss: 0.0204\n",
      "Epoch 39/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0186\n",
      "Epoch 39: val_loss did not improve from 0.02027\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0185 - val_loss: 0.0204\n",
      "Epoch 40/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0189\n",
      "Epoch 40: val_loss did not improve from 0.02027\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0186 - val_loss: 0.0205\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "LogisticRegression - Mean CV Score: 0.4713846153846154\n",
      "LogisticRegression - Mean Confusion Matrix:\n",
      "[[ 2.2 10.4]\n",
      " [ 3.3 10. ]]\n",
      "SVM - Mean CV Score: 0.4983076923076924\n",
      "SVM - Mean Confusion Matrix:\n",
      "[[6.  6.6]\n",
      " [6.4 6.9]]\n",
      "RandomForest - Mean CV Score: 0.5138461538461538\n",
      "RandomForest - Mean Confusion Matrix:\n",
      "[[6.4 6.2]\n",
      " [6.4 6.9]]\n",
      "KNN - Mean CV Score: 0.5521538461538462\n",
      "KNN - Mean Confusion Matrix:\n",
      "[[6.9 5.7]\n",
      " [5.9 7.4]]\n",
      "GradientBoosting - Mean CV Score: 0.5138461538461538\n",
      "GradientBoosting - Mean Confusion Matrix:\n",
      "[[6.4 6.2]\n",
      " [6.4 6.9]]\n",
      "AdaBoost - Mean CV Score: 0.46353846153846145\n",
      "AdaBoost - Mean Confusion Matrix:\n",
      "[[5.8 6.8]\n",
      " [7.1 6.2]]\n",
      "NaiveBayes - Mean CV Score: 0.5021538461538462\n",
      "NaiveBayes - Mean Confusion Matrix:\n",
      "[[8.8 3.8]\n",
      " [9.1 4.2]]\n",
      "DecisionTree - Mean CV Score: 0.5024615384615385\n",
      "DecisionTree - Mean Confusion Matrix:\n",
      "[[6.2 6.4]\n",
      " [6.5 6.8]]\n",
      "ExtraTrees - Mean CV Score: 0.5064615384615385\n",
      "ExtraTrees - Mean Confusion Matrix:\n",
      "[[6.3 6.3]\n",
      " [6.5 6.8]]\n",
      "XGBoost - Mean CV Score: 0.4903076923076924\n",
      "XGBoost - Mean Confusion Matrix:\n",
      "[[5.7 6.9]\n",
      " [6.3 7. ]]\n",
      "Size: bottleneck_34, Best classifier: KNN, CV Score: 0.5521538461538462\n",
      "Epoch 1/40\n",
      "19/26 [====================>.........] - ETA: 0s - loss: 0.0398 \n",
      "Epoch 1: val_loss improved from inf to 0.02698, saving model to model\\DSAE_bottleneck_38_best_model.keras\n",
      "26/26 [==============================] - 1s 14ms/step - loss: 0.0357 - val_loss: 0.0270\n",
      "Epoch 2/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0251\n",
      "Epoch 2: val_loss improved from 0.02698 to 0.02545, saving model to model\\DSAE_bottleneck_38_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0246 - val_loss: 0.0255\n",
      "Epoch 3/40\n",
      "14/26 [===============>..............] - ETA: 0s - loss: 0.0230\n",
      "Epoch 3: val_loss improved from 0.02545 to 0.02469, saving model to model\\DSAE_bottleneck_38_best_model.keras\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 0.0236 - val_loss: 0.0247\n",
      "Epoch 4/40\n",
      "17/26 [==================>...........] - ETA: 0s - loss: 0.0234\n",
      "Epoch 4: val_loss improved from 0.02469 to 0.02447, saving model to model\\DSAE_bottleneck_38_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0232 - val_loss: 0.0245\n",
      "Epoch 5/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0226\n",
      "Epoch 5: val_loss improved from 0.02447 to 0.02418, saving model to model\\DSAE_bottleneck_38_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0230 - val_loss: 0.0242\n",
      "Epoch 6/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0229\n",
      "Epoch 6: val_loss improved from 0.02418 to 0.02392, saving model to model\\DSAE_bottleneck_38_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0228 - val_loss: 0.0239\n",
      "Epoch 7/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0228\n",
      "Epoch 7: val_loss improved from 0.02392 to 0.02376, saving model to model\\DSAE_bottleneck_38_best_model.keras\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 0.0226 - val_loss: 0.0238\n",
      "Epoch 8/40\n",
      "21/26 [=======================>......] - ETA: 0s - loss: 0.0216\n",
      "Epoch 8: val_loss improved from 0.02376 to 0.02348, saving model to model\\DSAE_bottleneck_38_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0225 - val_loss: 0.0235\n",
      "Epoch 9/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0224\n",
      "Epoch 9: val_loss improved from 0.02348 to 0.02181, saving model to model\\DSAE_bottleneck_38_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0218 - val_loss: 0.0218\n",
      "Epoch 10/40\n",
      "21/26 [=======================>......] - ETA: 0s - loss: 0.0199\n",
      "Epoch 10: val_loss improved from 0.02181 to 0.02095, saving model to model\\DSAE_bottleneck_38_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0201 - val_loss: 0.0209\n",
      "Epoch 11/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0198\n",
      "Epoch 11: val_loss improved from 0.02095 to 0.02062, saving model to model\\DSAE_bottleneck_38_best_model.keras\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 0.0196 - val_loss: 0.0206\n",
      "Epoch 12/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0197\n",
      "Epoch 12: val_loss improved from 0.02062 to 0.02051, saving model to model\\DSAE_bottleneck_38_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0194 - val_loss: 0.0205\n",
      "Epoch 13/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0192\n",
      "Epoch 13: val_loss improved from 0.02051 to 0.02048, saving model to model\\DSAE_bottleneck_38_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0193 - val_loss: 0.0205\n",
      "Epoch 14/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0193\n",
      "Epoch 14: val_loss improved from 0.02048 to 0.02041, saving model to model\\DSAE_bottleneck_38_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0192 - val_loss: 0.0204\n",
      "Epoch 15/40\n",
      "14/26 [===============>..............] - ETA: 0s - loss: 0.0188\n",
      "Epoch 15: val_loss did not improve from 0.02041\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0192 - val_loss: 0.0204\n",
      "Epoch 16/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0191\n",
      "Epoch 16: val_loss improved from 0.02041 to 0.02035, saving model to model\\DSAE_bottleneck_38_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0192 - val_loss: 0.0203\n",
      "Epoch 17/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0191\n",
      "Epoch 17: val_loss did not improve from 0.02035\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0190 - val_loss: 0.0204\n",
      "Epoch 18/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0193\n",
      "Epoch 18: val_loss improved from 0.02035 to 0.02033, saving model to model\\DSAE_bottleneck_38_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0190 - val_loss: 0.0203\n",
      "Epoch 19/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0189\n",
      "Epoch 19: val_loss did not improve from 0.02033\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0189 - val_loss: 0.0204\n",
      "Epoch 20/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0191\n",
      "Epoch 20: val_loss did not improve from 0.02033\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0190 - val_loss: 0.0208\n",
      "Epoch 21/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0192\n",
      "Epoch 21: val_loss improved from 0.02033 to 0.02029, saving model to model\\DSAE_bottleneck_38_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0190 - val_loss: 0.0203\n",
      "Epoch 22/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0187\n",
      "Epoch 22: val_loss did not improve from 0.02029\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0189 - val_loss: 0.0204\n",
      "Epoch 23/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0186\n",
      "Epoch 23: val_loss improved from 0.02029 to 0.02025, saving model to model\\DSAE_bottleneck_38_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0188 - val_loss: 0.0202\n",
      "Epoch 24/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0186\n",
      "Epoch 24: val_loss did not improve from 0.02025\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0188 - val_loss: 0.0203\n",
      "Epoch 25/40\n",
      "21/26 [=======================>......] - ETA: 0s - loss: 0.0189\n",
      "Epoch 25: val_loss improved from 0.02025 to 0.02025, saving model to model\\DSAE_bottleneck_38_best_model.keras\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0188 - val_loss: 0.0202\n",
      "Epoch 26/40\n",
      "21/26 [=======================>......] - ETA: 0s - loss: 0.0184\n",
      "Epoch 26: val_loss improved from 0.02025 to 0.02024, saving model to model\\DSAE_bottleneck_38_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0187 - val_loss: 0.0202\n",
      "Epoch 27/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0185\n",
      "Epoch 27: val_loss did not improve from 0.02024\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0188 - val_loss: 0.0203\n",
      "Epoch 28/40\n",
      "20/26 [======================>.......] - ETA: 0s - loss: 0.0186\n",
      "Epoch 28: val_loss improved from 0.02024 to 0.02020, saving model to model\\DSAE_bottleneck_38_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0186 - val_loss: 0.0202\n",
      "Epoch 29/40\n",
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0188\n",
      "Epoch 29: val_loss did not improve from 0.02020\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0187 - val_loss: 0.0203\n",
      "Epoch 30/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0183\n",
      "Epoch 30: val_loss improved from 0.02020 to 0.02014, saving model to model\\DSAE_bottleneck_38_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0187 - val_loss: 0.0201\n",
      "Epoch 31/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0188\n",
      "Epoch 31: val_loss improved from 0.02014 to 0.02013, saving model to model\\DSAE_bottleneck_38_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0186 - val_loss: 0.0201\n",
      "Epoch 32/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0186\n",
      "Epoch 32: val_loss did not improve from 0.02013\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0186 - val_loss: 0.0201\n",
      "Epoch 33/40\n",
      "13/26 [==============>...............] - ETA: 0s - loss: 0.0198\n",
      "Epoch 33: val_loss improved from 0.02013 to 0.02002, saving model to model\\DSAE_bottleneck_38_best_model.keras\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0185 - val_loss: 0.0200\n",
      "Epoch 34/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0183\n",
      "Epoch 34: val_loss did not improve from 0.02002\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0186 - val_loss: 0.0202\n",
      "Epoch 35/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0184\n",
      "Epoch 35: val_loss did not improve from 0.02002\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0186 - val_loss: 0.0202\n",
      "Epoch 36/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0187\n",
      "Epoch 36: val_loss improved from 0.02002 to 0.02002, saving model to model\\DSAE_bottleneck_38_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0185 - val_loss: 0.0200\n",
      "Epoch 37/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0187\n",
      "Epoch 37: val_loss did not improve from 0.02002\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0186 - val_loss: 0.0201\n",
      "Epoch 38/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0180\n",
      "Epoch 38: val_loss did not improve from 0.02002\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0185 - val_loss: 0.0200\n",
      "Epoch 39/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0187\n",
      "Epoch 39: val_loss improved from 0.02002 to 0.01997, saving model to model\\DSAE_bottleneck_38_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0185 - val_loss: 0.0200\n",
      "Epoch 40/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0187\n",
      "Epoch 40: val_loss improved from 0.01997 to 0.01994, saving model to model\\DSAE_bottleneck_38_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0185 - val_loss: 0.0199\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "LogisticRegression - Mean CV Score: 0.45215384615384624\n",
      "LogisticRegression - Mean Confusion Matrix:\n",
      "[[ 1.4 11.2]\n",
      " [ 3.  10.3]]\n",
      "SVM - Mean CV Score: 0.5676923076923077\n",
      "SVM - Mean Confusion Matrix:\n",
      "[[7.6 5. ]\n",
      " [6.2 7.1]]\n",
      "RandomForest - Mean CV Score: 0.5287692307692309\n",
      "RandomForest - Mean Confusion Matrix:\n",
      "[[6.4 6.2]\n",
      " [6.  7.3]]\n",
      "KNN - Mean CV Score: 0.533076923076923\n",
      "KNN - Mean Confusion Matrix:\n",
      "[[6.6 6. ]\n",
      " [6.1 7.2]]\n",
      "GradientBoosting - Mean CV Score: 0.5638461538461538\n",
      "GradientBoosting - Mean Confusion Matrix:\n",
      "[[7.2 5.4]\n",
      " [5.9 7.4]]\n",
      "AdaBoost - Mean CV Score: 0.5950769230769231\n",
      "AdaBoost - Mean Confusion Matrix:\n",
      "[[7.5 5.1]\n",
      " [5.4 7.9]]\n",
      "NaiveBayes - Mean CV Score: 0.5443076923076923\n",
      "NaiveBayes - Mean Confusion Matrix:\n",
      "[[10.1  2.5]\n",
      " [ 9.3  4. ]]\n",
      "DecisionTree - Mean CV Score: 0.5287692307692307\n",
      "DecisionTree - Mean Confusion Matrix:\n",
      "[[6.2 6.4]\n",
      " [5.8 7.5]]\n",
      "ExtraTrees - Mean CV Score: 0.5332307692307692\n",
      "ExtraTrees - Mean Confusion Matrix:\n",
      "[[6.7 5.9]\n",
      " [6.2 7.1]]\n",
      "XGBoost - Mean CV Score: 0.5635384615384614\n",
      "XGBoost - Mean Confusion Matrix:\n",
      "[[6.9 5.7]\n",
      " [5.6 7.7]]\n",
      "Size: bottleneck_38, Best classifier: AdaBoost, CV Score: 0.5950769230769231\n",
      "Epoch 1/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0400 \n",
      "Epoch 1: val_loss improved from inf to 0.02747, saving model to model\\DSAE_bottleneck_42_best_model.keras\n",
      "26/26 [==============================] - 1s 12ms/step - loss: 0.0381 - val_loss: 0.0275\n",
      "Epoch 2/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0248\n",
      "Epoch 2: val_loss improved from 0.02747 to 0.02528, saving model to model\\DSAE_bottleneck_42_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0247 - val_loss: 0.0253\n",
      "Epoch 3/40\n",
      "15/26 [================>.............] - ETA: 0s - loss: 0.0243\n",
      "Epoch 3: val_loss improved from 0.02528 to 0.02432, saving model to model\\DSAE_bottleneck_42_best_model.keras\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 0.0234 - val_loss: 0.0243\n",
      "Epoch 4/40\n",
      "17/26 [==================>...........] - ETA: 0s - loss: 0.0230\n",
      "Epoch 4: val_loss improved from 0.02432 to 0.02417, saving model to model\\DSAE_bottleneck_42_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0230 - val_loss: 0.0242\n",
      "Epoch 5/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0230\n",
      "Epoch 5: val_loss improved from 0.02417 to 0.02401, saving model to model\\DSAE_bottleneck_42_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0228 - val_loss: 0.0240\n",
      "Epoch 6/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0222\n",
      "Epoch 6: val_loss improved from 0.02401 to 0.02244, saving model to model\\DSAE_bottleneck_42_best_model.keras\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0221 - val_loss: 0.0224\n",
      "Epoch 7/40\n",
      "20/26 [======================>.......] - ETA: 0s - loss: 0.0206\n",
      "Epoch 7: val_loss improved from 0.02244 to 0.02121, saving model to model\\DSAE_bottleneck_42_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0205 - val_loss: 0.0212\n",
      "Epoch 8/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0199\n",
      "Epoch 8: val_loss improved from 0.02121 to 0.02085, saving model to model\\DSAE_bottleneck_42_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0198 - val_loss: 0.0208\n",
      "Epoch 9/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0197\n",
      "Epoch 9: val_loss improved from 0.02085 to 0.02067, saving model to model\\DSAE_bottleneck_42_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0195 - val_loss: 0.0207\n",
      "Epoch 10/40\n",
      "21/26 [=======================>......] - ETA: 0s - loss: 0.0195\n",
      "Epoch 10: val_loss improved from 0.02067 to 0.02067, saving model to model\\DSAE_bottleneck_42_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0193 - val_loss: 0.0207\n",
      "Epoch 11/40\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0193\n",
      "Epoch 11: val_loss improved from 0.02067 to 0.02062, saving model to model\\DSAE_bottleneck_42_best_model.keras\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 0.0193 - val_loss: 0.0206\n",
      "Epoch 12/40\n",
      "19/26 [====================>.........] - ETA: 0s - loss: 0.0197\n",
      "Epoch 12: val_loss did not improve from 0.02062\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0192 - val_loss: 0.0207\n",
      "Epoch 13/40\n",
      "20/26 [======================>.......] - ETA: 0s - loss: 0.0193\n",
      "Epoch 13: val_loss improved from 0.02062 to 0.02061, saving model to model\\DSAE_bottleneck_42_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0192 - val_loss: 0.0206\n",
      "Epoch 14/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0193\n",
      "Epoch 14: val_loss improved from 0.02061 to 0.02042, saving model to model\\DSAE_bottleneck_42_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0191 - val_loss: 0.0204\n",
      "Epoch 15/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0190\n",
      "Epoch 15: val_loss did not improve from 0.02042\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0190 - val_loss: 0.0204\n",
      "Epoch 16/40\n",
      "21/26 [=======================>......] - ETA: 0s - loss: 0.0188\n",
      "Epoch 16: val_loss did not improve from 0.02042\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0191 - val_loss: 0.0206\n",
      "Epoch 17/40\n",
      "21/26 [=======================>......] - ETA: 0s - loss: 0.0190\n",
      "Epoch 17: val_loss improved from 0.02042 to 0.02036, saving model to model\\DSAE_bottleneck_42_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0189 - val_loss: 0.0204\n",
      "Epoch 18/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0189\n",
      "Epoch 18: val_loss improved from 0.02036 to 0.02032, saving model to model\\DSAE_bottleneck_42_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0187 - val_loss: 0.0203\n",
      "Epoch 19/40\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0187\n",
      "Epoch 19: val_loss did not improve from 0.02032\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0187 - val_loss: 0.0205\n",
      "Epoch 20/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0191\n",
      "Epoch 20: val_loss improved from 0.02032 to 0.02029, saving model to model\\DSAE_bottleneck_42_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0188 - val_loss: 0.0203\n",
      "Epoch 21/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0186\n",
      "Epoch 21: val_loss did not improve from 0.02029\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0187 - val_loss: 0.0203\n",
      "Epoch 22/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0186\n",
      "Epoch 22: val_loss improved from 0.02029 to 0.02024, saving model to model\\DSAE_bottleneck_42_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0186 - val_loss: 0.0202\n",
      "Epoch 23/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0182\n",
      "Epoch 23: val_loss did not improve from 0.02024\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0185 - val_loss: 0.0203\n",
      "Epoch 24/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0186\n",
      "Epoch 24: val_loss improved from 0.02024 to 0.02017, saving model to model\\DSAE_bottleneck_42_best_model.keras\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 0.0185 - val_loss: 0.0202\n",
      "Epoch 25/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0183\n",
      "Epoch 25: val_loss did not improve from 0.02017\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0185 - val_loss: 0.0203\n",
      "Epoch 26/40\n",
      "21/26 [=======================>......] - ETA: 0s - loss: 0.0183\n",
      "Epoch 26: val_loss did not improve from 0.02017\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0185 - val_loss: 0.0202\n",
      "Epoch 27/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0186\n",
      "Epoch 27: val_loss improved from 0.02017 to 0.02012, saving model to model\\DSAE_bottleneck_42_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0184 - val_loss: 0.0201\n",
      "Epoch 28/40\n",
      "17/26 [==================>...........] - ETA: 0s - loss: 0.0185\n",
      "Epoch 28: val_loss improved from 0.02012 to 0.01987, saving model to model\\DSAE_bottleneck_42_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0183 - val_loss: 0.0199\n",
      "Epoch 29/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0180\n",
      "Epoch 29: val_loss improved from 0.01987 to 0.01968, saving model to model\\DSAE_bottleneck_42_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0181 - val_loss: 0.0197\n",
      "Epoch 30/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0181\n",
      "Epoch 30: val_loss improved from 0.01968 to 0.01945, saving model to model\\DSAE_bottleneck_42_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0179 - val_loss: 0.0195\n",
      "Epoch 31/40\n",
      "20/26 [======================>.......] - ETA: 0s - loss: 0.0175\n",
      "Epoch 31: val_loss improved from 0.01945 to 0.01923, saving model to model\\DSAE_bottleneck_42_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0177 - val_loss: 0.0192\n",
      "Epoch 32/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0177\n",
      "Epoch 32: val_loss improved from 0.01923 to 0.01907, saving model to model\\DSAE_bottleneck_42_best_model.keras\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0175 - val_loss: 0.0191\n",
      "Epoch 33/40\n",
      "20/26 [======================>.......] - ETA: 0s - loss: 0.0177\n",
      "Epoch 33: val_loss did not improve from 0.01907\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0176 - val_loss: 0.0193\n",
      "Epoch 34/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0174\n",
      "Epoch 34: val_loss improved from 0.01907 to 0.01898, saving model to model\\DSAE_bottleneck_42_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0174 - val_loss: 0.0190\n",
      "Epoch 35/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0174\n",
      "Epoch 35: val_loss did not improve from 0.01898\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0173 - val_loss: 0.0190\n",
      "Epoch 36/40\n",
      "17/26 [==================>...........] - ETA: 0s - loss: 0.0175\n",
      "Epoch 36: val_loss improved from 0.01898 to 0.01869, saving model to model\\DSAE_bottleneck_42_best_model.keras\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0172 - val_loss: 0.0187\n",
      "Epoch 37/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0168\n",
      "Epoch 37: val_loss improved from 0.01869 to 0.01853, saving model to model\\DSAE_bottleneck_42_best_model.keras\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 0.0169 - val_loss: 0.0185\n",
      "Epoch 38/40\n",
      "21/26 [=======================>......] - ETA: 0s - loss: 0.0169\n",
      "Epoch 38: val_loss did not improve from 0.01853\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0168 - val_loss: 0.0188\n",
      "Epoch 39/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0168\n",
      "Epoch 39: val_loss improved from 0.01853 to 0.01848, saving model to model\\DSAE_bottleneck_42_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0167 - val_loss: 0.0185\n",
      "Epoch 40/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0161\n",
      "Epoch 40: val_loss improved from 0.01848 to 0.01844, saving model to model\\DSAE_bottleneck_42_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0166 - val_loss: 0.0184\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "LogisticRegression - Mean CV Score: 0.4712307692307691\n",
      "LogisticRegression - Mean Confusion Matrix:\n",
      "[[4.5 8.1]\n",
      " [5.6 7.7]]\n",
      "SVM - Mean CV Score: 0.5406153846153845\n",
      "SVM - Mean Confusion Matrix:\n",
      "[[8.1 4.5]\n",
      " [7.4 5.9]]\n",
      "RandomForest - Mean CV Score: 0.5444615384615386\n",
      "RandomForest - Mean Confusion Matrix:\n",
      "[[6.2 6.4]\n",
      " [5.4 7.9]]\n",
      "KNN - Mean CV Score: 0.5176923076923077\n",
      "KNN - Mean Confusion Matrix:\n",
      "[[6.1 6.5]\n",
      " [6.  7.3]]\n",
      "GradientBoosting - Mean CV Score: 0.5636923076923077\n",
      "GradientBoosting - Mean Confusion Matrix:\n",
      "[[6.6 6. ]\n",
      " [5.3 8. ]]\n",
      "AdaBoost - Mean CV Score: 0.5101538461538461\n",
      "AdaBoost - Mean Confusion Matrix:\n",
      "[[5.8 6.8]\n",
      " [5.9 7.4]]\n",
      "NaiveBayes - Mean CV Score: 0.5444615384615383\n",
      "NaiveBayes - Mean Confusion Matrix:\n",
      "[[9.1 3.5]\n",
      " [8.3 5. ]]\n",
      "DecisionTree - Mean CV Score: 0.5796923076923077\n",
      "DecisionTree - Mean Confusion Matrix:\n",
      "[[6.5 6.1]\n",
      " [4.8 8.5]]\n",
      "ExtraTrees - Mean CV Score: 0.564\n",
      "ExtraTrees - Mean Confusion Matrix:\n",
      "[[6.5 6.1]\n",
      " [5.2 8.1]]\n",
      "XGBoost - Mean CV Score: 0.5715384615384614\n",
      "XGBoost - Mean Confusion Matrix:\n",
      "[[6.7 5.9]\n",
      " [5.2 8.1]]\n",
      "Size: bottleneck_42, Best classifier: DecisionTree, CV Score: 0.5796923076923077\n",
      "Epoch 1/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0420 \n",
      "Epoch 1: val_loss improved from inf to 0.02943, saving model to model\\DSAE_bottleneck_46_best_model.keras\n",
      "26/26 [==============================] - 1s 13ms/step - loss: 0.0407 - val_loss: 0.0294\n",
      "Epoch 2/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0245\n",
      "Epoch 2: val_loss improved from 0.02943 to 0.02532, saving model to model\\DSAE_bottleneck_46_best_model.keras\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0246 - val_loss: 0.0253\n",
      "Epoch 3/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0241\n",
      "Epoch 3: val_loss improved from 0.02532 to 0.02478, saving model to model\\DSAE_bottleneck_46_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0236 - val_loss: 0.0248\n",
      "Epoch 4/40\n",
      "20/26 [======================>.......] - ETA: 0s - loss: 0.0233\n",
      "Epoch 4: val_loss improved from 0.02478 to 0.02422, saving model to model\\DSAE_bottleneck_46_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0231 - val_loss: 0.0242\n",
      "Epoch 5/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0226\n",
      "Epoch 5: val_loss improved from 0.02422 to 0.02394, saving model to model\\DSAE_bottleneck_46_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0229 - val_loss: 0.0239\n",
      "Epoch 6/40\n",
      "15/26 [================>.............] - ETA: 0s - loss: 0.0229\n",
      "Epoch 6: val_loss improved from 0.02394 to 0.02376, saving model to model\\DSAE_bottleneck_46_best_model.keras\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0227 - val_loss: 0.0238\n",
      "Epoch 7/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0222\n",
      "Epoch 7: val_loss improved from 0.02376 to 0.02214, saving model to model\\DSAE_bottleneck_46_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0221 - val_loss: 0.0221\n",
      "Epoch 8/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0205\n",
      "Epoch 8: val_loss improved from 0.02214 to 0.02093, saving model to model\\DSAE_bottleneck_46_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0204 - val_loss: 0.0209\n",
      "Epoch 9/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0198\n",
      "Epoch 9: val_loss improved from 0.02093 to 0.02053, saving model to model\\DSAE_bottleneck_46_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0196 - val_loss: 0.0205\n",
      "Epoch 10/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0192\n",
      "Epoch 10: val_loss improved from 0.02053 to 0.02047, saving model to model\\DSAE_bottleneck_46_best_model.keras\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 0.0194 - val_loss: 0.0205\n",
      "Epoch 11/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0193\n",
      "Epoch 11: val_loss improved from 0.02047 to 0.02041, saving model to model\\DSAE_bottleneck_46_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0193 - val_loss: 0.0204\n",
      "Epoch 12/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0190\n",
      "Epoch 12: val_loss improved from 0.02041 to 0.02033, saving model to model\\DSAE_bottleneck_46_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0192 - val_loss: 0.0203\n",
      "Epoch 13/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0193\n",
      "Epoch 13: val_loss did not improve from 0.02033\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0191 - val_loss: 0.0204\n",
      "Epoch 14/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0187\n",
      "Epoch 14: val_loss did not improve from 0.02033\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0191 - val_loss: 0.0204\n",
      "Epoch 15/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0195\n",
      "Epoch 15: val_loss did not improve from 0.02033\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0191 - val_loss: 0.0204\n",
      "Epoch 16/40\n",
      "21/26 [=======================>......] - ETA: 0s - loss: 0.0188\n",
      "Epoch 16: val_loss improved from 0.02033 to 0.02033, saving model to model\\DSAE_bottleneck_46_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0190 - val_loss: 0.0203\n",
      "Epoch 17/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0192\n",
      "Epoch 17: val_loss improved from 0.02033 to 0.02029, saving model to model\\DSAE_bottleneck_46_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0190 - val_loss: 0.0203\n",
      "Epoch 18/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0189\n",
      "Epoch 18: val_loss did not improve from 0.02029\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0189 - val_loss: 0.0203\n",
      "Epoch 19/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0190\n",
      "Epoch 19: val_loss did not improve from 0.02029\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0189 - val_loss: 0.0203\n",
      "Epoch 20/40\n",
      "17/26 [==================>...........] - ETA: 0s - loss: 0.0188\n",
      "Epoch 20: val_loss improved from 0.02029 to 0.02028, saving model to model\\DSAE_bottleneck_46_best_model.keras\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0189 - val_loss: 0.0203\n",
      "Epoch 21/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0188\n",
      "Epoch 21: val_loss improved from 0.02028 to 0.02026, saving model to model\\DSAE_bottleneck_46_best_model.keras\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0188 - val_loss: 0.0203\n",
      "Epoch 22/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0189\n",
      "Epoch 22: val_loss did not improve from 0.02026\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0188 - val_loss: 0.0203\n",
      "Epoch 23/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0189\n",
      "Epoch 23: val_loss did not improve from 0.02026\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0188 - val_loss: 0.0204\n",
      "Epoch 24/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0188\n",
      "Epoch 24: val_loss did not improve from 0.02026\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0189 - val_loss: 0.0203\n",
      "Epoch 25/40\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0187\n",
      "Epoch 25: val_loss did not improve from 0.02026\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0187 - val_loss: 0.0203\n",
      "Epoch 26/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0189\n",
      "Epoch 26: val_loss did not improve from 0.02026\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0187 - val_loss: 0.0203\n",
      "Epoch 27/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0186\n",
      "Epoch 27: val_loss did not improve from 0.02026\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0187 - val_loss: 0.0203\n",
      "Epoch 28/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0187\n",
      "Epoch 28: val_loss did not improve from 0.02026\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0187 - val_loss: 0.0204\n",
      "Epoch 29/40\n",
      "24/26 [==========================>...] - ETA: 0s - loss: 0.0190\n",
      "Epoch 29: val_loss did not improve from 0.02026\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0187 - val_loss: 0.0203\n",
      "Epoch 30/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0185\n",
      "Epoch 30: val_loss did not improve from 0.02026\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0187 - val_loss: 0.0203\n",
      "Epoch 31/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0187\n",
      "Epoch 31: val_loss did not improve from 0.02026\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0187 - val_loss: 0.0203\n",
      "Epoch 32/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0187\n",
      "Epoch 32: val_loss did not improve from 0.02026\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0187 - val_loss: 0.0203\n",
      "Epoch 33/40\n",
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0187\n",
      "Epoch 33: val_loss did not improve from 0.02026\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0186 - val_loss: 0.0203\n",
      "Epoch 34/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0190\n",
      "Epoch 34: val_loss did not improve from 0.02026\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0187 - val_loss: 0.0203\n",
      "Epoch 35/40\n",
      "17/26 [==================>...........] - ETA: 0s - loss: 0.0184\n",
      "Epoch 35: val_loss did not improve from 0.02026\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0187 - val_loss: 0.0204\n",
      "Epoch 36/40\n",
      "20/26 [======================>.......] - ETA: 0s - loss: 0.0189\n",
      "Epoch 36: val_loss did not improve from 0.02026\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0186 - val_loss: 0.0203\n",
      "Epoch 37/40\n",
      "17/26 [==================>...........] - ETA: 0s - loss: 0.0189\n",
      "Epoch 37: val_loss did not improve from 0.02026\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0186 - val_loss: 0.0205\n",
      "Epoch 38/40\n",
      "23/26 [=========================>....] - ETA: 0s - loss: 0.0189\n",
      "Epoch 38: val_loss did not improve from 0.02026\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0186 - val_loss: 0.0203\n",
      "Epoch 39/40\n",
      "22/26 [========================>.....] - ETA: 0s - loss: 0.0185\n",
      "Epoch 39: val_loss did not improve from 0.02026\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0186 - val_loss: 0.0203\n",
      "Epoch 40/40\n",
      "21/26 [=======================>......] - ETA: 0s - loss: 0.0189\n",
      "Epoch 40: val_loss did not improve from 0.02026\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0186 - val_loss: 0.0203\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "LogisticRegression - Mean CV Score: 0.46369230769230774\n",
      "LogisticRegression - Mean Confusion Matrix:\n",
      "[[ 2.1 10.5]\n",
      " [ 3.4  9.9]]\n",
      "SVM - Mean CV Score: 0.5024615384615384\n",
      "SVM - Mean Confusion Matrix:\n",
      "[[6.6 6. ]\n",
      " [6.9 6.4]]\n",
      "RandomForest - Mean CV Score: 0.4866153846153846\n",
      "RandomForest - Mean Confusion Matrix:\n",
      "[[6.2 6.4]\n",
      " [6.9 6.4]]\n",
      "KNN - Mean CV Score: 0.4941538461538462\n",
      "KNN - Mean Confusion Matrix:\n",
      "[[6.3 6.3]\n",
      " [6.8 6.5]]\n",
      "GradientBoosting - Mean CV Score: 0.4903076923076924\n",
      "GradientBoosting - Mean Confusion Matrix:\n",
      "[[5.3 7.3]\n",
      " [5.9 7.4]]\n",
      "AdaBoost - Mean CV Score: 0.4866153846153846\n",
      "AdaBoost - Mean Confusion Matrix:\n",
      "[[5.9 6.7]\n",
      " [6.6 6.7]]\n",
      "NaiveBayes - Mean CV Score: 0.5252307692307692\n",
      "NaiveBayes - Mean Confusion Matrix:\n",
      "[[7.8 4.8]\n",
      " [7.5 5.8]]\n",
      "DecisionTree - Mean CV Score: 0.5058461538461538\n",
      "DecisionTree - Mean Confusion Matrix:\n",
      "[[6.5 6.1]\n",
      " [6.7 6.6]]\n",
      "ExtraTrees - Mean CV Score: 0.4712307692307693\n",
      "ExtraTrees - Mean Confusion Matrix:\n",
      "[[6.3 6.3]\n",
      " [7.4 5.9]]\n",
      "XGBoost - Mean CV Score: 0.5172307692307692\n",
      "XGBoost - Mean Confusion Matrix:\n",
      "[[6.2 6.4]\n",
      " [6.1 7.2]]\n",
      "Size: bottleneck_46, Best classifier: NaiveBayes, CV Score: 0.5252307692307692\n"
     ]
    }
   ],
   "source": [
    "DSAEresults = dispatcher(DSAE,\"DSAE\",6,48)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resources Investigation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ICGC:\n",
    "https://dcc.icgc.org/repositories?filters=%7B%22file%22:%7B%20%22projectCode%22:%7B%22is%22:%5B%22HNSC-US%22%5D%7D%7D%7D\n",
    "\n",
    " Data Type\n",
    " SSM  2,126\n",
    " Aligned Reads  2,037\n",
    " Clinical Data  453\n",
    " Biospecimen Data  448\n",
    " StSM  223\n",
    " SGV  132\n",
    " CNSM  88\n",
    " StGV  88"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TCPA:\n",
    "https://www.tcpaportal.org/tcpa/download.html\n",
    "\n",
    "TCGA of 2018, with L4(normalized across RPPA batches therefore enable pan-cancer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PDC:\n",
    "https://proteomic.datacommons.cancer.gov/pdc/browse\n",
    "3 studies, but Mass Spectrum not RPPA, therefore only contains Peptide result. do have clinincal though"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HNSCC PDX: \n",
    "https://aacrjournals.org/mcr/article/14/3/278/89624/Proteomic-Characterization-of-Head-and-Neck-Cancer\n",
    "RPPA, but on mention how to acess and probabaly wound not have clinical since the read from transplated rats."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HAP: Reference RNA and protein from healthy samples:\n",
    "https://www.proteinatlas.org/about/download"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pride:Full MS sets\n",
    "https://www.ebi.ac.uk/pride/archive?keyword=HNSCC,RPPA&sortDirection=DESC&page=0&pageSize=20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paper HNSCC: RPPA but only target 60 specific protein\n",
    "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3070553/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GEO: Some Protein profiling by protein array (RPPA), no HNSCC\n",
    "https://www.ncbi.nlm.nih.gov/geo/browse/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ArraryExpress: RPPA for GBM, lung cancer, breast cancer\n",
    "https://www.ebi.ac.uk/biostudies/arrayexpress/studies?query=RPPA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FANTOM6 Experiment Index: RNA-Seq\n",
    "https://fantom.gsc.riken.jp/6/experiment_index/#/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resources index: \n",
    "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6971871/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
