{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## todo:\n",
    "KerasTuner Adaption\n",
    "\n",
    "EarlyStopping callback:\n",
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=2)\n",
    "model.fit(x, y, validation_split=0.2, callbacks=[early_stopping])\n",
    "\n",
    "TensorBoard:\n",
    "keras.callbacks.TensorBoard(\n",
    "    log_dir=\"logs\",\n",
    "    histogram_freq=0,\n",
    "    write_graph=True,\n",
    "    write_images=False,\n",
    "    write_steps_per_second=False,\n",
    "    update_freq=\"epoch\",\n",
    "    profile_batch=0,\n",
    "    embeddings_freq=0,\n",
    "    embeddings_metadata=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import layers, models, regularizers\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, ExtraTreesClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import confusion_matrix,classification_report,accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.svm import SVC\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.read_csv('protein_expression.csv')\n",
    "inputed_columns = ['AGID00215',\n",
    " 'AGID00537',\n",
    " 'AGID00536',\n",
    " 'AGID00211',\n",
    " 'AGID00485',\n",
    " 'AGID00383',\n",
    " 'AGID00216',\n",
    " 'AGID00257',\n",
    " 'AGID00545',\n",
    " 'AGID00413',\n",
    " 'AGID00547',\n",
    " 'AGID00144']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['AGID00100', 'AGID00111', 'AGID00101', 'AGID00001', 'AGID00002',\n",
       "       'AGID00003', 'AGID00443', 'AGID00120', 'AGID00004', 'AGID00005',\n",
       "       ...\n",
       "       'AGID00349', 'AGID02137', 'AGID00088', 'AGID00089', 'AGID00504',\n",
       "       'AGID00095', 'AGID02217', 'AGID02210', 'AGID00326', 'AGID00432'],\n",
       "      dtype='object', length=468)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "protein_columns = merged_df.columns.drop([\"ajcc_pathologic_stage\",\"vital_status\",\"days_to_death\",\"days_to_last_follow_up\",\"case_submitter_id\"])\n",
    "protein_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "describe_df = merged_df[protein_columns].describe()\n",
    "row_means = describe_df.loc['mean']\n",
    "\n",
    "# Plot row means\n",
    "plt.figure(figsize=(10, 6))\n",
    "row_means.plot(kind='bar', color='skyblue')\n",
    "plt.title('Feature Means')\n",
    "plt.xlabel('Feature')\n",
    "plt.ylabel('Mean')\n",
    "\n",
    "plt.xticks(range(0, len(row_means), 10), row_means.index[::10], rotation=45, ha='right')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = merged_df.drop([\"ajcc_pathologic_stage\",\"vital_status\",\"days_to_last_follow_up\",\"case_submitter_id\"], axis=1)\n",
    "other = merged_df.columns.drop(\"days_to_death\")\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "merged_df[other] = scaler.fit_transform(merged_df[other])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(merged_df[other], merged_df[\"days_to_death\"],\n",
    "                                                    train_size=0.8,\n",
    "                                                    random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_train.hist(bins=30) \n",
    "plt.xlabel('OS')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of the OS')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AE():\n",
    "    def __init__(self,X_train,X_test,y_train,y_test,bottleneck,size,type):\n",
    "        self.X_train = X_train\n",
    "        self.X_test = X_test        \n",
    "        self.y_train = y_train\n",
    "        self.y_test = y_test\n",
    "        self.bottleneck = bottleneck\n",
    "        self.history = None\n",
    "        self.encoder = None\n",
    "        self.autoencoder = None\n",
    "        self.size = size\n",
    "        self.classifer = None\n",
    "        self.cv_scores = {}\n",
    "        self.type = type\n",
    "\n",
    "    def train(self):\n",
    "    # Number of features in your dataset\n",
    "        n_features = len(self.X_train.columns) \n",
    "\n",
    "\n",
    "        input_layer = Input(shape=(n_features,))\n",
    "        encoder = Dense(64, activation='relu')(input_layer)\n",
    "        encoder = Dense(32, activation='relu')(encoder)\n",
    "\n",
    "\n",
    "        bottleneck = Dense(self.bottleneck, activation='relu')(encoder)  \n",
    "\n",
    "        # Define the decoder (mirror the encoder)\n",
    "        decoder = Dense(32, activation='relu')(bottleneck)\n",
    "        decoder = Dense(64, activation='relu')(decoder)\n",
    "        self.encoder= Model(inputs=input_layer, outputs=bottleneck)\n",
    "\n",
    "        # Output layer\n",
    "        output_layer = Dense(n_features, activation='sigmoid')(decoder) \n",
    "\n",
    "        # Define the autoencoder model\n",
    "        self.autoencoder = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "        # Compile the autoencoder\n",
    "        self.autoencoder.compile(optimizer='Adam', loss='mse')\n",
    "\n",
    "        self.checkpoint = ModelCheckpoint(f'model/{self.type}_{self.size}_best_model.h5', \n",
    "                             monitor='val_loss', \n",
    "                             verbose=1,           \n",
    "                             save_best_only=True, \n",
    "                             mode='min')         \n",
    "\n",
    "        X_train, X_test= train_test_split(self.X_train,\n",
    "                                            train_size=0.8,\n",
    "                                            random_state=1)\n",
    "\n",
    "        self.history = self.autoencoder.fit(X_train, X_train,\n",
    "                epochs=100,\n",
    "                batch_size=8,\n",
    "                shuffle=True,\n",
    "                validation_data=(X_test, X_test),\n",
    "                callbacks=[self.checkpoint])  \n",
    "        \n",
    "        self.encode()\n",
    "        self.map_y()\n",
    "\n",
    "    def plot(self):\n",
    "        plt.plot(self.history.history['loss'], label='Training Loss')\n",
    "        plt.plot(self.history.history['val_loss'], label='Validation Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title('Training and Validation Loss '+ self.size)\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    def encode(self):\n",
    "        try:\n",
    "            self.autoencoder.load_weights(f'model/{self.type}_{self.size}_best_model.h5')\n",
    "        except FileNotFoundError:\n",
    "            self.autoencoder.load_weights(f'model/{self.type}_{self.size}_best_model.keras')\n",
    "\n",
    "        self.encoded_X_train = self.encoder.predict(self.X_train)\n",
    "        self.encoded_X_test = self.encoder.predict(self.X_test)\n",
    "    \n",
    "    def do_PCA(self,n_components):\n",
    "        if self.bottleneck == 2:\n",
    "            # pca = PCA(n_components=n_components)\n",
    "            # reduced_data = pca.fit_transform(self.encoded_X_test)\n",
    "            x = self.encoded_X_test[:, 0]\n",
    "            y = self.encoded_X_test[:, 1]\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            scatter = plt.scatter(x, y, c=self.y_test_in_bin, cmap='viridis', alpha=0.7)\n",
    "            plt.title('Encoded Data '+self.size)\n",
    "            plt.xlabel('Encoded Dim 0')\n",
    "            plt.ylabel('Encoded Dim 1')\n",
    "            plt.colorbar(scatter, label='OS')\n",
    "            plt.grid(True)\n",
    "            plt.show()\n",
    "            return\n",
    "        if n_components ==2:\n",
    "            pca = PCA(n_components=n_components)\n",
    "            reduced_data = pca.fit_transform(self.encoded_X_test)\n",
    "            x = reduced_data[:, 0]\n",
    "            y = reduced_data[:, 1]\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            scatter = plt.scatter(x, y, c=self.y_test_in_bin, cmap='viridis', alpha=0.7)\n",
    "            plt.title('PCA of Encoded Data '+self.size)\n",
    "            plt.xlabel('Principal Component 1')\n",
    "            plt.ylabel('Principal Component 2')\n",
    "            plt.colorbar(scatter, label='OS')\n",
    "            plt.grid(True)\n",
    "            plt.show()\n",
    "        elif n_components ==3:\n",
    "            pca = PCA(n_components=3)  # Reduce to 3 dimensions\n",
    "            reduced_data = pca.fit_transform(self.encoded_X_test)\n",
    "            x = reduced_data[:, 0]\n",
    "            y = reduced_data[:, 1]\n",
    "            z = reduced_data[:, 2]\n",
    "            fig =plt.figure(figsize=(8, 6))\n",
    "            ax = fig.add_subplot(111, projection='3d')\n",
    "            scatter = ax.scatter(x, y, z, c=self.y_test_in_bin, cmap='viridis', depthshade=True)\n",
    "            ax.set_title('3D PCA of Encoded Data '+self.size)\n",
    "            ax.set_xlabel('Principal Component 1')\n",
    "            ax.set_ylabel('Principal Component 2')\n",
    "            ax.set_zlabel('Principal Component 3')\n",
    "            plt.colorbar(scatter, label='OS')\n",
    "            plt.show()\n",
    "\n",
    "    @staticmethod\n",
    "    def map_years_to_group(value):\n",
    "        years = value / 365\n",
    "        if years <= 1:\n",
    "            return 0\n",
    "        elif 1 < years <= 3:\n",
    "            return 1\n",
    "        elif 3 < years <= 5:\n",
    "            return 2\n",
    "        elif 5 < years <= 10:\n",
    "            return 3\n",
    "        elif 10 < years <= 20:\n",
    "            return 4\n",
    "        else:  \n",
    "            return 5\n",
    "        \n",
    "    @staticmethod        \n",
    "    def map_to_binary(category):\n",
    "        if category >= 4:\n",
    "            return 1\n",
    "        else:  \n",
    "            return 0\n",
    "        \n",
    "    def map_y(self):\n",
    "        self.y_trian_in_category = self.y_train.map(AE.map_years_to_group)\n",
    "        self.y_test_in_category = self.y_test.map(AE.map_years_to_group)        \n",
    "        \n",
    "        self.y_trian_in_bin = self.y_trian_in_category.map(AE.map_to_binary)\n",
    "        self.y_test_in_bin = self.y_test_in_category.map(AE.map_to_binary)\n",
    "\n",
    "    def cross_validation_model_selection(self,fold=10):\n",
    "        classifiers = {\n",
    "            'LogisticRegression': LogisticRegression(),\n",
    "            'SVM': SVC(),\n",
    "            'RandomForest': RandomForestClassifier(),\n",
    "            'KNN': KNeighborsClassifier(),\n",
    "            'GradientBoosting': GradientBoostingClassifier(),\n",
    "            'AdaBoost': AdaBoostClassifier(),\n",
    "            'NaiveBayes': GaussianNB(),\n",
    "            'DecisionTree': DecisionTreeClassifier(),\n",
    "            'ExtraTrees': ExtraTreesClassifier(),\n",
    "            'XGBoost': xgb.XGBClassifier()\n",
    "        }\n",
    "\n",
    "        kf = KFold(n_splits=fold)\n",
    "        best_cv_score = 0\n",
    "\n",
    "\n",
    "        for name, clf in classifiers.items():\n",
    "            cv_scores = []\n",
    "            confusion_matrices = []\n",
    "\n",
    "            for train_index, test_index in kf.split(self.encoded_X_train):\n",
    "                X_train, X_test = self.encoded_X_train[train_index], self.encoded_X_train[test_index]\n",
    "                y_train, y_test = self.y_trian_in_bin.iloc[train_index], self.y_trian_in_bin.iloc[test_index]\n",
    "\n",
    "                clf.fit(X_train, y_train)\n",
    "                y_pred = clf.predict(X_test)\n",
    "                \n",
    "                cv_scores.append(accuracy_score(y_test, y_pred))\n",
    "                confusion_matrices.append(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "            mean_cv_score = np.mean(cv_scores)\n",
    "            mean_conf_matrix = np.mean(confusion_matrices, axis=0)\n",
    "\n",
    "            self.cv_scores[name] = mean_cv_score\n",
    "            \n",
    "            print(f\"{name} - Mean CV Score: {mean_cv_score}\")\n",
    "            print(f\"{name} - Mean Confusion Matrix:\\n{mean_conf_matrix}\")\n",
    "\n",
    "            if mean_cv_score > best_cv_score:\n",
    "                best_cv_score = mean_cv_score\n",
    "                best_classifier = name\n",
    "\n",
    "        print(f\"Size: {self.size}, Best classifier: {best_classifier}, CV Score: {best_cv_score}\")\n",
    "\n",
    "\n",
    "\n",
    "    def cross_validation_hyperparameter_optimization(self,fold=5):\n",
    "        pass\n",
    "\n",
    "\n",
    "    def do_RF(self,binary):\n",
    "        clf = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "\n",
    "        if binary:\n",
    "            clf.fit(self.encoded_X_train, self.y_trian_in_bin)\n",
    "            y_pred = clf.predict(self.encoded_X_test)\n",
    "            cm = confusion_matrix(self.y_test_in_bin, y_pred)\n",
    "            print(classification_report(self.y_test_in_bin, y_pred))\n",
    "\n",
    "        else:\n",
    "            clf.fit(self.encoded_X_train, self.y_trian_in_category)\n",
    "            y_pred = clf.predict(self.encoded_X_test)\n",
    "            cm = confusion_matrix(self.y_test_in_category, y_pred)\n",
    "            print(classification_report(self.y_test_in_category, y_pred))\n",
    "\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=np.unique(y_pred), yticklabels=np.unique(self.y_test_in_bin))\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('Actual')\n",
    "        plt.title('RF Confusion Matrix '+self.type)\n",
    "        plt.show()\n",
    "        self.classifer = clf\n",
    "\n",
    "    def do_Kmean(self):\n",
    "        # Number of clusters - assuming you want as many as your known classes\n",
    "        num_clusters = 2\n",
    "        # Perform K-means clustering on the PCA output\n",
    "        kmeans = KMeans(n_clusters=num_clusters, random_state=0)\n",
    "        cluster_labels = kmeans.fit_predict(self.encoded_X_test)  # Use your 2D or 3D PCA-reduced data here\n",
    "\n",
    "\n",
    "        print(\"Classification Report:\")\n",
    "        print(classification_report(self.y_test_in_bin, cluster_labels))\n",
    "        conf_mat = confusion_matrix(self.y_test_in_bin, cluster_labels)\n",
    "\n",
    "        # Plotting the confusion matrix\n",
    "        sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues', xticklabels=range(num_clusters), yticklabels=np.unique(self.y_test_in_bin))\n",
    "        plt.xlabel('Predicted labels')\n",
    "        plt.ylabel('True labels')\n",
    "        plt.title('K-mean Confusion Matrix '+self.size)\n",
    "        plt.show()\n",
    "        self.classifer = kmeans\n",
    "\n",
    "    def do_SVM(self,binary):\n",
    "        svm_classifier = SVC(kernel='linear',random_state=0)\n",
    "        # Load the best weights into the autoencoder model\n",
    "        if binary:\n",
    "            svm_classifier.fit(self.encoded_X_train, self.y_trian_in_bin)\n",
    "            y_pred = svm_classifier.predict(self.encoded_X_test)\n",
    "            cm = confusion_matrix(self.y_test_in_bin, y_pred)\n",
    "            print(classification_report(self.y_test_in_bin, y_pred))\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=np.unique(y_pred), yticklabels=np.unique(self.y_test_in_bin))\n",
    "            plt.xlabel('Predicted')\n",
    "            plt.ylabel('Actual')\n",
    "            plt.title('SVM Confusion Matrix '+ self.size)\n",
    "            plt.show()\n",
    "        else:\n",
    "            svm_classifier.fit(self.encoded_X_train, self.y_trian_in_category)\n",
    "            y_pred = svm_classifier.predict(self.encoded_X_test)\n",
    "            cm = confusion_matrix(self.y_test_in_category, y_pred)\n",
    "            print(classification_report(self.y_test_in_category, y_pred))\n",
    "        \n",
    "            # Plotting the confusion matrix\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=np.unique(y_pred), yticklabels=np.unique(self.y_test_in_category))\n",
    "            plt.xlabel('Predicted')\n",
    "            plt.ylabel('Actual')\n",
    "            plt.title('SVM Confusion Matrix '+ self.size)\n",
    "            plt.show()\n",
    "        self.classifer = svm_classifier\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WAE(AE):\n",
    "    def train(self):\n",
    "    # Number of features in your dataset\n",
    "\n",
    "    # Number of features in your dataset\n",
    "        n_features = len(self.X_train.columns) \n",
    "\n",
    "\n",
    "        input_layer = Input(shape=(n_features,))\n",
    "        encoder = Dense(256, activation='relu')(input_layer)\n",
    "        encoder = Dense(128, activation='relu')(encoder)\n",
    "\n",
    "\n",
    "        bottleneck = Dense(self.bottleneck, activation='relu')(encoder)  \n",
    "\n",
    "        # Define the decoder (mirror the encoder)\n",
    "        decoder = Dense(128, activation='relu')(bottleneck)\n",
    "        decoder = Dense(256, activation='relu')(decoder)\n",
    "        self.encoder= Model(inputs=input_layer, outputs=bottleneck)\n",
    "\n",
    "        # Output layer\n",
    "        output_layer = Dense(n_features, activation='sigmoid')(decoder) \n",
    "\n",
    "        # Define the autoencoder model\n",
    "        self.autoencoder = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "        # Compile the autoencoder\n",
    "        self.autoencoder.compile(optimizer='Adam', loss='mse')\n",
    "\n",
    "        self.checkpoint = ModelCheckpoint(f'model/{self.type}_{self.size}_best_model.h5', \n",
    "                             monitor='val_loss', \n",
    "                             verbose=1,           \n",
    "                             save_best_only=True, \n",
    "                             mode='min')         \n",
    "\n",
    "        X_train, X_test= train_test_split(self.X_train,\n",
    "                                            train_size=0.8,\n",
    "                                            random_state=1)\n",
    "\n",
    "        self.history = self.autoencoder.fit(X_train, X_train,\n",
    "                epochs=100,\n",
    "                batch_size=8,\n",
    "                shuffle=True,\n",
    "                validation_data=(X_test, X_test),\n",
    "                callbacks=[self.checkpoint])  \n",
    "        \n",
    "        self.encode()\n",
    "        self.map_y()\n",
    "        \n",
    "        self.encode()\n",
    "        self.map_y()       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DAE(AE):\n",
    "    def train(self):\n",
    "    # Number of features in your dataset\n",
    "        n_features = len(self.X_train.columns) \n",
    "    # Number of features in your dataset\n",
    "        input_layer = Input(shape=(n_features,))\n",
    "        encoder = Dense(128, activation='relu')(input_layer)\n",
    "\n",
    "        encoder = Dense(64, activation='relu')(encoder)\n",
    "        encoder = Dense(32, activation='relu')(encoder)\n",
    "\n",
    "\n",
    "        bottleneck = Dense(self.bottleneck, activation='relu')(encoder)  \n",
    "\n",
    "        # Define the decoder (mirror the encoder)\n",
    "        decoder = Dense(32, activation='relu')(bottleneck)\n",
    "        decoder = Dense(64, activation='relu')(decoder)\n",
    "        decoder = Dense(128, activation='relu')(decoder)\n",
    "\n",
    "        self.encoder= Model(inputs=input_layer, outputs=bottleneck)\n",
    "\n",
    "        # Output layer\n",
    "        output_layer = Dense(n_features, activation='sigmoid')(decoder) \n",
    "\n",
    "        # Define the autoencoder model\n",
    "        self.autoencoder = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "        # Compile the autoencoder\n",
    "        self.autoencoder.compile(optimizer='Adam', loss='mse')\n",
    "\n",
    "        self.checkpoint = ModelCheckpoint(f'model/{self.type}_{self.size}_best_model.h5', \n",
    "                             monitor='val_loss', \n",
    "                             verbose=1,           \n",
    "                             save_best_only=True, \n",
    "                             mode='min')         \n",
    "\n",
    "        X_train, X_test= train_test_split(self.X_train,\n",
    "                                            train_size=0.8,\n",
    "                                            random_state=1)\n",
    "\n",
    "        self.history = self.autoencoder.fit(X_train, X_train,\n",
    "                epochs=100,\n",
    "                batch_size=8,\n",
    "                shuffle=True,\n",
    "                validation_data=(X_test, X_test),\n",
    "                callbacks=[self.checkpoint])  \n",
    "        \n",
    "        self.encode()\n",
    "        self.map_y()    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WDAE(AE):\n",
    "    def train(self):\n",
    "    # Number of features in your dataset\n",
    "        n_features = len(self.X_train.columns) \n",
    "\n",
    "\n",
    "        input_layer = Input(shape=(n_features,))\n",
    "        encoder = Dense(256, activation='relu')(input_layer)\n",
    "        encoder = Dense(128, activation='relu')(encoder)\n",
    "        encoder = Dense(64, activation='relu')(encoder)\n",
    "        encoder = Dense(32, activation='relu')(encoder)\n",
    "\n",
    "\n",
    "        bottleneck = Dense(self.bottleneck, activation='relu')(encoder)  \n",
    "\n",
    "        # Define the decoder (mirror the encoder)\n",
    "        decoder = Dense(32, activation='relu')(bottleneck)\n",
    "        decoder = Dense(64, activation='relu')(decoder)\n",
    "        decoder = Dense(128, activation='relu')(decoder)\n",
    "        decoder = Dense(256, activation='relu')(decoder)\n",
    "\n",
    "        self.encoder= Model(inputs=input_layer, outputs=bottleneck)\n",
    "\n",
    "        # Output layer\n",
    "        output_layer = Dense(n_features, activation='sigmoid')(decoder) \n",
    "\n",
    "        # Define the autoencoder model\n",
    "        self.autoencoder = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "        # Compile the autoencoder\n",
    "        self.autoencoder.compile(optimizer='SGD', loss='mse')\n",
    "\n",
    "        self.checkpoint = ModelCheckpoint(f'model/{self.type}_{self.size}_best_model.h5', \n",
    "                             monitor='val_loss', \n",
    "                             verbose=1,           \n",
    "                             save_best_only=True, \n",
    "                             mode='min')         \n",
    "\n",
    "        X_train, X_test= train_test_split(self.X_train,\n",
    "                                            train_size=0.8,\n",
    "                                            random_state=1)\n",
    "\n",
    "        self.history = self.autoencoder.fit(X_train, X_train,\n",
    "                epochs=2000,\n",
    "                batch_size=8,\n",
    "                shuffle=True,\n",
    "                validation_data=(X_test, X_test),\n",
    "                callbacks=[self.checkpoint])  \n",
    "        \n",
    "        self.encode()\n",
    "        self.map_y()       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAE(AE):\n",
    "    def train(self):\n",
    "\n",
    "        n_features = len(self.X_train.columns)\n",
    "\n",
    "        # Define the encoder\n",
    "        input_layer = Input(shape=(n_features,))\n",
    "        # Add L1 regularization to encourage sparsity\n",
    "        encoder = Dense(64, activation='relu', \n",
    "                        activity_regularizer=regularizers.l1(1e-6))(input_layer)  # Adjust regularization rate as needed\n",
    "        encoder = Dense(32, activation='relu', \n",
    "                        activity_regularizer=regularizers.l1(1e-6))(encoder)  # Adjust regularization rate as needed\n",
    "\n",
    "        # Define the bottleneck\n",
    "        bottleneck = Dense(self.bottleneck, activation='relu')(encoder)  \n",
    "\n",
    "        # Define the decoder (mirror the encoder)\n",
    "        decoder = Dense(32, activation='relu')(bottleneck)\n",
    "        decoder = Dense(64, activation='relu')(decoder)\n",
    "        self.encoder = Model(inputs=input_layer, outputs=bottleneck)\n",
    "\n",
    "        # Output layer\n",
    "        output_layer = Dense(n_features, activation='sigmoid')(decoder) \n",
    "\n",
    "        # Define the autoencoder model\n",
    "        self.autoencoder = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "        # Compile the autoencoder\n",
    "        self.autoencoder.compile(optimizer='Adam', loss='mse')\n",
    "\n",
    "        # Callback to save the best model\n",
    "        self.checkpoint = ModelCheckpoint(f'model/{self.type}_{self.size}_best_model.keras', \n",
    "                             monitor='val_loss', \n",
    "                             verbose=1, \n",
    "                             save_best_only=True, \n",
    "                             mode='min')\n",
    "\n",
    "        X_train, X_test= train_test_split(self.X_train,\n",
    "                                            train_size=0.8,\n",
    "                                            random_state=1)\n",
    "\n",
    "        self.history = self.autoencoder.fit(X_train, X_train,\n",
    "                epochs=100,\n",
    "                batch_size=8,\n",
    "                shuffle=True,\n",
    "                validation_data=(X_test, X_test),\n",
    "                callbacks=[self.checkpoint])  \n",
    "        self.encode()\n",
    "        self.map_y()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SWDAE(AE):\n",
    "    def train(self):\n",
    "\n",
    "        n_features = len(self.X_train.columns) \n",
    "\n",
    "\n",
    "        input_layer = Input(shape=(n_features,))\n",
    "        encoder = Dense(256, activation='relu',activity_regularizer=regularizers.l1(1e-4))(input_layer)\n",
    "        encoder = Dense(128, activation='relu',activity_regularizer=regularizers.l1(1e-4))(encoder)\n",
    "        encoder = Dense(64, activation='relu',activity_regularizer=regularizers.l1(1e-4))(encoder)\n",
    "        encoder = Dense(32, activation='relu',activity_regularizer=regularizers.l1(1e-4))(encoder)\n",
    "\n",
    "\n",
    "        bottleneck = Dense(self.bottleneck, activation='relu')(encoder)  \n",
    "\n",
    "        # Define the decoder (mirror the encoder)\n",
    "        decoder = Dense(32, activation='relu')(bottleneck)\n",
    "        decoder = Dense(64, activation='relu')(decoder)\n",
    "        decoder = Dense(128, activation='relu')(decoder)\n",
    "        decoder = Dense(256, activation='relu')(decoder)\n",
    "\n",
    "        self.encoder= Model(inputs=input_layer, outputs=bottleneck)\n",
    "\n",
    "        # Output layer\n",
    "        output_layer = Dense(n_features, activation='sigmoid')(decoder) \n",
    "\n",
    "        # Define the autoencoder model\n",
    "        self.autoencoder = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "        # Compile the autoencoder\n",
    "        self.autoencoder.compile(optimizer='Adam', loss='mse')\n",
    "\n",
    "        self.checkpoint = ModelCheckpoint(f'model/{self.type}_{self.size}_best_model.keras', \n",
    "                             monitor='val_loss', \n",
    "                             verbose=1,           \n",
    "                             save_best_only=True, \n",
    "                             mode='min')         \n",
    "\n",
    "        X_train, X_test= train_test_split(self.X_train,\n",
    "                                            train_size=0.8,\n",
    "                                            random_state=1)\n",
    "\n",
    "        self.history = self.autoencoder.fit(X_train, X_train,\n",
    "                epochs=100,\n",
    "                batch_size=8,\n",
    "                shuffle=True,\n",
    "                validation_data=(X_test, X_test),\n",
    "                callbacks=[self.checkpoint])  \n",
    "        \n",
    "        self.encode()\n",
    "        self.map_y()    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AsymmetricAE0(AE):\n",
    "    def train(self):\n",
    "    # Number of features in your dataset\n",
    "        n_features = len(self.X_train.columns) \n",
    "\n",
    "\n",
    "        input_layer = Input(shape=(n_features,))\n",
    "        encoder = Dense(256, activation='relu')(input_layer)\n",
    "\n",
    "        encoder = Dense(128, activation='relu')(encoder)\n",
    "        encoder = Dense(64, activation='relu')(encoder)\n",
    "\n",
    "\n",
    "        bottleneck = Dense(self.bottleneck, activation='relu')(encoder)  \n",
    "\n",
    "        # Define the decoder (mirror the encoder)\n",
    "        decoder = Dense(64, activation='relu')(bottleneck)\n",
    "        decoder = Dense(128, activation='relu')(decoder)\n",
    "        decoder = Dense(256, activation='relu')(decoder)\n",
    "\n",
    "        self.encoder= Model(inputs=input_layer, outputs=bottleneck)\n",
    "\n",
    "        # Output layer\n",
    "        output_layer = Dense(n_features, activation='sigmoid')(decoder) \n",
    "\n",
    "        # Define the autoencoder model\n",
    "        self.autoencoder = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "        # Compile the autoencoder\n",
    "        self.autoencoder.compile(optimizer='Adam', loss='mse')\n",
    "\n",
    "        self.checkpoint = ModelCheckpoint(f'model/{self.type}_{self.size}_best_model.keras', \n",
    "                             monitor='val_loss', \n",
    "                             verbose=1,           \n",
    "                             save_best_only=True, \n",
    "                             mode='min')         \n",
    "\n",
    "        X_train, X_test= train_test_split(self.X_train,\n",
    "                                            train_size=0.8,\n",
    "                                            random_state=1)\n",
    "\n",
    "        self.history = self.autoencoder.fit(X_train, X_train,\n",
    "                epochs=100,\n",
    "                batch_size=8,\n",
    "                shuffle=True,\n",
    "                validation_data=(X_test, X_test),\n",
    "                callbacks=[self.checkpoint])  \n",
    "        \n",
    "        self.encode()\n",
    "        self.map_y()\n",
    "\n",
    "\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AsymmetricAE1(AE):\n",
    "    def train(self):\n",
    "    # Number of features in your dataset\n",
    "        n_features = len(self.X_train.columns) \n",
    "\n",
    "\n",
    "        input_layer = Input(shape=(n_features,))\n",
    "\n",
    "        encoder = Dense(128, activation='relu')(input_layer)\n",
    "        encoder = Dense(64, activation='relu')(encoder)\n",
    "\n",
    "\n",
    "        bottleneck = Dense(self.bottleneck, activation='relu')(encoder)  \n",
    "\n",
    "        # Define the decoder (mirror the encoder)\n",
    "        decoder = Dense(64, activation='relu')(bottleneck)\n",
    "        decoder = Dense(128, activation='relu')(decoder)\n",
    "        decoder = Dense(256, activation='relu')(decoder)\n",
    "\n",
    "        self.encoder= Model(inputs=input_layer, outputs=bottleneck)\n",
    "\n",
    "        # Output layer\n",
    "        output_layer = Dense(n_features, activation='sigmoid')(decoder) \n",
    "\n",
    "        # Define the autoencoder model\n",
    "        self.autoencoder = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "        # Compile the autoencoder\n",
    "        self.autoencoder.compile(optimizer='Adam', loss='mse')\n",
    "\n",
    "        self.checkpoint = ModelCheckpoint(f'model/{self.type}_{self.size}_best_model.keras', \n",
    "                             monitor='val_loss', \n",
    "                             verbose=1,           \n",
    "                             save_best_only=True, \n",
    "                             mode='min')         \n",
    "\n",
    "        X_train, X_test= train_test_split(self.X_train,\n",
    "                                            train_size=0.8,\n",
    "                                            random_state=1)\n",
    "\n",
    "        self.history = self.autoencoder.fit(X_train, X_train,\n",
    "                epochs=100,\n",
    "                batch_size=8,\n",
    "                shuffle=True,\n",
    "                validation_data=(X_test, X_test),\n",
    "                callbacks=[self.checkpoint])  \n",
    "        \n",
    "        self.encode()\n",
    "        self.map_y()\n",
    "\n",
    "\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AsymmetricAE2(AE):\n",
    "    def train(self):\n",
    "    # Number of features in your dataset\n",
    "        n_features = len(self.X_train.columns) \n",
    "\n",
    "\n",
    "        input_layer = Input(shape=(n_features,))\n",
    "\n",
    "        encoder = Dense(128, activation='relu')(input_layer)\n",
    "        encoder = Dense(64, activation='relu')(encoder)\n",
    "\n",
    "\n",
    "        bottleneck = Dense(self.bottleneck, activation='relu')(encoder)  \n",
    "\n",
    "        # Define the decoder (mirror the encoder)\n",
    "        decoder = Dense(32, activation='relu')(bottleneck)\n",
    "\n",
    "        decoder = Dense(64, activation='relu')(decoder)\n",
    "        decoder = Dense(128, activation='relu')(decoder)\n",
    "        decoder = Dense(256, activation='relu')(decoder)\n",
    "\n",
    "        self.encoder= Model(inputs=input_layer, outputs=bottleneck)\n",
    "\n",
    "        # Output layer\n",
    "        output_layer = Dense(n_features, activation='sigmoid')(decoder) \n",
    "\n",
    "        # Define the autoencoder model\n",
    "        self.autoencoder = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "        self.autoencoder.compile(optimizer='Adam', loss='mse')\n",
    "\n",
    "        self.checkpoint = ModelCheckpoint(f'model/{self.type}_{self.size}_best_model.keras', \n",
    "                             monitor='val_loss', \n",
    "                             verbose=1,           \n",
    "                             save_best_only=True, \n",
    "                             mode='min')         \n",
    "\n",
    "        X_train, X_test= train_test_split(self.X_train,\n",
    "                                            train_size=0.8,\n",
    "                                            random_state=1)\n",
    "\n",
    "        self.history = self.autoencoder.fit(X_train, X_train,\n",
    "                epochs=100,\n",
    "                batch_size=8,\n",
    "                shuffle=True,\n",
    "                validation_data=(X_test, X_test),\n",
    "                callbacks=[self.checkpoint])  \n",
    "        \n",
    "        self.encode()\n",
    "        self.map_y()\n",
    "\n",
    "\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AsymmetricAE3(AE):\n",
    "    def train(self):\n",
    "    # Number of features in your dataset\n",
    "        n_features = len(self.X_train.columns) \n",
    "\n",
    "\n",
    "        input_layer = Input(shape=(n_features,))\n",
    "\n",
    "        encoder = Dense(256, activation='relu')(input_layer)\n",
    "        encoder = Dense(64, activation='relu')(encoder)\n",
    "\n",
    "\n",
    "        bottleneck = Dense(self.bottleneck, activation='relu')(encoder)  \n",
    "\n",
    "        # Define the decoder (mirror the encoder)\n",
    "\n",
    "        decoder = Dense(64, activation='relu')(bottleneck)\n",
    "        decoder = Dense(128, activation='relu')(decoder)\n",
    "        decoder = Dense(256, activation='relu')(decoder)\n",
    "\n",
    "        self.encoder= Model(inputs=input_layer, outputs=bottleneck)\n",
    "\n",
    "        # Output layer\n",
    "        output_layer = Dense(n_features, activation='sigmoid')(decoder) \n",
    "\n",
    "        # Define the autoencoder model\n",
    "        self.autoencoder = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "        # Compile the autoencoder\n",
    "        self.autoencoder.compile(optimizer='Adam', loss='mse')\n",
    "\n",
    "        self.checkpoint = ModelCheckpoint(f'model/{self.type}_{self.size}_best_model.keras', \n",
    "                             monitor='val_loss', \n",
    "                             verbose=1,           \n",
    "                             save_best_only=True, \n",
    "                             mode='min')         \n",
    "\n",
    "        X_train, X_test= train_test_split(self.X_train,\n",
    "                                            train_size=0.8,\n",
    "                                            random_state=1)\n",
    "\n",
    "        self.history = self.autoencoder.fit(X_train, X_train,\n",
    "                epochs=100,\n",
    "                batch_size=8,\n",
    "                shuffle=True,\n",
    "                validation_data=(X_test, X_test),\n",
    "                callbacks=[self.checkpoint])  \n",
    "        \n",
    "        self.encode()\n",
    "        self.map_y()\n",
    "\n",
    "\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AsymmetricAE4(AE):\n",
    "    def train(self):\n",
    "    # Number of features in your dataset\n",
    "        n_features = len(self.X_train.columns) \n",
    "\n",
    "\n",
    "        input_layer = Input(shape=(n_features,))\n",
    "\n",
    "        encoder = Dense(256, activation='relu')(input_layer)\n",
    "        encoder = Dense(64, activation='relu')(encoder)\n",
    "        encoder = Dense(32, activation='relu')(encoder)\n",
    "\n",
    "\n",
    "        bottleneck = Dense(self.bottleneck, activation='relu')(encoder)  \n",
    "\n",
    "        # Define the decoder (mirror the encoder)\n",
    "        decoder = Dense(32, activation='relu')(bottleneck)\n",
    "\n",
    "        decoder = Dense(64, activation='relu')(decoder)\n",
    "\n",
    "\n",
    "        self.encoder= Model(inputs=input_layer, outputs=bottleneck)\n",
    "\n",
    "        # Output layer\n",
    "        output_layer = Dense(n_features, activation='sigmoid')(decoder) \n",
    "\n",
    "        # Define the autoencoder model\n",
    "        self.autoencoder = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "        # Compile the autoencoder\n",
    "        self.autoencoder.compile(optimizer='Adam', loss='mse')\n",
    "\n",
    "        self.checkpoint = ModelCheckpoint(f'model/{self.type}_{self.size}_best_model.keras', \n",
    "                             monitor='val_loss', \n",
    "                             verbose=1,           \n",
    "                             save_best_only=True, \n",
    "                             mode='min')         \n",
    "\n",
    "        X_train, X_test= train_test_split(self.X_train,\n",
    "                                            train_size=0.8,\n",
    "                                            random_state=1)\n",
    "\n",
    "        self.history = self.autoencoder.fit(X_train, X_train,\n",
    "                epochs=100,\n",
    "                batch_size=8,\n",
    "                shuffle=True,\n",
    "                validation_data=(X_test, X_test),\n",
    "                callbacks=[self.checkpoint])  \n",
    "        \n",
    "        self.encode()\n",
    "        self.map_y()\n",
    "\n",
    "\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AsymmetricAE5(AE):\n",
    "    def train(self):\n",
    "    # Number of features in your dataset\n",
    "        n_features = len(self.X_train.columns) \n",
    "\n",
    "\n",
    "        input_layer = Input(shape=(n_features,))\n",
    "\n",
    "        encoder = Dense(256, activation='relu')(input_layer)\n",
    "        encoder = Dense(64, activation='relu')(encoder)\n",
    "        encoder = Dense(32, activation='relu')(encoder)\n",
    "\n",
    "\n",
    "        bottleneck = Dense(self.bottleneck, activation='relu')(encoder)  \n",
    "\n",
    "        # Define the decoder (mirror the encoder)\n",
    "\n",
    "        decoder = Dense(64, activation='relu')(bottleneck)\n",
    "\n",
    "\n",
    "        self.encoder= Model(inputs=input_layer, outputs=bottleneck)\n",
    "\n",
    "        # Output layer\n",
    "        output_layer = Dense(n_features, activation='sigmoid')(decoder) \n",
    "\n",
    "        # Define the autoencoder model\n",
    "        self.autoencoder = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "        # Compile the autoencoder\n",
    "        self.autoencoder.compile(optimizer='Adam', loss='mse')\n",
    "\n",
    "        self.checkpoint = ModelCheckpoint(f'model/{self.type}_{self.size}_best_model.keras', \n",
    "                             monitor='val_loss', \n",
    "                             verbose=1,           \n",
    "                             save_best_only=True, \n",
    "                             mode='min')         \n",
    "\n",
    "        X_train, X_test= train_test_split(self.X_train,\n",
    "                                            train_size=0.8,\n",
    "                                            random_state=1)\n",
    "\n",
    "        self.history = self.autoencoder.fit(X_train, X_train,\n",
    "                epochs=100,\n",
    "                batch_size=8,\n",
    "                shuffle=True,\n",
    "                validation_data=(X_test, X_test),\n",
    "                callbacks=[self.checkpoint])  \n",
    "        \n",
    "        self.encode()\n",
    "        self.map_y()\n",
    "\n",
    "\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AsymmetricAE6(AE):\n",
    "    def train(self):\n",
    "    # Number of features in your dataset\n",
    "        n_features = len(self.X_train.columns) \n",
    "\n",
    "\n",
    "        input_layer = Input(shape=(n_features,))\n",
    "\n",
    "        encoder = Dense(256, activation='relu')(input_layer)\n",
    "        encoder = Dense(64, activation='relu')(encoder)\n",
    "        encoder = Dense(32, activation='relu')(encoder)\n",
    "\n",
    "\n",
    "        bottleneck = Dense(self.bottleneck, activation='relu')(encoder)  \n",
    "\n",
    "        # Define the decoder (mirror the encoder)\n",
    "        decoder = Dense(32, activation='relu')(bottleneck)\n",
    "\n",
    "\n",
    "\n",
    "        self.encoder= Model(inputs=input_layer, outputs=bottleneck)\n",
    "\n",
    "        # Output layer\n",
    "        output_layer = Dense(n_features, activation='sigmoid')(decoder) \n",
    "\n",
    "        # Define the autoencoder model\n",
    "        self.autoencoder = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "        # Compile the autoencoder\n",
    "        self.autoencoder.compile(optimizer='Adam', loss='mse')\n",
    "\n",
    "        self.checkpoint = ModelCheckpoint(f'model/{self.type}_{self.size}_best_model.keras', \n",
    "                             monitor='val_loss', \n",
    "                             verbose=1,           \n",
    "                             save_best_only=True, \n",
    "                             mode='min')         \n",
    "\n",
    "        X_train, X_test= train_test_split(self.X_train,\n",
    "                                            train_size=0.8,\n",
    "                                            random_state=1)\n",
    "\n",
    "        self.history = self.autoencoder.fit(X_train, X_train,\n",
    "                epochs=100,\n",
    "                batch_size=8,\n",
    "                shuffle=True,\n",
    "                validation_data=(X_test, X_test),\n",
    "                callbacks=[self.checkpoint])  \n",
    "        \n",
    "        self.encode()\n",
    "        self.map_y()\n",
    "\n",
    "\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAW(AE):\n",
    "    def train(self):\n",
    "        self.map_y()\n",
    "\n",
    "        self.encoded_X_train = self.X_train.values\n",
    "        self.encoded_X_test = self.X_test.values\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dispatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dispatcher(model,type,min_bottleneck, max_bottleneck,step =1):\n",
    "    current_size = min_bottleneck\n",
    "    AEs = []\n",
    "    results = []\n",
    "    while current_size <= max_bottleneck:\n",
    "        name = f\"bottleneck_{current_size}\"\n",
    "        AEs.append(model(X_train=X_train,X_test=X_test,y_train=y_train,y_test=y_test,bottleneck = current_size,size = name,type = type))\n",
    "        current_size += step\n",
    "    for AE_to_train in AEs:\n",
    "        AE_to_train.train()\n",
    "        AE_to_train.cross_validation_model_selection()\n",
    "        results.append({f\"{AE_to_train.type} {AE_to_train.size}\": AE_to_train.cv_scores})\n",
    "    \n",
    "    output = json.dumps(results)\n",
    "    with open(f\"output/{type}_model_output.json\",\"w\") as file:\n",
    "        file.write(output)\n",
    "    return\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dispatcher(AE,\"AE\",6,48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dispatcher(WAE,\"WAE\",6,48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dispatcher(DAE,\"DAE\",6,48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dispatcher(WDAE,\"WDAE\",6,48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dispatcher(SAE,\"SAE\",6,48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dispatcher(SWDAE,\"SWDAE\",6,48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dispatcher(AsymmetricAE0,\"AsymmetricAE0\",6,48)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dispatcher(AsymmetricAE1,\"AsymmetricAE1\",6,48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dispatcher(AsymmetricAE2,\"AsymmetricAE2\",6,48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dispatcher(AsymmetricAE3,\"AsymmetricAE3\",6,48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dispatcher(AsymmetricAE4,\"AsymmetricAE4\",6,48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dispatcher(AsymmetricAE5,\"AsymmetricAE5\",6,48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dispatcher(AsymmetricAE6,\"AsymmetricAE6\",6,48)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dispatcher(RAW,\"RAW\",6,48)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_statistics(data,filename):\n",
    "    # overall_means = {classifier: np.mean(list(values.values())) for classifier, values in data.items()}\n",
    "\n",
    "\n",
    "\n",
    "    # Calculate statistics for each classifier\n",
    "    statistics = {}\n",
    "    for classifier, values in data.items():\n",
    "        values_list = list(values.values())\n",
    "        statistics[classifier] = {\n",
    "            'Mean': np.mean(values_list),\n",
    "            'Standard Deviation': np.std(values_list),\n",
    "            # 'Minimum': np.min(values_list),\n",
    "            'Maximum': np.max(values_list),\n",
    "            # '25th Percentile': np.percentile(values_list, 25),\n",
    "            # '50th Percentile (Median)': np.median(values_list),\n",
    "            # '75th Percentile': np.percentile(values_list, 75)\n",
    "        }\n",
    "\n",
    "    # Convert statistics dictionary to a DataFrame for better visualization\n",
    "    stats_df = pd.DataFrame(statistics).T\n",
    "    # overall_mean = np.mean(stats_df[\"Mean\"])\n",
    "    print(f\"--------------------- {filename} ----------------------\")\n",
    "    # print(f\"Overall_mean {overall_means}\")\n",
    "    print(stats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------- WDAE_model_output.json ----------------------\n",
      "                        Mean  Standard Deviation   Maximum\n",
      "LogisticRegression  0.561553            0.032962  0.621538\n",
      "SVM                 0.574326            0.031079  0.648462\n",
      "RandomForest        0.588490            0.029148  0.660308\n",
      "KNN                 0.581703            0.027113  0.641077\n",
      "GradientBoosting    0.573496            0.034066  0.652615\n",
      "AdaBoost            0.564386            0.039860  0.660462\n",
      "NaiveBayes          0.532937            0.026126  0.605846\n",
      "DecisionTree        0.549170            0.029699  0.606308\n",
      "ExtraTrees          0.594533            0.027376  0.645077\n",
      "XGBoost             0.574354            0.036256  0.648462\n",
      "--------------------- SWDAE_model_output.json ----------------------\n",
      "                        Mean  Standard Deviation   Maximum\n",
      "LogisticRegression  0.475231            0.000000  0.475231\n",
      "SVM                 0.475231            0.000000  0.475231\n",
      "RandomForest        0.475488            0.015166  0.513692\n",
      "KNN                 0.478615            0.000000  0.478615\n",
      "GradientBoosting    0.475141            0.000580  0.475231\n",
      "AdaBoost            0.475141            0.000580  0.475231\n",
      "NaiveBayes          0.507589            0.025907  0.547846\n",
      "DecisionTree        0.475141            0.000580  0.475231\n",
      "ExtraTrees          0.475141            0.000580  0.475231\n",
      "XGBoost             0.475231            0.000000  0.475231\n",
      "--------------------- AE_model_output.json ----------------------\n",
      "                        Mean  Standard Deviation   Maximum\n",
      "LogisticRegression  0.569599            0.039844  0.648462\n",
      "SVM                 0.573156            0.035144  0.629385\n",
      "RandomForest        0.600097            0.035649  0.668154\n",
      "KNN                 0.585642            0.029432  0.644923\n",
      "GradientBoosting    0.581903            0.041122  0.667846\n",
      "AdaBoost            0.566819            0.045635  0.661231\n",
      "NaiveBayes          0.547667            0.031255  0.606154\n",
      "DecisionTree        0.554422            0.031373  0.609846\n",
      "ExtraTrees          0.600522            0.034198  0.671538\n",
      "XGBoost             0.589077            0.038593  0.648923\n",
      "--------------------- RAW_model_output.json ----------------------\n",
      "                        Mean  Standard Deviation   Maximum\n",
      "LogisticRegression  0.613538        0.000000e+00  0.613538\n",
      "SVM                 0.617692        1.110223e-16  0.617692\n",
      "RandomForest        0.617932        1.641948e-02  0.656154\n",
      "KNN                 0.602000        0.000000e+00  0.602000\n",
      "GradientBoosting    0.630093        4.709259e-03  0.640923\n",
      "AdaBoost            0.540154        0.000000e+00  0.540154\n",
      "NaiveBayes          0.606308        1.110223e-16  0.606308\n",
      "DecisionTree        0.548637        1.203292e-02  0.579231\n",
      "ExtraTrees          0.618834        2.120769e-02  0.656308\n",
      "XGBoost             0.641385        1.110223e-16  0.641385\n",
      "--------------------- AsymmetricAE6_model_output.json ----------------------\n",
      "                        Mean  Standard Deviation   Maximum\n",
      "LogisticRegression  0.576526            0.038617  0.632923\n",
      "SVM                 0.584018            0.024228  0.629385\n",
      "RandomForest        0.599016            0.033936  0.671692\n",
      "KNN                 0.601499            0.025804  0.660462\n",
      "GradientBoosting    0.589342            0.034822  0.663692\n",
      "AdaBoost            0.564483            0.028298  0.618000\n",
      "NaiveBayes          0.549564            0.028808  0.606308\n",
      "DecisionTree        0.549081            0.038428  0.637077\n",
      "ExtraTrees          0.608254            0.031819  0.664154\n",
      "XGBoost             0.591284            0.030481  0.648615\n",
      "--------------------- AsymmetricAE3_model_output.json ----------------------\n",
      "                        Mean  Standard Deviation   Maximum\n",
      "LogisticRegression  0.581925            0.028130  0.644462\n",
      "SVM                 0.588172            0.019144  0.633077\n",
      "RandomForest        0.609574            0.023415  0.679231\n",
      "KNN                 0.597395            0.020602  0.660308\n",
      "GradientBoosting    0.587635            0.024766  0.644923\n",
      "AdaBoost            0.573660            0.031759  0.621538\n",
      "NaiveBayes          0.541234            0.029699  0.617846\n",
      "DecisionTree        0.555374            0.035247  0.648462\n",
      "ExtraTrees          0.611685            0.020959  0.664154\n",
      "XGBoost             0.596801            0.031682  0.671846\n",
      "--------------------- SAE_model_output.json ----------------------\n",
      "                        Mean  Standard Deviation   Maximum\n",
      "LogisticRegression  0.575123            0.028412  0.629077\n",
      "SVM                 0.602780            0.023075  0.656000\n",
      "RandomForest        0.605717            0.025506  0.652462\n",
      "KNN                 0.598640            0.027704  0.660154\n",
      "GradientBoosting    0.595828            0.028842  0.648308\n",
      "AdaBoost            0.581009            0.033016  0.675538\n",
      "NaiveBayes          0.567320            0.021394  0.622000\n",
      "DecisionTree        0.557213            0.030178  0.629077\n",
      "ExtraTrees          0.614970            0.023484  0.667692\n",
      "XGBoost             0.601206            0.028901  0.671692\n",
      "--------------------- DAE_model_output.json ----------------------\n",
      "                        Mean  Standard Deviation   Maximum\n",
      "LogisticRegression  0.575184            0.029539  0.633538\n",
      "SVM                 0.575771            0.022068  0.614308\n",
      "RandomForest        0.603689            0.030504  0.675538\n",
      "KNN                 0.582333            0.020870  0.625846\n",
      "GradientBoosting    0.590619            0.028430  0.672154\n",
      "AdaBoost            0.565753            0.033239  0.640462\n",
      "NaiveBayes          0.538265            0.029312  0.594154\n",
      "DecisionTree        0.554551            0.032219  0.606308\n",
      "ExtraTrees          0.598791            0.019886  0.640769\n",
      "XGBoost             0.584934            0.034445  0.660154\n",
      "--------------------- AsymmetricAE2_model_output.json ----------------------\n",
      "                        Mean  Standard Deviation   Maximum\n",
      "LogisticRegression  0.568812            0.032407  0.640769\n",
      "SVM                 0.578683            0.019875  0.618000\n",
      "RandomForest        0.598630            0.021653  0.652462\n",
      "KNN                 0.581893            0.023250  0.622000\n",
      "GradientBoosting    0.580132            0.033655  0.645077\n",
      "AdaBoost            0.575592            0.032794  0.644615\n",
      "NaiveBayes          0.537284            0.032503  0.606462\n",
      "DecisionTree        0.559639            0.025962  0.613846\n",
      "ExtraTrees          0.598934            0.022722  0.644769\n",
      "XGBoost             0.588283            0.027436  0.660308\n",
      "--------------------- WAE_model_output.json ----------------------\n",
      "                        Mean  Standard Deviation   Maximum\n",
      "LogisticRegression  0.577170            0.035582  0.632615\n",
      "SVM                 0.597746            0.018108  0.629231\n",
      "RandomForest        0.602147            0.033661  0.675385\n",
      "KNN                 0.590945            0.024239  0.652308\n",
      "GradientBoosting    0.585517            0.029975  0.633538\n",
      "AdaBoost            0.566465            0.035715  0.632923\n",
      "NaiveBayes          0.551041            0.026274  0.606308\n",
      "DecisionTree        0.551742            0.037424  0.609692\n",
      "ExtraTrees          0.610980            0.032435  0.683231\n",
      "XGBoost             0.587728            0.032288  0.663538\n",
      "--------------------- AsymmetricAE4_model_output.json ----------------------\n",
      "                        Mean  Standard Deviation   Maximum\n",
      "LogisticRegression  0.580945            0.036024  0.644769\n",
      "SVM                 0.578229            0.029668  0.637231\n",
      "RandomForest        0.611134            0.036526  0.690769\n",
      "KNN                 0.596855            0.027000  0.648462\n",
      "GradientBoosting    0.586358            0.036491  0.675692\n",
      "AdaBoost            0.574572            0.036795  0.640923\n",
      "NaiveBayes          0.536705            0.032132  0.609846\n",
      "DecisionTree        0.560730            0.032145  0.628923\n",
      "ExtraTrees          0.615238            0.033669  0.683385\n",
      "XGBoost             0.597188            0.039322  0.691077\n",
      "--------------------- AsymmetricAE1_model_output.json ----------------------\n",
      "                        Mean  Standard Deviation   Maximum\n",
      "LogisticRegression  0.572862            0.041603  0.632769\n",
      "SVM                 0.585889            0.032116  0.633385\n",
      "RandomForest        0.603481            0.033832  0.660154\n",
      "KNN                 0.585195            0.028987  0.652769\n",
      "GradientBoosting    0.588143            0.034963  0.656000\n",
      "AdaBoost            0.570655            0.030523  0.652462\n",
      "NaiveBayes          0.547313            0.031529  0.609846\n",
      "DecisionTree        0.555564            0.031027  0.630154\n",
      "ExtraTrees          0.603653            0.032033  0.652308\n",
      "XGBoost             0.594315            0.028772  0.653231\n",
      "--------------------- AsymmetricAE5_model_output.json ----------------------\n",
      "                        Mean  Standard Deviation   Maximum\n",
      "LogisticRegression  0.589692            0.029432  0.645077\n",
      "SVM                 0.593685            0.023145  0.637231\n",
      "RandomForest        0.608608            0.031359  0.663846\n",
      "KNN                 0.603789            0.028975  0.660462\n",
      "GradientBoosting    0.600193            0.036247  0.683385\n",
      "AdaBoost            0.577896            0.034805  0.659846\n",
      "NaiveBayes          0.547775            0.028104  0.605692\n",
      "DecisionTree        0.559735            0.032623  0.621385\n",
      "ExtraTrees          0.603932            0.032359  0.675385\n",
      "XGBoost             0.601728            0.040874  0.679538\n",
      "--------------------- AsymmetricAE0_model_output.json ----------------------\n",
      "                        Mean  Standard Deviation   Maximum\n",
      "LogisticRegression  0.574200            0.037145  0.637385\n",
      "SVM                 0.587900            0.019736  0.625846\n",
      "RandomForest        0.596150            0.024802  0.633692\n",
      "KNN                 0.583617            0.018573  0.614308\n",
      "GradientBoosting    0.580787            0.031114  0.656462\n",
      "AdaBoost            0.573703            0.029073  0.633385\n",
      "NaiveBayes          0.538973            0.025308  0.590769\n",
      "DecisionTree        0.553996            0.030400  0.629231\n",
      "ExtraTrees          0.598250            0.022043  0.644615\n",
      "XGBoost             0.581055            0.032880  0.652308\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Directory containing the JSON files\n",
    "directory = 'output'\n",
    "\n",
    "\n",
    "# List of classifiers to consider\n",
    "classifiers = [\"LogisticRegression\", \"SVM\", \"RandomForest\", \"KNN\", \"GradientBoosting\", \n",
    "               \"AdaBoost\", \"NaiveBayes\", \"DecisionTree\", \"ExtraTrees\", \"XGBoost\"]\n",
    "\n",
    "# Function to plot data from a single JSON file\n",
    "def plot_single_file(data, title):\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    for classifier, bottlenecks in data.items():\n",
    "        x = sorted(bottlenecks.keys())\n",
    "        y = [bottlenecks[size] for size in x]\n",
    "        plt.plot(x, y, label=classifier)\n",
    "        max_index = y.index(max(y))\n",
    "        plt.plot(x[max_index], y[max_index], 'ro')  # Mark the highest point\n",
    "        plt.text(x[max_index], y[max_index], f'{y[max_index]:.2f}', fontsize=9, ha='right')\n",
    "    plt.xlabel('Bottleneck Size')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Initialize a list to hold data for each JSON file\n",
    "all_data = []\n",
    "\n",
    "# Read and process each JSON file\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".json\"):\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        with open(filepath, 'r') as file:\n",
    "            json_data = json.load(file)\n",
    "            data = {classifier: {} for classifier in classifiers}\n",
    "            for entry in json_data:\n",
    "                for bottleneck, scores in entry.items():\n",
    "                    size = int(bottleneck.split('_')[-1])\n",
    "                    for classifier, score in scores.items():\n",
    "                        data[classifier][size] = score\n",
    "                        \n",
    "            print_statistics(data,filename)\n",
    "            # plot_single_file(data, f'Performance from {filename}')\n",
    "            all_data.append(data)\n",
    "\n",
    "# # Plotting combined graph\n",
    "# plt.figure(figsize=(14, 8))\n",
    "# for i, data in enumerate(all_data):\n",
    "#     for classifier, bottlenecks in data.items():\n",
    "#         x = sorted(bottlenecks.keys())\n",
    "#         y = [bottlenecks[size] for size in x]\n",
    "#         plt.plot(x, y, label=f'{classifier} (File {i+1})')\n",
    "#         max_index = y.index(max(y))\n",
    "#         plt.plot(x[max_index], y[max_index], 'ro')  # Mark the highest point\n",
    "#         plt.text(x[max_index], y[max_index], f'{y[max_index]:.2f}', fontsize=9, ha='right')\n",
    "\n",
    "# plt.xlabel('Bottleneck Size')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.title('Combined Classifier Performance by Bottleneck Size')\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtained a record 0f 0.69 at AsymmetricAE4 for RandomForest and XGBoost of bottle neck 36, then applying hyperparameter optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from math import inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OptimizedAsymmetricAE(AsymmetricAE4):\n",
    "    def __init__(self, X_train, X_test, y_train, y_test, bottleneck = 36, size = \"36\", type=\"OptimizedAsymmetricAE\"):\n",
    "        super().__init__(X_train, X_test, y_train, y_test, bottleneck, size, type)\n",
    "    \n",
    "    \n",
    "    def cross_validation_hyperparameter_optimization(self,fold=5):\n",
    "\n",
    "\n",
    "\n",
    "        RF_study = optuna.create_study(direction='maximize')\n",
    "        RF_study.optimize(self.RF_objective, n_trials=100)\n",
    "\n",
    "        # Retrieve the best trial\n",
    "        best_trial = RF_study.best_trial\n",
    "\n",
    "        # Print the best hyperparameters and the best accuracy\n",
    "        print(\"RF Result\")\n",
    "\n",
    "        print(\"Best hyperparameters: \", best_trial.params)\n",
    "        print(\"Best accuracy: \", best_trial.value)\n",
    "\n",
    "\n",
    "\n",
    "        XGBoost_study = optuna.create_study(direction='maximize')\n",
    "        XGBoost_study.optimize(self.XGBoost_objective, n_trials=100)\n",
    "        # Retrieve the best trial\n",
    "        best_trial = XGBoost_study.best_trial\n",
    "\n",
    "        # Print the best hyperparameters and the best accuracy\n",
    "        print(\"XGBoost Result\")\n",
    "        print(\"Best hyperparameters: \", best_trial.params)\n",
    "        print(\"Best accuracy: \", best_trial.value)\n",
    "\n",
    "\n",
    "    def RF_objective(self,trial):\n",
    "        # Load data\n",
    "\n",
    "        # Suggest hyperparameters\n",
    "        param = {\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 10, 200),\n",
    "            'max_depth': trial.suggest_int('max_depth', 2, 32),\n",
    "            'min_samples_split': trial.suggest_int('min_samples_split', 2, 16),\n",
    "            'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 16),\n",
    "            'max_features': trial.suggest_categorical('max_features', [1,inf])\n",
    "        }\n",
    "\n",
    "        # Create the model\n",
    "        clf = RandomForestClassifier(**param)\n",
    "        \n",
    "        # Evaluate the model using cross-validation\n",
    "        score = cross_val_score(clf, self.encoded_X_train, self.y_trian_in_bin, n_jobs=-1, cv=3, scoring='accuracy')\n",
    "        accuracy = score.mean()\n",
    "        return accuracy\n",
    "\n",
    "\n",
    "    def XGBoost_objective(self,trial):\n",
    "        \n",
    "        # Suggest hyperparameters\n",
    "        param = {\n",
    "            'verbosity': 0,\n",
    "            'objective': 'binary:logistic',\n",
    "            'eval_metric': 'auc',\n",
    "            'tree_method': 'hist',  # faster with large datasets\n",
    "            'booster': trial.suggest_categorical('booster', ['gbtree', 'dart']),\n",
    "            'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
    "            'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
    "            'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "            'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "            'max_depth': trial.suggest_int('max_depth', 3, 9),\n",
    "            'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "        }\n",
    "\n",
    "        if param['booster'] == 'dart':\n",
    "            param['sample_type'] = trial.suggest_categorical('sample_type', ['uniform', 'weighted'])\n",
    "            param['normalize_type'] = trial.suggest_categorical('normalize_type', ['tree', 'forest'])\n",
    "            param['rate_drop'] = trial.suggest_float('rate_drop', 0.0, 0.3)\n",
    "            param['skip_drop'] = trial.suggest_float('skip_drop', 0.0, 0.3)\n",
    "        \n",
    "        # Create the model\n",
    "        model = xgb.XGBClassifier(**param)\n",
    "        \n",
    "        # Evaluate the model using cross-validation\n",
    "        score = cross_val_score(model, self.encoded_X_train, self.y_trian_in_bin, n_jobs=-1, cv=3, scoring='accuracy')\n",
    "        accuracy = score.mean()\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m 1/26\u001b[0m \u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 485ms/step - loss: 0.0469\n",
      "Epoch 1: val_loss improved from inf to 0.02636, saving model to model/OptimizedAsymmetricAE_36_best_model.keras\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0418 - val_loss: 0.0264\n",
      "Epoch 2/100\n",
      "\u001b[1m 1/26\u001b[0m \u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0186\n",
      "Epoch 2: val_loss improved from 0.02636 to 0.02367, saving model to model/OptimizedAsymmetricAE_36_best_model.keras\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0228 - val_loss: 0.0237\n",
      "Epoch 3/100\n",
      "\u001b[1m 1/26\u001b[0m \u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0146\n",
      "Epoch 3: val_loss improved from 0.02367 to 0.02275, saving model to model/OptimizedAsymmetricAE_36_best_model.keras\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0214 - val_loss: 0.0227\n",
      "Epoch 4/100\n",
      "\u001b[1m 1/26\u001b[0m \u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0206\n",
      "Epoch 4: val_loss improved from 0.02275 to 0.02089, saving model to model/OptimizedAsymmetricAE_36_best_model.keras\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0216 - val_loss: 0.0209\n",
      "Epoch 5/100\n",
      "\u001b[1m 1/26\u001b[0m \u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0168\n",
      "Epoch 5: val_loss improved from 0.02089 to 0.01977, saving model to model/OptimizedAsymmetricAE_36_best_model.keras\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0193 - val_loss: 0.0198\n",
      "Epoch 6/100\n",
      "\u001b[1m 1/26\u001b[0m \u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0151\n",
      "Epoch 6: val_loss improved from 0.01977 to 0.01930, saving model to model/OptimizedAsymmetricAE_36_best_model.keras\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0185 - val_loss: 0.0193\n",
      "Epoch 7/100\n",
      "\u001b[1m 1/26\u001b[0m \u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0168\n",
      "Epoch 7: val_loss improved from 0.01930 to 0.01903, saving model to model/OptimizedAsymmetricAE_36_best_model.keras\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0183 - val_loss: 0.0190\n",
      "Epoch 8/100\n",
      "\u001b[1m 1/26\u001b[0m \u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0169\n",
      "Epoch 8: val_loss improved from 0.01903 to 0.01872, saving model to model/OptimizedAsymmetricAE_36_best_model.keras\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0182 - val_loss: 0.0187\n",
      "Epoch 9/100\n",
      "\u001b[1m 1/26\u001b[0m \u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0160\n",
      "Epoch 9: val_loss improved from 0.01872 to 0.01824, saving model to model/OptimizedAsymmetricAE_36_best_model.keras\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0176 - val_loss: 0.0182\n",
      "Epoch 10/100\n",
      "\u001b[1m 1/26\u001b[0m \u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0199\n",
      "Epoch 10: val_loss improved from 0.01824 to 0.01755, saving model to model/OptimizedAsymmetricAE_36_best_model.keras\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0173 - val_loss: 0.0175\n",
      "Epoch 11/100\n",
      "\u001b[1m 1/26\u001b[0m \u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0165\n",
      "Epoch 11: val_loss improved from 0.01755 to 0.01698, saving model to model/OptimizedAsymmetricAE_36_best_model.keras\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0160 - val_loss: 0.0170\n",
      "Epoch 12/100\n",
      "\u001b[1m 1/26\u001b[0m \u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0119\n",
      "Epoch 12: val_loss improved from 0.01698 to 0.01647, saving model to model/OptimizedAsymmetricAE_36_best_model.keras\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0148 - val_loss: 0.0165\n",
      "Epoch 13/100\n",
      "\u001b[1m 1/26\u001b[0m \u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0121\n",
      "Epoch 13: val_loss improved from 0.01647 to 0.01611, saving model to model/OptimizedAsymmetricAE_36_best_model.keras\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0144 - val_loss: 0.0161\n",
      "Epoch 14/100\n",
      "\u001b[1m 1/26\u001b[0m \u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0179\n",
      "Epoch 14: val_loss improved from 0.01611 to 0.01577, saving model to model/OptimizedAsymmetricAE_36_best_model.keras\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0152 - val_loss: 0.0158\n",
      "Epoch 15/100\n",
      "\u001b[1m 1/26\u001b[0m \u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0168\n",
      "Epoch 15: val_loss improved from 0.01577 to 0.01556, saving model to model/OptimizedAsymmetricAE_36_best_model.keras\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0146 - val_loss: 0.0156\n",
      "Epoch 16/100\n",
      "\u001b[1m 1/26\u001b[0m \u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0136\n",
      "Epoch 16: val_loss improved from 0.01556 to 0.01547, saving model to model/OptimizedAsymmetricAE_36_best_model.keras\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0144 - val_loss: 0.0155\n",
      "Epoch 17/100\n",
      "\u001b[1m 1/26\u001b[0m \u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0152\n",
      "Epoch 17: val_loss improved from 0.01547 to 0.01542, saving model to model/OptimizedAsymmetricAE_36_best_model.keras\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0145 - val_loss: 0.0154\n",
      "Epoch 18/100\n",
      "\u001b[1m 1/26\u001b[0m \u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0113\n",
      "Epoch 18: val_loss improved from 0.01542 to 0.01530, saving model to model/OptimizedAsymmetricAE_36_best_model.keras\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0130 - val_loss: 0.0153\n",
      "Epoch 19/100\n",
      "\u001b[1m 1/26\u001b[0m \u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0133\n",
      "Epoch 19: val_loss did not improve from 0.01530\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0134 - val_loss: 0.0153\n",
      "Epoch 20/100\n",
      "\u001b[1m 1/26\u001b[0m \u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0124\n",
      "Epoch 20: val_loss improved from 0.01530 to 0.01526, saving model to model/OptimizedAsymmetricAE_36_best_model.keras\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0134 - val_loss: 0.0153\n",
      "Epoch 21/100\n",
      "\u001b[1m 1/26\u001b[0m \u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0126\n",
      "Epoch 21: val_loss did not improve from 0.01526\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0133 - val_loss: 0.0153\n",
      "Epoch 22/100\n",
      "\u001b[1m 1/26\u001b[0m \u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0096\n",
      "Epoch 22: val_loss improved from 0.01526 to 0.01516, saving model to model/OptimizedAsymmetricAE_36_best_model.keras\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0128 - val_loss: 0.0152\n",
      "Epoch 23/100\n",
      "\u001b[1m 1/26\u001b[0m \u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0099\n",
      "Epoch 23: val_loss did not improve from 0.01516\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0128 - val_loss: 0.0152\n",
      "Epoch 24/100\n",
      "\u001b[1m 1/26\u001b[0m \u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0113\n",
      "Epoch 24: val_loss did not improve from 0.01516\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0129 - val_loss: 0.0152\n",
      "Epoch 25/100\n",
      "\u001b[1m 1/26\u001b[0m \u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0129\n",
      "Epoch 25: val_loss did not improve from 0.01516\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0134 - val_loss: 0.0153\n",
      "Epoch 26/100\n",
      "\u001b[1m 1/26\u001b[0m \u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0144\n",
      "Epoch 26: val_loss did not improve from 0.01516\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0133 - val_loss: 0.0152\n",
      "Epoch 27/100\n",
      "\u001b[1m 1/26\u001b[0m \u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0117\n",
      "Epoch 27: val_loss did not improve from 0.01516\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0127 - val_loss: 0.0152\n",
      "Epoch 28/100\n",
      "\u001b[1m 1/26\u001b[0m \u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0151\n",
      "Epoch 28: val_loss improved from 0.01516 to 0.01511, saving model to model/OptimizedAsymmetricAE_36_best_model.keras\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0133 - val_loss: 0.0151\n",
      "Epoch 29/100\n",
      "\u001b[1m 1/26\u001b[0m \u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0108\n",
      "Epoch 29: val_loss did not improve from 0.01511\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0126 - val_loss: 0.0152\n",
      "Epoch 30/100\n",
      "\u001b[1m 1/26\u001b[0m \u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0123\n",
      "Epoch 30: val_loss did not improve from 0.01511\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0125 - val_loss: 0.0151\n",
      "Epoch 31/100\n",
      "\u001b[1m 1/26\u001b[0m \u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0160\n",
      "Epoch 31: val_loss did not improve from 0.01511\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0130 - val_loss: 0.0152\n",
      "Epoch 32/100\n",
      "\u001b[1m 1/26\u001b[0m \u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0118\n",
      "Epoch 32: val_loss did not improve from 0.01511\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0126 - val_loss: 0.0152\n",
      "Epoch 33/100\n",
      "\u001b[1m 1/26\u001b[0m \u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0138\n",
      "Epoch 33: val_loss did not improve from 0.01511\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0125 - val_loss: 0.0152\n",
      "Epoch 34/100\n",
      "\u001b[1m 1/26\u001b[0m \u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0123\n",
      "Epoch 34: val_loss improved from 0.01511 to 0.01509, saving model to model/OptimizedAsymmetricAE_36_best_model.keras\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0128 - val_loss: 0.0151\n",
      "Epoch 35/100\n",
      "\u001b[1m 1/26\u001b[0m \u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0128\n",
      "Epoch 35: val_loss did not improve from 0.01509\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0126 - val_loss: 0.0152\n",
      "Epoch 36/100\n",
      "\u001b[1m 1/26\u001b[0m \u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0118\n",
      "Epoch 36: val_loss improved from 0.01509 to 0.01507, saving model to model/OptimizedAsymmetricAE_36_best_model.keras\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0121 - val_loss: 0.0151\n",
      "Epoch 37/100\n",
      "\u001b[1m 1/26\u001b[0m \u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0110\n",
      "Epoch 37: val_loss did not improve from 0.01507\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0121 - val_loss: 0.0151\n",
      "Epoch 38/100\n",
      "\u001b[1m 1/26\u001b[0m \u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0125\n",
      "Epoch 38: val_loss did not improve from 0.01507\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0123 - val_loss: 0.0152\n",
      "Epoch 39/100\n",
      "\u001b[1m 1/26\u001b[0m \u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0118\n",
      "Epoch 39: val_loss did not improve from 0.01507\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0120 - val_loss: 0.0151\n",
      "Epoch 40/100\n",
      "\u001b[1m 1/26\u001b[0m \u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0108\n",
      "Epoch 40: val_loss improved from 0.01507 to 0.01505, saving model to model/OptimizedAsymmetricAE_36_best_model.keras\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0119 - val_loss: 0.0150\n",
      "Epoch 41/100\n",
      "\u001b[1m 1/26\u001b[0m \u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0095\n",
      "Epoch 41: val_loss did not improve from 0.01505\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0113 - val_loss: 0.0152\n",
      "Epoch 42/100\n",
      "\u001b[1m 1/26\u001b[0m \u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0111\n",
      "Epoch 42: val_loss did not improve from 0.01505\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0119 - val_loss: 0.0151\n",
      "Epoch 43/100\n",
      "\u001b[1m 4/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0125\n",
      "Epoch 43: val_loss did not improve from 0.01505\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0121 - val_loss: 0.0150\n",
      "Epoch 44/100\n",
      "\u001b[1m 1/26\u001b[0m \u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0106\n",
      "Epoch 44: val_loss did not improve from 0.01505\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0116 - val_loss: 0.0152\n",
      "Epoch 45/100\n",
      "\u001b[1m 1/26\u001b[0m \u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0112\n",
      "Epoch 45: val_loss did not improve from 0.01505\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0117 - val_loss: 0.0151\n",
      "Epoch 46/100\n",
      "\u001b[1m 1/26\u001b[0m \u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0092\n",
      "Epoch 46: val_loss did not improve from 0.01505\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0115 - val_loss: 0.0152\n",
      "Epoch 47/100\n",
      "\u001b[1m 1/26\u001b[0m \u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0108\n",
      "Epoch 47: val_loss did not improve from 0.01505\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0116 - val_loss: 0.0151\n",
      "Epoch 48/100\n",
      "\u001b[1m 1/26\u001b[0m \u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0107\n",
      "Epoch 48: val_loss improved from 0.01505 to 0.01504, saving model to model/OptimizedAsymmetricAE_36_best_model.keras\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0117 - val_loss: 0.0150\n",
      "Epoch 49/100\n",
      "\u001b[1m 1/26\u001b[0m \u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0112\n",
      "Epoch 49: val_loss did not improve from 0.01504\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0111 - val_loss: 0.0151\n",
      "Epoch 50/100\n",
      "\u001b[1m 1/26\u001b[0m \u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0126\n",
      "Epoch 50: val_loss did not improve from 0.01504\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0119 - val_loss: 0.0151\n",
      "Epoch 51/100\n",
      "\u001b[1m 1/26\u001b[0m \u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0095\n",
      "Epoch 51: val_loss improved from 0.01504 to 0.01494, saving model to model/OptimizedAsymmetricAE_36_best_model.keras\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0112 - val_loss: 0.0149\n",
      "Epoch 52/100\n",
      "\u001b[1m 1/26\u001b[0m \u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0096\n",
      "Epoch 52: val_loss did not improve from 0.01494\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0111 - val_loss: 0.0150\n",
      "Epoch 53/100\n",
      "\u001b[1m 1/26\u001b[0m \u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0096\n",
      "Epoch 53: val_loss improved from 0.01494 to 0.01493, saving model to model/OptimizedAsymmetricAE_36_best_model.keras\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0110 - val_loss: 0.0149\n",
      "Epoch 54/100\n",
      "\u001b[1m 1/26\u001b[0m \u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0109\n",
      "Epoch 54: val_loss did not improve from 0.01493\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0111 - val_loss: 0.0151\n",
      "Epoch 55/100\n",
      "\u001b[1m 1/26\u001b[0m \u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0136\n",
      "Epoch 55: val_loss did not improve from 0.01493\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0113 - val_loss: 0.0150\n",
      "Epoch 56/100\n",
      "\u001b[1m 1/26\u001b[0m \u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0105\n",
      "Epoch 56: val_loss did not improve from 0.01493\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0109 - val_loss: 0.0149\n",
      "Epoch 57/100\n",
      "\u001b[1m 1/26\u001b[0m \u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0104\n",
      "Epoch 57: val_loss did not improve from 0.01493\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0107 - val_loss: 0.0150\n",
      "Epoch 58/100\n",
      "\u001b[1m 1/26\u001b[0m \u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0103\n",
      "Epoch 58: val_loss improved from 0.01493 to 0.01491, saving model to model/OptimizedAsymmetricAE_36_best_model.keras\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0110 - val_loss: 0.0149\n",
      "Epoch 59/100\n",
      "\u001b[1m 1/26\u001b[0m \u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0100\n",
      "Epoch 59: val_loss improved from 0.01491 to 0.01487, saving model to model/OptimizedAsymmetricAE_36_best_model.keras\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0109 - val_loss: 0.0149\n",
      "Epoch 60/100\n",
      "\u001b[1m 1/26\u001b[0m \u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0098\n",
      "Epoch 60: val_loss improved from 0.01487 to 0.01486, saving model to model/OptimizedAsymmetricAE_36_best_model.keras\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0111 - val_loss: 0.0149\n",
      "Epoch 61/100\n",
      "\u001b[1m 1/26\u001b[0m \u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0116\n",
      "Epoch 61: val_loss improved from 0.01486 to 0.01481, saving model to model/OptimizedAsymmetricAE_36_best_model.keras\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0106 - val_loss: 0.0148\n",
      "Epoch 62/100\n",
      "\u001b[1m 1/26\u001b[0m \u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0093\n",
      "Epoch 62: val_loss did not improve from 0.01481\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0108 - val_loss: 0.0150\n",
      "Epoch 63/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0109 \n",
      "Epoch 63: val_loss improved from 0.01481 to 0.01473, saving model to model/OptimizedAsymmetricAE_36_best_model.keras\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0109 - val_loss: 0.0147\n",
      "Epoch 64/100\n",
      "\u001b[1m 1/26\u001b[0m \u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0108\n",
      "Epoch 64: val_loss improved from 0.01473 to 0.01470, saving model to model/OptimizedAsymmetricAE_36_best_model.keras\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0109 - val_loss: 0.0147\n",
      "Epoch 65/100\n",
      "\u001b[1m20/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0104 \n",
      "Epoch 65: val_loss did not improve from 0.01470\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0105 - val_loss: 0.0148\n",
      "Epoch 66/100\n",
      "\u001b[1m 1/26\u001b[0m \u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0118\n",
      "Epoch 66: val_loss improved from 0.01470 to 0.01467, saving model to model/OptimizedAsymmetricAE_36_best_model.keras\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0109 - val_loss: 0.0147\n",
      "Epoch 67/100\n",
      "\u001b[1m 1/26\u001b[0m \u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0105\n",
      "Epoch 67: val_loss did not improve from 0.01467\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0108 - val_loss: 0.0147\n",
      "Epoch 68/100\n",
      "\u001b[1m 1/26\u001b[0m \u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0075\n",
      "Epoch 68: val_loss did not improve from 0.01467\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0100 - val_loss: 0.0149\n",
      "Epoch 69/100\n",
      "\u001b[1m 1/26\u001b[0m \u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0110\n",
      "Epoch 69: val_loss did not improve from 0.01467\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0109 - val_loss: 0.0149\n",
      "Epoch 70/100\n",
      "\u001b[1m 1/26\u001b[0m \u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0104\n",
      "Epoch 70: val_loss did not improve from 0.01467\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0106 - val_loss: 0.0147\n",
      "Epoch 71/100\n",
      "\u001b[1m 1/26\u001b[0m \u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0088\n",
      "Epoch 71: val_loss did not improve from 0.01467\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0103 - val_loss: 0.0147\n",
      "Epoch 72/100\n",
      "\u001b[1m 1/26\u001b[0m \u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0094\n",
      "Epoch 72: val_loss did not improve from 0.01467\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0104 - val_loss: 0.0147\n",
      "Epoch 73/100\n",
      "\u001b[1m 1/26\u001b[0m \u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0115\n",
      "Epoch 73: val_loss did not improve from 0.01467\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0104 - val_loss: 0.0147\n",
      "Epoch 74/100\n",
      "\u001b[1m 1/26\u001b[0m \u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0098\n",
      "Epoch 74: val_loss did not improve from 0.01467\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0104 - val_loss: 0.0147\n",
      "Epoch 75/100\n",
      "\u001b[1m 1/26\u001b[0m \u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0128\n",
      "Epoch 75: val_loss did not improve from 0.01467\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0108 - val_loss: 0.0149\n",
      "Epoch 76/100\n",
      "\u001b[1m 1/26\u001b[0m \u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0075\n",
      "Epoch 76: val_loss did not improve from 0.01467\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0102 - val_loss: 0.0148\n",
      "Epoch 77/100\n",
      "\u001b[1m 1/26\u001b[0m \u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0112\n",
      "Epoch 77: val_loss did not improve from 0.01467\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0105 - val_loss: 0.0147\n",
      "Epoch 78/100\n",
      "\u001b[1m 1/26\u001b[0m \u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0102\n",
      "Epoch 78: val_loss improved from 0.01467 to 0.01462, saving model to model/OptimizedAsymmetricAE_36_best_model.keras\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0103 - val_loss: 0.0146\n",
      "Epoch 79/100\n",
      "\u001b[1m16/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0097 \n",
      "Epoch 79: val_loss did not improve from 0.01462\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0099 - val_loss: 0.0147\n",
      "Epoch 80/100\n",
      "\u001b[1m 1/26\u001b[0m \u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0105\n",
      "Epoch 80: val_loss did not improve from 0.01462\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0104 - val_loss: 0.0147\n",
      "Epoch 81/100\n",
      "\u001b[1m 1/26\u001b[0m \u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0084\n",
      "Epoch 81: val_loss did not improve from 0.01462\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0098 - val_loss: 0.0147\n",
      "Epoch 82/100\n",
      "\u001b[1m 1/26\u001b[0m \u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0093\n",
      "Epoch 82: val_loss improved from 0.01462 to 0.01462, saving model to model/OptimizedAsymmetricAE_36_best_model.keras\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0100 - val_loss: 0.0146\n",
      "Epoch 83/100\n",
      "\u001b[1m 1/26\u001b[0m \u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0093\n",
      "Epoch 83: val_loss did not improve from 0.01462\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0101 - val_loss: 0.0146\n",
      "Epoch 84/100\n",
      "\u001b[1m 1/26\u001b[0m \u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0114\n",
      "Epoch 84: val_loss did not improve from 0.01462\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0103 - val_loss: 0.0147\n",
      "Epoch 85/100\n",
      "\u001b[1m 1/26\u001b[0m \u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0099\n",
      "Epoch 85: val_loss did not improve from 0.01462\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0100 - val_loss: 0.0147\n",
      "Epoch 86/100\n",
      "\u001b[1m 1/26\u001b[0m \u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0101\n",
      "Epoch 86: val_loss did not improve from 0.01462\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0102 - val_loss: 0.0147\n",
      "Epoch 87/100\n",
      "\u001b[1m 1/26\u001b[0m \u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0113\n",
      "Epoch 87: val_loss did not improve from 0.01462\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0099 - val_loss: 0.0147\n",
      "Epoch 88/100\n",
      "\u001b[1m 1/26\u001b[0m \u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0109\n",
      "Epoch 88: val_loss improved from 0.01462 to 0.01459, saving model to model/OptimizedAsymmetricAE_36_best_model.keras\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0100 - val_loss: 0.0146\n",
      "Epoch 89/100\n",
      "\u001b[1m 1/26\u001b[0m \u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0096\n",
      "Epoch 89: val_loss improved from 0.01459 to 0.01450, saving model to model/OptimizedAsymmetricAE_36_best_model.keras\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0097 - val_loss: 0.0145\n",
      "Epoch 90/100\n",
      "\u001b[1m 1/26\u001b[0m \u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0100\n",
      "Epoch 90: val_loss did not improve from 0.01450\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0099 - val_loss: 0.0145\n",
      "Epoch 91/100\n",
      "\u001b[1m 1/26\u001b[0m \u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0086\n",
      "Epoch 91: val_loss did not improve from 0.01450\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0097 - val_loss: 0.0146\n",
      "Epoch 92/100\n",
      "\u001b[1m 1/26\u001b[0m \u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0091\n",
      "Epoch 92: val_loss did not improve from 0.01450\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0099 - val_loss: 0.0146\n",
      "Epoch 93/100\n",
      "\u001b[1m 1/26\u001b[0m \u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0109\n",
      "Epoch 93: val_loss did not improve from 0.01450\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0099 - val_loss: 0.0146\n",
      "Epoch 94/100\n",
      "\u001b[1m 1/26\u001b[0m \u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0075\n",
      "Epoch 94: val_loss improved from 0.01450 to 0.01446, saving model to model/OptimizedAsymmetricAE_36_best_model.keras\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0094 - val_loss: 0.0145\n",
      "Epoch 95/100\n",
      "\u001b[1m 1/26\u001b[0m \u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0092\n",
      "Epoch 95: val_loss did not improve from 0.01446\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0094 - val_loss: 0.0145\n",
      "Epoch 96/100\n",
      "\u001b[1m 1/26\u001b[0m \u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0093\n",
      "Epoch 96: val_loss did not improve from 0.01446\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0095 - val_loss: 0.0147\n",
      "Epoch 97/100\n",
      "\u001b[1m 1/26\u001b[0m \u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0116\n",
      "Epoch 97: val_loss did not improve from 0.01446\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0101 - val_loss: 0.0146\n",
      "Epoch 98/100\n",
      "\u001b[1m 1/26\u001b[0m \u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0074\n",
      "Epoch 98: val_loss did not improve from 0.01446\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0092 - val_loss: 0.0145\n",
      "Epoch 99/100\n",
      "\u001b[1m 1/26\u001b[0m \u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0075\n",
      "Epoch 99: val_loss did not improve from 0.01446\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0091 - val_loss: 0.0146\n",
      "Epoch 100/100\n",
      "\u001b[1m 1/26\u001b[0m \u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0099\n",
      "Epoch 100: val_loss did not improve from 0.01446\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0095 - val_loss: 0.0146\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 73\u001b[0m, in \u001b[0;36mAE.encode\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 73\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautoencoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtype\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_best_model.h5\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/HSAE/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/HSAE/lib/python3.9/site-packages/h5py/_hl/files.py:562\u001b[0m, in \u001b[0;36mFile.__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[1;32m    559\u001b[0m     fcpl \u001b[38;5;241m=\u001b[39m make_fcpl(track_order\u001b[38;5;241m=\u001b[39mtrack_order, fs_strategy\u001b[38;5;241m=\u001b[39mfs_strategy,\n\u001b[1;32m    560\u001b[0m                      fs_persist\u001b[38;5;241m=\u001b[39mfs_persist, fs_threshold\u001b[38;5;241m=\u001b[39mfs_threshold,\n\u001b[1;32m    561\u001b[0m                      fs_page_size\u001b[38;5;241m=\u001b[39mfs_page_size)\n\u001b[0;32m--> 562\u001b[0m     fid \u001b[38;5;241m=\u001b[39m make_fid(name, mode, userblock_size, fapl, fcpl, swmr\u001b[38;5;241m=\u001b[39mswmr)\n\u001b[1;32m    564\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(libver, \u001b[38;5;28mtuple\u001b[39m):\n",
      "File \u001b[0;32m/opt/anaconda3/envs/HSAE/lib/python3.9/site-packages/h5py/_hl/files.py:235\u001b[0m, in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    234\u001b[0m         flags \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mACC_SWMR_READ\n\u001b[0;32m--> 235\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mh5f\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfapl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/h5f.pyx:102\u001b[0m, in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] Unable to open file (unable to open file: name = 'model/OptimizedAsymmetricAE_36_best_model.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[62], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m AE_to_optimize \u001b[38;5;241m=\u001b[39m OptimizedAsymmetricAE(X_train\u001b[38;5;241m=\u001b[39mX_train,X_test\u001b[38;5;241m=\u001b[39mX_test,y_train\u001b[38;5;241m=\u001b[39my_train,y_test\u001b[38;5;241m=\u001b[39my_test)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mAE_to_optimize\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m AE_to_optimize\u001b[38;5;241m.\u001b[39mcross_validation_hyperparameter_optimization()\n",
      "Cell \u001b[0;32mIn[49], line 50\u001b[0m, in \u001b[0;36mAsymmetricAE4.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     39\u001b[0m X_train, X_test\u001b[38;5;241m=\u001b[39m train_test_split(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX_train,\n\u001b[1;32m     40\u001b[0m                                     train_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.8\u001b[39m,\n\u001b[1;32m     41\u001b[0m                                     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhistory \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mautoencoder\u001b[38;5;241m.\u001b[39mfit(X_train, X_train,\n\u001b[1;32m     44\u001b[0m         epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m,\n\u001b[1;32m     45\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m,\n\u001b[1;32m     46\u001b[0m         shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     47\u001b[0m         validation_data\u001b[38;5;241m=\u001b[39m(X_test, X_test),\n\u001b[1;32m     48\u001b[0m         callbacks\u001b[38;5;241m=\u001b[39m[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheckpoint])  \n\u001b[0;32m---> 50\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmap_y()\n",
      "Cell \u001b[0;32mIn[48], line 75\u001b[0m, in \u001b[0;36mAE.encode\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mautoencoder\u001b[38;5;241m.\u001b[39mload_weights(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_best_model.h5\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m:\n\u001b[0;32m---> 75\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautoencoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtype\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_best_model.keras\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoded_X_train \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder\u001b[38;5;241m.\u001b[39mpredict(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX_train)\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoded_X_test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder\u001b[38;5;241m.\u001b[39mpredict(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX_test)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/HSAE/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/HSAE/lib/python3.9/site-packages/keras/src/models/model.py:351\u001b[0m, in \u001b[0;36mModel.load_weights\u001b[0;34m(self, filepath, skip_mismatch, **kwargs)\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[38;5;129m@traceback_utils\u001b[39m\u001b[38;5;241m.\u001b[39mfilter_traceback\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_weights\u001b[39m(\u001b[38;5;28mself\u001b[39m, filepath, skip_mismatch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    326\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load weights from a file saved via `save_weights()`.\u001b[39;00m\n\u001b[1;32m    327\u001b[0m \n\u001b[1;32m    328\u001b[0m \u001b[38;5;124;03m    Weights are loaded based on the network's\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[38;5;124;03m            the shape of the weights.\u001b[39;00m\n\u001b[1;32m    350\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 351\u001b[0m     \u001b[43msaving_api\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_weights\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip_mismatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_mismatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/HSAE/lib/python3.9/site-packages/keras/src/saving/saving_api.py:237\u001b[0m, in \u001b[0;36mload_weights\u001b[0;34m(model, filepath, skip_mismatch, **kwargs)\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m kwargs:\n\u001b[1;32m    236\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid keyword arguments: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwargs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 237\u001b[0m     \u001b[43msaving_lib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_weights_only\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip_mismatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_mismatch\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath)\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.weights.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    241\u001b[0m     objects_to_skip \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjects_to_skip\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/HSAE/lib/python3.9/site-packages/keras/src/saving/saving_lib.py:410\u001b[0m, in \u001b[0;36mload_weights_only\u001b[0;34m(model, filepath, skip_mismatch, objects_to_skip)\u001b[0m\n\u001b[1;32m    408\u001b[0m     visited_saveables \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[1;32m    409\u001b[0m error_msgs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 410\u001b[0m \u001b[43m_load_state\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweights_store\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights_store\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[43m    \u001b[49m\u001b[43massets_store\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[43m    \u001b[49m\u001b[43minner_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[43m    \u001b[49m\u001b[43mskip_mismatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_mismatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvisited_saveables\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvisited_saveables\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfailed_saveables\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfailed_saveables\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    418\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_msgs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_msgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    419\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    420\u001b[0m weights_store\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m    421\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m archive:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/HSAE/lib/python3.9/site-packages/keras/src/saving/saving_lib.py:602\u001b[0m, in \u001b[0;36m_load_state\u001b[0;34m(saveable, weights_store, assets_store, inner_path, skip_mismatch, visited_saveables, failed_saveables, error_msgs)\u001b[0m\n\u001b[1;32m    589\u001b[0m         _load_state(\n\u001b[1;32m    590\u001b[0m             child_obj,\n\u001b[1;32m    591\u001b[0m             weights_store,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    599\u001b[0m             error_msgs\u001b[38;5;241m=\u001b[39merror_msgs,\n\u001b[1;32m    600\u001b[0m         )\n\u001b[1;32m    601\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(child_obj, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mdict\u001b[39m, \u001b[38;5;28mtuple\u001b[39m, \u001b[38;5;28mset\u001b[39m)):\n\u001b[0;32m--> 602\u001b[0m         \u001b[43m_load_container_state\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    603\u001b[0m \u001b[43m            \u001b[49m\u001b[43mchild_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    604\u001b[0m \u001b[43m            \u001b[49m\u001b[43mweights_store\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    605\u001b[0m \u001b[43m            \u001b[49m\u001b[43massets_store\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    606\u001b[0m \u001b[43m            \u001b[49m\u001b[43minner_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfile_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43minner_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchild_attr\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplace\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m    608\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    609\u001b[0m \u001b[43m            \u001b[49m\u001b[43mskip_mismatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_mismatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    610\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvisited_saveables\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvisited_saveables\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    611\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfailed_saveables\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfailed_saveables\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    612\u001b[0m \u001b[43m            \u001b[49m\u001b[43merror_msgs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_msgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    615\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m failed_saveables \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    616\u001b[0m     newly_failed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(failed_saveables) \u001b[38;5;241m-\u001b[39m currently_failed\n",
      "File \u001b[0;32m/opt/anaconda3/envs/HSAE/lib/python3.9/site-packages/keras/src/saving/saving_lib.py:681\u001b[0m, in \u001b[0;36m_load_container_state\u001b[0;34m(container, weights_store, assets_store, inner_path, skip_mismatch, visited_saveables, failed_saveables, error_msgs)\u001b[0m\n\u001b[1;32m    679\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    680\u001b[0m     used_names[name] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 681\u001b[0m \u001b[43m_load_state\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[43m    \u001b[49m\u001b[43msaveable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    683\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweights_store\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    684\u001b[0m \u001b[43m    \u001b[49m\u001b[43massets_store\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    685\u001b[0m \u001b[43m    \u001b[49m\u001b[43minner_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfile_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43minner_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplace\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    686\u001b[0m \u001b[43m    \u001b[49m\u001b[43mskip_mismatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_mismatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    687\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvisited_saveables\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvisited_saveables\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    688\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfailed_saveables\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfailed_saveables\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    689\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_msgs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_msgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    690\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/HSAE/lib/python3.9/site-packages/keras/src/saving/saving_lib.py:562\u001b[0m, in \u001b[0;36m_load_state\u001b[0;34m(saveable, weights_store, assets_store, inner_path, skip_mismatch, visited_saveables, failed_saveables, error_msgs)\u001b[0m\n\u001b[1;32m    560\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m skip_mismatch \u001b[38;5;129;01mor\u001b[39;00m failed_saveables \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    561\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 562\u001b[0m         \u001b[43msaveable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_own_variables\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights_store\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43minner_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    563\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    564\u001b[0m         failed_saveables\u001b[38;5;241m.\u001b[39madd(\u001b[38;5;28mid\u001b[39m(saveable))\n",
      "File \u001b[0;32m/opt/anaconda3/envs/HSAE/lib/python3.9/site-packages/keras/src/layers/core/dense.py:241\u001b[0m, in \u001b[0;36mDense.load_own_variables\u001b[0;34m(self, store)\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_quantization_mode_error(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquantization_mode)\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, variable \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(target_variables):\n\u001b[0;32m--> 241\u001b[0m     \u001b[43mvariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massign\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstore\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlora_enabled:\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlora_kernel_a\u001b[38;5;241m.\u001b[39massign(ops\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlora_kernel_a\u001b[38;5;241m.\u001b[39mshape))\n",
      "File \u001b[0;32m/opt/anaconda3/envs/HSAE/lib/python3.9/site-packages/keras/src/backend/common/variables.py:224\u001b[0m, in \u001b[0;36mKerasVariable.assign\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21massign\u001b[39m(\u001b[38;5;28mself\u001b[39m, value):\n\u001b[0;32m--> 224\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    225\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m shape_equal(value\u001b[38;5;241m.\u001b[39mshape, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape):\n\u001b[1;32m    226\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    227\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe shape of the target variable and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    228\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe shape of the target value in \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    232\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTarget variable: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    233\u001b[0m         )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/HSAE/lib/python3.9/site-packages/keras/src/backend/tensorflow/core.py:54\u001b[0m, in \u001b[0;36mVariable._convert_to_tensor\u001b[0;34m(self, value, dtype)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_convert_to_tensor\u001b[39m(\u001b[38;5;28mself\u001b[39m, value, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m---> 54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconvert_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/HSAE/lib/python3.9/site-packages/keras/src/backend/tensorflow/core.py:113\u001b[0m, in \u001b[0;36mconvert_to_tensor\u001b[0;34m(x, dtype, sparse)\u001b[0m\n\u001b[1;32m    111\u001b[0m         x \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconvert_to_tensor(x)\n\u001b[1;32m    112\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mcast(x, dtype)\n\u001b[0;32m--> 113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m x\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m dtype:\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, tf\u001b[38;5;241m.\u001b[39mSparseTensor):\n",
      "File \u001b[0;32m/opt/anaconda3/envs/HSAE/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/HSAE/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1260\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1258\u001b[0m \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[1;32m   1259\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1260\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch_target\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1261\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[1;32m   1262\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[1;32m   1263\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[1;32m   1264\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/HSAE/lib/python3.9/site-packages/tensorflow/python/framework/tensor_conversion.py:161\u001b[0m, in \u001b[0;36mconvert_to_tensor_v2_with_dispatch\u001b[0;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m\u001b[38;5;241m.\u001b[39mtf_export(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconvert_to_tensor\u001b[39m\u001b[38;5;124m\"\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[])\n\u001b[1;32m     97\u001b[0m \u001b[38;5;129m@dispatch\u001b[39m\u001b[38;5;241m.\u001b[39madd_dispatch_support\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert_to_tensor_v2_with_dispatch\u001b[39m(\n\u001b[1;32m     99\u001b[0m     value, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype_hint\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    100\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m tensor_lib\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m    101\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Converts the given `value` to a `Tensor`.\u001b[39;00m\n\u001b[1;32m    102\u001b[0m \n\u001b[1;32m    103\u001b[0m \u001b[38;5;124;03m  This function converts Python objects of various types to `Tensor`\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;124;03m    ValueError: If the `value` is a tensor not of given `dtype` in graph mode.\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 161\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconvert_to_tensor_v2\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m      \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype_hint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_hint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/HSAE/lib/python3.9/site-packages/tensorflow/python/framework/tensor_conversion.py:171\u001b[0m, in \u001b[0;36mconvert_to_tensor_v2\u001b[0;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Converts the given `value` to a `Tensor`.\"\"\"\u001b[39;00m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# preferred_dtype = preferred_dtype or dtype_hint\u001b[39;00m\n\u001b[0;32m--> 171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtensor_conversion_registry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreferred_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_hint\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/HSAE/lib/python3.9/site-packages/tensorflow/python/framework/tensor_conversion_registry.py:234\u001b[0m, in \u001b[0;36mconvert\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, accepted_result_types)\u001b[0m\n\u001b[1;32m    225\u001b[0m       \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    226\u001b[0m           _add_error_prefix(\n\u001b[1;32m    227\u001b[0m               \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConversion function \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconversion_func\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m for type \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    230\u001b[0m               \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactual = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mret\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mbase_dtype\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    231\u001b[0m               name\u001b[38;5;241m=\u001b[39mname))\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 234\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mconversion_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_ref\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_ref\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[1;32m    237\u001b[0m   \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/HSAE/lib/python3.9/site-packages/tensorflow/python/framework/constant_tensor_conversion.py:29\u001b[0m, in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m constant_op  \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top\u001b[39;00m\n\u001b[1;32m     28\u001b[0m _ \u001b[38;5;241m=\u001b[39m as_ref\n\u001b[0;32m---> 29\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconstant_op\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstant\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/HSAE/lib/python3.9/site-packages/tensorflow/python/ops/weak_tensor_ops.py:142\u001b[0m, in \u001b[0;36mweak_tensor_binary_op_wrapper.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    141\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mis_auto_dtype_conversion_enabled():\n\u001b[0;32m--> 142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    143\u001b[0m   bound_arguments \u001b[38;5;241m=\u001b[39m signature\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    144\u001b[0m   bound_arguments\u001b[38;5;241m.\u001b[39mapply_defaults()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/HSAE/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py:276\u001b[0m, in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconstant\u001b[39m\u001b[38;5;124m\"\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[])\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconstant\u001b[39m(\n\u001b[1;32m    179\u001b[0m     value, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConst\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    180\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[ops\u001b[38;5;241m.\u001b[39mOperation, ops\u001b[38;5;241m.\u001b[39m_EagerTensorBase]:\n\u001b[1;32m    181\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Creates a constant tensor from a tensor-like object.\u001b[39;00m\n\u001b[1;32m    182\u001b[0m \n\u001b[1;32m    183\u001b[0m \u001b[38;5;124;03m  Note: All eager `tf.Tensor` values are immutable (in contrast to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;124;03m    ValueError: if called on a symbolic tensor.\u001b[39;00m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 276\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mallow_broadcast\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/HSAE/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py:289\u001b[0m, in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf.constant\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    288\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[0;32m--> 289\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_eager_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    291\u001b[0m const_tensor \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39m_create_graph_constant(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    292\u001b[0m     value, dtype, shape, name, verify_shape, allow_broadcast\n\u001b[1;32m    293\u001b[0m )\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m const_tensor\n",
      "File \u001b[0;32m/opt/anaconda3/envs/HSAE/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py:301\u001b[0m, in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_constant_eager_impl\u001b[39m(\n\u001b[1;32m    298\u001b[0m     ctx, value, dtype, shape, verify_shape\n\u001b[1;32m    299\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ops\u001b[38;5;241m.\u001b[39m_EagerTensorBase:\n\u001b[1;32m    300\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Creates a constant on the current device.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 301\u001b[0m   t \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_to_eager_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    302\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m shape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\n",
      "File \u001b[0;32m/opt/anaconda3/envs/HSAE/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py:108\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    106\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[1;32m    107\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m--> 108\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/HSAE/lib/python3.9/site-packages/h5py/_hl/dataset.py:1063\u001b[0m, in \u001b[0;36mDataset.__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   1060\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1061\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\n\u001b[0;32m-> 1063\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_direct\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1064\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arr\n",
      "File \u001b[0;32m/opt/anaconda3/envs/HSAE/lib/python3.9/site-packages/h5py/_hl/dataset.py:1024\u001b[0m, in \u001b[0;36mDataset.read_direct\u001b[0;34m(self, dest, source_sel, dest_sel)\u001b[0m\n\u001b[1;32m   1021\u001b[0m     dest_sel \u001b[38;5;241m=\u001b[39m sel\u001b[38;5;241m.\u001b[39mselect(dest\u001b[38;5;241m.\u001b[39mshape, dest_sel)\n\u001b[1;32m   1023\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m mspace \u001b[38;5;129;01min\u001b[39;00m dest_sel\u001b[38;5;241m.\u001b[39mbroadcast(source_sel\u001b[38;5;241m.\u001b[39marray_shape):\n\u001b[0;32m-> 1024\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmspace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfspace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdxpl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dxpl\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/h5d.pyx:242\u001b[0m, in \u001b[0;36mh5py.h5d.DatasetID.read\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_proxy.pyx:113\u001b[0m, in \u001b[0;36mh5py._proxy.dset_rw\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/h5fd.pyx:160\u001b[0m, in \u001b[0;36mh5py.h5fd.H5FD_fileobj_read\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/HSAE/lib/python3.9/zipfile.py:1092\u001b[0m, in \u001b[0;36mZipExtFile.seek\u001b[0;34m(self, offset, whence)\u001b[0m\n\u001b[1;32m   1090\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m read_offset \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1091\u001b[0m     read_len \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mMAX_SEEK_READ, read_offset)\n\u001b[0;32m-> 1092\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mread_len\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1093\u001b[0m     read_offset \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m read_len\n\u001b[1;32m   1095\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/HSAE/lib/python3.9/zipfile.py:926\u001b[0m, in \u001b[0;36mZipExtFile.read\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m    924\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_offset \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    925\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m n \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eof:\n\u001b[0;32m--> 926\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    927\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(data):\n\u001b[1;32m    928\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_readbuffer \u001b[38;5;241m=\u001b[39m data\n",
      "File \u001b[0;32m/opt/anaconda3/envs/HSAE/lib/python3.9/zipfile.py:1016\u001b[0m, in \u001b[0;36mZipExtFile._read1\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m   1014\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_left \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1015\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eof \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m-> 1016\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_crc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1017\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m/opt/anaconda3/envs/HSAE/lib/python3.9/zipfile.py:941\u001b[0m, in \u001b[0;36mZipExtFile._update_crc\u001b[0;34m(self, newdata)\u001b[0m\n\u001b[1;32m    938\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expected_crc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    939\u001b[0m     \u001b[38;5;66;03m# No need to compute the CRC if we don't have a reference value\u001b[39;00m\n\u001b[1;32m    940\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 941\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_running_crc \u001b[38;5;241m=\u001b[39m \u001b[43mcrc32\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnewdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_running_crc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    942\u001b[0m \u001b[38;5;66;03m# Check the CRC if we're at the end of the file\u001b[39;00m\n\u001b[1;32m    943\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eof \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_running_crc \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expected_crc:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "AE_to_optimize = OptimizedAsymmetricAE(X_train=X_train,X_test=X_test,y_train=y_train,y_test=y_test)\n",
    "AE_to_optimize.train()\n",
    "AE_to_optimize.cross_validation_hyperparameter_optimization()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Optimization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resources Investigation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ICGC:\n",
    "https://dcc.icgc.org/repositories?filters=%7B%22file%22:%7B%20%22projectCode%22:%7B%22is%22:%5B%22HNSC-US%22%5D%7D%7D%7D\n",
    "\n",
    " Data Type\n",
    " SSM  2,126\n",
    " Aligned Reads  2,037\n",
    " Clinical Data  453\n",
    " Biospecimen Data  448\n",
    " StSM  223\n",
    " SGV  132\n",
    " CNSM  88\n",
    " StGV  88"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TCPA:\n",
    "https://www.tcpaportal.org/tcpa/download.html\n",
    "\n",
    "TCGA of 2018, with L4(normalized across RPPA batches therefore enable pan-cancer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PDC:\n",
    "https://proteomic.datacommons.cancer.gov/pdc/browse\n",
    "3 studies, but Mass Spectrum not RPPA, therefore only contains Peptide result. do have clinincal though"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HNSCC PDX: \n",
    "https://aacrjournals.org/mcr/article/14/3/278/89624/Proteomic-Characterization-of-Head-and-Neck-Cancer\n",
    "RPPA, but on mention how to acess and probabaly wound not have clinical since the read from transplated rats."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HAP: Reference RNA and protein from healthy samples:\n",
    "https://www.proteinatlas.org/about/download"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pride:Full MS sets\n",
    "https://www.ebi.ac.uk/pride/archive?keyword=HNSCC,RPPA&sortDirection=DESC&page=0&pageSize=20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paper HNSCC: RPPA but only target 60 specific protein\n",
    "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3070553/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GEO: Some Protein profiling by protein array (RPPA), no HNSCC\n",
    "https://www.ncbi.nlm.nih.gov/geo/browse/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ArraryExpress: RPPA for GBM, lung cancer, breast cancer\n",
    "https://www.ebi.ac.uk/biostudies/arrayexpress/studies?query=RPPA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FANTOM6 Experiment Index: RNA-Seq\n",
    "https://fantom.gsc.riken.jp/6/experiment_index/#/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resources index: \n",
    "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6971871/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
